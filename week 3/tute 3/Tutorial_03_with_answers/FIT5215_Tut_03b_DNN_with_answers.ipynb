{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT5215: Deep Learning (2022)</span>\n",
    "***\n",
    "*CE/Lecturer:*  **Dr Trung Le** | trunglm@monash.edu <br/> <br/>\n",
    "*Tutor:*  **Mr Tuan Nguyen**  \\[tuan.ng@monash.edu \\] |**Mr Anh Bui** \\[tuananh.bui@monash.edu\\] | **Mr Xiaohao Yang** \\[xiaohao.yang@monash.edu \\] | **Mr Md Mohaimenuzzaman** \\[md.mohaimen@monash.edu \\] |**Mr Thanh Nguyen** \\[Thanh.Nguyen4@monash.edu \\] |\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Tutorial 3b: Feed-forward Neural Nets with TensorFlow 2.x</span>\n",
    "**This continues Tutorial 2a and shows you how to implement a feedforward neural network using TF 2.x**:  \n",
    "- ***Inspect how to use keras in TF 2.x to fulfill the task. As you can see later, the implementation is much simpler*.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.1 Feedforward Neural Network </span> <span style=\"color:red\">***** (highly important)</span>\n",
    "#### <span style=\"color:#0b486b\"> Tutorial objective </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will consider a fairly realistic deep NNs with *three* layers plus the *output* layer. Its architecture will be specified as: $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$. This means:\n",
    "- Input size is 16\n",
    "- First layer has 10 hidden units with ReLU activation function\n",
    "- Second layer has 20 hidden units with 20 ReLU activiation function\n",
    "- Third layer has 15 hidden units with 15 ReLU activiation function\n",
    "- And output layer is logit layer with 26 hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network, for example, can take the `letter` dataset input with $16$ features and with $26$ classes (A-Z). **Our objective in this tutorial is to implement this specific network in `TensorFlow 2.x`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.2 Implementation with TensorFlow 2.x</span> <span style=\"color:red\">***** (highly important)</span>\n",
    "We now shall implement the aforementioned network with the architecture of $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$ in Tensorflow using the dataset `letter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This letter dataset can be found at [the LIBSVM website](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#letter). Here is the dataset information:\n",
    "-  *The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet. The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli. Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical pipeline process of implementing a deep learning model is as follows:\n",
    "\n",
    "1. **Data processing**: \n",
    "    - Load the dataset and split into train, valid, and test sets.  \n",
    "     \n",
    "2. **Building the model**: \n",
    "    - Build the model using keras layers.\n",
    "     \n",
    "3. **Compiling the model**: \n",
    "    - Compile the model and specify the optimizer, the loss (e.g., cross-entropy loss) you want to optimize, metrics you want to measure. \n",
    "    \n",
    "4. **Training and evalutating**:\n",
    "    - Train the model with specific training set and validation set in a number of epochs.\n",
    "    - Predict on the test set and assess its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">1. Data Processing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `sklearn` to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (15000, 16)\n",
      "y data shape: (15000, 1)\n",
      "# classes: 26\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26.]\n"
     ]
    }
   ],
   "source": [
    "data_file_name= \"letter_scale.libsvm\"\n",
    "data_file = os.path.abspath(\"./Data/\" + data_file_name)\n",
    "X_data, y_data = load_svmlight_file(data_file)\n",
    "X_data= X_data.toarray()\n",
    "y_data= y_data.reshape(y_data.shape[0],-1)\n",
    "print(\"X data shape: {}\".format(X_data.shape))\n",
    "print(\"y data shape: {}\".format(y_data.shape))\n",
    "print(\"# classes: {}\".format(len(np.unique(y_data))))\n",
    "print(np.unique(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `sklearn` to split the dataset into the train, validation, and test sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_valid_test_split(data, target, train_size, test_size):\n",
    "    valid_size = 1 - (train_size + test_size)\n",
    "    X1, X_test, y1, y_test = train_test_split(data, target, test_size = test_size, random_state= 33)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X1, y1, test_size = float(valid_size)/(valid_size+ train_size))\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to encode the label in the form of numeric vector. For example, we want to turn $y\\_data=[\"cat\", \"dog\", \"cat\", \"lion\", \"dog\"]$ to $y\\_data=[0,1,0,2,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, in the following segment of code, we use the object `le` as an instance of the class `preprocessing.LabelEncoder()` which supports us to transform catefgorial labels in `y_data` to numerical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25 15 18 ...  0 11 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\tf2_cpu\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_data.ravel())\n",
    "y_data= le.transform(y_data)\n",
    "y_data = y_data.ravel()\n",
    "print(y_data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the function defined above to prepare our data for training, validating and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 16) (1500, 16) (1500, 16)\n",
      "(12000,) (1500,) (1500,)\n",
      "lables: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = train_valid_test_split(X_data, y_data, \n",
    "                                                                            train_size=0.8, \n",
    "                                                                            test_size=0.1)\n",
    "y_train= y_train.reshape(-1)\n",
    "y_test= y_test.reshape(-1)\n",
    "y_valid= y_valid.reshape(-1)\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)\n",
    "print(\"lables: {}\".format(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size= int(X_train.shape[0])\n",
    "n_features= int(X_train.shape[1])\n",
    "n_classes= len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">2. Build up the model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build up a feedforward neural network with the architecture: $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$ in TensorFlow 2.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(units=10,  input_shape=(16,), activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=15, activation='relu'))\n",
    "dnn_model.add(Dense(units=n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                416       \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model.build()\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x2b97995c400>,\n",
       " <keras.layers.core.Dense at 0x2b97995c460>,\n",
       " <keras.layers.core.Dense at 0x2b97a9fda30>,\n",
       " <keras.layers.core.Dense at 0x2b97a9fd610>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n"
     ]
    }
   ],
   "source": [
    "hidden1 = dnn_model.layers[0]\n",
    "hidden1\n",
    "print(hidden1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">3. Compiling Model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">4. Training and Evaluating </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#0b486b\"> Visualizing Training Progress </span>\n",
    "In this example, we demonstrate two approaches to visualize training progress, using a History object and using TensorBoard.\n",
    "\n",
    "**Using History object** \n",
    "The history object is the output of `fit()` method, which contains the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any). The training need to be finished before we can visualize using the history output. \n",
    "\n",
    "**Using TensorBoard**\n",
    "To visualize with TensorBoard we first need to create a `tensorboard callback` method with specific log directory. We then pass the callback method to `model.fit()` method. Unlike the previous method, the callback method writes log data to the log file on-the-fly. Therefore, by opening Tensorboard on a separate browser, we can train a model and parallelly visualize the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.9438 - accuracy: 0.1428 - val_loss: 2.2506 - val_accuracy: 0.3500\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 754us/step - loss: 1.8586 - accuracy: 0.4593 - val_loss: 1.5824 - val_accuracy: 0.5440\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 808us/step - loss: 1.5105 - accuracy: 0.5630 - val_loss: 1.4070 - val_accuracy: 0.6053\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 752us/step - loss: 1.3651 - accuracy: 0.6117 - val_loss: 1.3151 - val_accuracy: 0.6360\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 749us/step - loss: 1.2723 - accuracy: 0.6427 - val_loss: 1.2409 - val_accuracy: 0.6660\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 810us/step - loss: 1.2080 - accuracy: 0.6599 - val_loss: 1.1918 - val_accuracy: 0.6787\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 896us/step - loss: 1.1577 - accuracy: 0.6755 - val_loss: 1.1663 - val_accuracy: 0.6727\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 957us/step - loss: 1.1179 - accuracy: 0.6897 - val_loss: 1.1211 - val_accuracy: 0.6927\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 1.0835 - accuracy: 0.6935 - val_loss: 1.0998 - val_accuracy: 0.6973\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 957us/step - loss: 1.0543 - accuracy: 0.7027 - val_loss: 1.0791 - val_accuracy: 0.6880\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 915us/step - loss: 1.0301 - accuracy: 0.7097 - val_loss: 1.0580 - val_accuracy: 0.7073\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 760us/step - loss: 1.0073 - accuracy: 0.7144 - val_loss: 1.0328 - val_accuracy: 0.7067\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 743us/step - loss: 0.9882 - accuracy: 0.7178 - val_loss: 1.0226 - val_accuracy: 0.7080\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 722us/step - loss: 0.9712 - accuracy: 0.7237 - val_loss: 0.9951 - val_accuracy: 0.7133\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 757us/step - loss: 0.9547 - accuracy: 0.7292 - val_loss: 0.9890 - val_accuracy: 0.7180\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 778us/step - loss: 0.9419 - accuracy: 0.7309 - val_loss: 0.9675 - val_accuracy: 0.7173\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 0s 719us/step - loss: 0.9267 - accuracy: 0.7337 - val_loss: 0.9630 - val_accuracy: 0.7207\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 0s 743us/step - loss: 0.9154 - accuracy: 0.7377 - val_loss: 0.9435 - val_accuracy: 0.7240\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 0s 730us/step - loss: 0.9035 - accuracy: 0.7374 - val_loss: 0.9341 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 744us/step - loss: 0.8933 - accuracy: 0.7415 - val_loss: 0.9197 - val_accuracy: 0.7240\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "logdir = \"tf_logs/\"\n",
    "\n",
    "# Init a tensorboard_callback \n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Call the fit method, passing the tensorboard_callback \n",
    "history = dnn_model.fit(x=X_train, y=y_train, batch_size=32, \n",
    "                        epochs=20, \n",
    "                        validation_data=(X_valid, y_valid), \n",
    "                       callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate the trained model on the testing set or any subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 544us/step - loss: 0.9371 - accuracy: 0.7260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9370524287223816, 0.7260000109672546]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(X_test, y_test)  #return loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.98, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.reshape(X_test[10, :], (1,-1))\n",
    "y_prob = dnn_model.predict(X_new)\n",
    "y_prob.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect prediction !\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(dnn_model.predict(X_new), axis=-1)\n",
    "if y_pred[0]==y_test[0]:\n",
    "    print(\"Correct predeiction !\")\n",
    "else:\n",
    "    print(\"Incorrect prediction !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">5. Visualizing the Performance and Loss Objective Function </span>\n",
    "\n",
    "The `fit()` method returns a History object containing the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly a dictionary (history.history) containing the loss (`sparse_categorical_crossentropy`) and extra metrics (`accuracy`) as setted when compiling model.\n",
    "There are four keys in the history dictionary: `loss` and `val_loss` measure the loss on the training set and the validation set, respectively, while `accuracy` and `val_accuracy` measure the accuracy on the training set and the validation set.  \n",
    "The following figure visualize all four metrics with two y-axes, losses (blue lines, in descending) and accuracies (red lines, in asending) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAEvCAYAAAAZ2ogrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABZ+0lEQVR4nO3dd3iTVfvA8e/pAEpZhbJBhoBQ2bIURUZB9FVwIS7c4gJBXweiIs7XvRHFhbgAURQnUrY/BRkyyxRByh5lFOg+vz/uhKRt2iYlaZr2/lzXcyV55nmatrlzzn3OMdZalFJKKaX8ISzYBVBKKaVU6aGBhVJKKaX8RgMLpZRSSvmNBhZKKaWU8hsNLJRSSinlNxpYKKWUUspvIoJdAF+FhYXZqKioYBdDKaWUKjbHjx+31tqQqAwIucAiKiqKY8eOBbsYSimlVLExxpwIdhm8FbDoxxgqGMOfxrDSGNYaw5Me9ilvDFOMYbMxLDaGxoEqj1JKKaUCL5DVKmlAb2tpB7QH+htDt1z73AokW0sz4DXghQCWRymllFIBFrDAwlqstaQ4XkY6ltzjhw8EPnE8nwb0MQYTqDIppZRSKrACmmNhDOHAMqAZMM5aFufapT6wHcBaMo3hMFAD2B/IcimllBIZGRkkJSWRmpoa7KIooEKFCjRo0IDIyMhgF6XIAhpYWEsW0N4YqgHTjaG1tazx9TzGMBQYClCunH/LqJRSZVlSUhKVK1emcePGGKMVxsFkreXAgQMkJSXRpEmTYBenyIql64q1HALmAv1zbdoBNAQwhgigKnDAw/ETrKWTtXSKCLl+LEopVXKlpqZSo0YNDSpKAGMMNWrUCPnao0D2CqnpqKnAGKKAvsD6XLvNAG50PL8SmGNtnjwMpZRSAaRBRclRGt6LQH7/rwt84sizCAOmWssPxvAUsNRaZgAfAp8aw2bgIHB1AMujlFKqBKpUqRIpKSmF76hCQsACC2tZBXTwsH6M2/NUYFCgyqCUUkqp4hUSw4MqpZQq/ay1PPjgg7Ru3Zo2bdowZcoUAHbt2kWPHj1o3749rVu3ZuHChWRlZXHTTTed3Pe1114LVqHlMTMT5syBqVNhx47glKWEKNOpkP/+C6NGwfDhcPbZwS6NUkqVbd988w0rVqxg5cqV7N+/n86dO9OjRw+++OILLrjgAh599FGysrI4fvw4K1asYMeOHaxZIx0NDx06dOoFyM6G5GTYv9+11KgB554r22+9FXbvdm3btw+GDIFx4yTA6NPHeSNw2WWnXp4QVaYDiwoV4MsvoUsXDSyUUgqgZ8+86666Cu6+G44fh4suyrv9pptk2b8frrwy57Z58wq4mLXgNvfT1q+/5rHGjQl/+21qHzjAR1FRnLj9djo/9BC33HILfWbMoO2RI1SuWJF22dm8sm4dfzVrxp6336Zfv34wbBj89RcYA2Fh8njGGTBhglzg7rth0yZZ79ynTRt48UXZ3rQpbNuWs4yXXuoKLFaskMfYWGjeXB579JB1kZGwYAFUrw6NGxdw06VfmQ4sataUYHTdumCXRCmlQp85fIjTju2iUuYhqmYeoGrGfnjlANx3n3yIv/suTJ4sEciBA7KEh8s2oMeKFXR2/kM2hq7lypGZnU3THj1YsGABO++6iz/Xr6dZkyY0qF+fuFq12J6VxZPvvsvUqVP5KCYGoqIkYLFWaiDcpaZKIOO+/ehR1/aHHpImjdhY11Kvnmv7smUF/wDOO88PP8XQZ6wNrd6d0dHR1p+zm/boIb9fCxf67ZRKKRUaMjLYsGwZZ3TsKKMP7toFK1fCkSOu5fBhuOceqFULvvsO3nkn5/YjR+TbWb168OSTMHZs3uscOCDf5F9/HaZPl290sbEnH6uMGcORY8f4+d13+eqzz3j/m284mJ1Np65dWbx4MWlpaTRo0IDw8HDefvttNm/ezGOPPUa5cuWoUqUKa9as4frrr2eFs0YhxK1bt45WrVrlWGeMOW6tjQ5SkXxSpmssAOLiJNfGWqkZU0qpEiMrC/buhYoVoWpV+ab/ww9w4oR8+z5xQpZBg6BtW1i7Fp591rXN+fjKK9C9O/zyi+QEOLdlZXEGyDerc8+FhAS44Ya85bj0Ugks0tIk0KhSBerXl8cqVVxDIl9+ObRsKeucgUONGvIaYORIWXLJfuIJAPrfcQdz/v6bdr17Y4zhxRdfpE6dOnzyySe89NJLREZGUqlSJSZNmsSOHTu4+eabyXbUSvzvf//z909fFVGZr7F4911ZFi6EypX9dlqllCrYiRPSeyApST6kmzeXxMBhw2Tdjh1Sg5CVBePHw513Sv5Ax455z/X553DttfDnn/IYFSVLhQry+OST0K0brF4t53Kur1CB3cePU+fuu6FhQwlitmxxBQxVqkClSiebKkJOVhYcOiRLcrLnx7AwqFYNYmI8P1atWuz3H+o1FmU+sFBKKb+yVqr+ncHBjh2SFBgfL9mPXbvKuuRk1zGjR0tNQ3IynHMONGggwYZz6dULWrWSGoOdO3MGDeXKnVJ1q6cPsRLDWvmZ5Q4GCgoU3B/d8yc8CQ+Xx6ys/PcxRgKs/AKP/B5btIAizkER6oFFmW8KUUopnxw5Atu3y/Lvv/J42mlw++2yvVYtabJwd8MNElhERUlTQY8erqChQQNZB/KhVFA2efnyEGqTU2Vm+hYM5A4gMjIKPn/lyjk/0Js0KfgD3/15tONzOiXFt7Jt2uR6nd8X3eRkuUYZpIEFcMkl0jz57LPBLolSKui2bZPmAGfwsH27fBA52/C7dIENG1z7h4XBFVe4AosHHpDaBPdahzp1ZJsx8NVXxXs/p8rZJbQogUFysnxoFyQiQn6+7gFAkyb5BwTu66tWLXKtQA6VK8ty2mm+H5ueLnknue/dmVdSBmlggXy5+OOPYJdCKeVX2dlSu3DokFSJt2kj6xMSpOeD80Ng505Z/8038njrrTB7tus8sbGucQwAnnpKzt2woSz16uX8cHv44aKV11opz549nhdnLUhEhFThOxf310XYVmPbNhmDoaAAITOz4LJXrpwzAHAGBp5qDXKvq1gxtDPny5WTsQtq1gx2SUoMDSyQpsuffgp2KZRSHqWkyAdr48bygbhsGSxalPfDb8oU+bB87DEZCfHwYddwy5GRkp9gjCQ6TpzoStqrW1cSJ53GjoVHHpFvrw0aSPOFu6uu8r7s2dlw8GD+wYJz2b1bEic9VfuHh0vzSmyslD8rSz7os7Jci/vr/Lblo5bz5+P+oV+jBpx+une5BP6qNVClhv42IF1OP/5Y/v6rVw92aZQqA06ccH2g7t4tz6+6Sj6svvlGukc6tzvbsJ29J378ERzdE6lY0fUhd/y4VD+3ayddKnN/CDr7lL/2GrzxhnzL9vRN2b12Ij/Z2TKc886dkojp/uhc9uyRfTx924+MlGChdm1Z2rSRxzp1XOucS/Xq/umVkJ3tMQhZv20bLTt0CO1aA1WiaGCBBBYgOVPduwe3LEqFvP374fffc34b37MHHn9ckpm+/FK6RObWoYPkL4SFSY5C1645P2yd/cHvvVe6XlatKsmMuQ0aJEt+Ckqos1aaT9yDBE/Pd+3KGzAYI+WsV08CoI4dPQcKtWtLoFPcH+RhYbJERuZYbffu1aBC+ZUGFsiXhYsu0to8pbxy4gQsWSIJjn//LcuWLTBmjPwhzZwJ11/v2r9SJfnWvXChHBsZKWM11Kol7dK1a8vz6tUlUbJrV+lymTsvICxMciWc37p37ZLmjbQ0SaDz9FjYtrQ0V82DM3A4fjzvPVer5goYWraUx3r1XOvq1ZP7yPWhrfyvUqVKpOSTELp161YuvvjikxOTqeDQj1Ik/+rHH4NdCqVKiKws2LjRFTA4g4err5aAISkJzj9f9g0Lg0aNJB8hIQGefz7v+PgpKbIMG1b895IfY6S2o3x513wQHTtKFzH3YMG5VKwY7BIrVTBj+gNvAOHAB1j7fK7trwG9HK8qArWwtlogiqKBhZuMDP3CocqIjAwJHtaskT75W7ZAp04y+2N6uqt9EKSv/+mnS20DSBLlL79I5v+WLZIM+fXXMH++zCT53HMyoJO13icWerNfdrZk4Jcv73p0f+7NNudzrZ4sMUaNGkXDhg255557ABg7diwRERHMnTuX5ORkMjIyeOaZZxg4cKBP501NTeWuu+5i6dKlRERE8Oqrr9KrVy/Wrl3LzTffTHp6OtnZ2Xz99dfUq1ePq666iqSkJLKysnj88ccZPHhwIG43MIwJB8YBfYEkYAnGzMDaxJP7WHuf2/7DgQ6BKo7+dTncd5/kjOWeMVepkGatVPGvXi0f0P/5j6xv1EiaEpzq1pWqfJBeEF99JT0imjaV5gr3NvitW6VW4vbbpemialW48UZZunbV9voQNnKka2Zwf2nfXuYey8/gwYMZOXLkycBi6tSpzJw5k3vvvZcqVaqwf/9+unXrxoABAzA+/G6NGzcOYwyrV69m/fr19OvXj40bN/Luu+8yYsQIrrvuOtLT08nKyuKnn36iXr16/Oiouj58+PAp3HFQdAE2Y+0WAIyZDAwEEvPZ/xrgiUAVJuSG9G7YsKH99NNP/X7e3bulebVDh9AdFl+VTiYri8hDhwhLTSWtTh2scxji3Pulp2Mdk0E1/PJLaixeTPQ//xB55AgAKU2bsvTDDwGo9913ZFWsSEqTJpxo0IDsChUKLEN4Sgq15s2jzi+/UHXtWmxYGAc7d2Z3v34cOPdcsp2TUKmQk5qaSgXH+799u6tiyl+ioqS5uSBr166lRYsWZGZm8u+//9KiRQuSkpI46hiSOzU1lbZt2xIREcFff/1Fhw6ev2ynp6ezefNm4uLi+Pvvv6lVqxaVHUm/GzZs4LTTTuPEiRPs2rWLGjVqEBMTQ/ny5UlLS2Pjxo1Ur16dqlWrUqlSJb/+DHzl/p44DerVK30frHZbNQFrJwBgzJVAf6y9zfF6CNAVa/O2PxrTCFgENMDaAsYyL7qQCywCNVfId9/JBH6LF0tiulIBlZEh4xZ4M77BgQOu8RgqVIAzz5SahIoVpRbiwAEZCTIlRfY3Bu64A1atkl4YbdrIY+vWvvWnzsqSvIlPPpGprlNTpYnkxhsl16JevcD8bFSxKglzhYwZM4bY2Fh2795NnTp1qFKlCj///DOfffYZkZGRNG7cmHnz5tG4cWOvkzcvu+wyhg8fTu/evQE477zzGDduHG3btuXvv//mxx9/5K233uK9996jd+/eHDx4kJ9++on333+fPn36MGbMmOL8EeTg81whvgUWDyNBxXA/F/skbQpxcDYpJyZqYKFOUVKSjOyYX6CwZ48MmuJJdLQ0STjnMWjdWvIBwsIkcOjUSX5JnVNnO0VFSdPFQw9J3fPw4ZLvUJSkofXrJZj49FOpxouJkdEob7xRrq9NHcrPBg8ezO23387+/fuZP38+U6dOpVatWkRGRjJ37ly2FaGN+rzzzuPzzz+nd+/ebNy4kX///ZczzjiDLVu20LRpU+69917+/fdfVq1aRcuWLalevTrXX3891apV44MPPgjAXQbUDsC9XqiBY50nVwP3BLIwGlg4NGkieV2J+bVIKVWQtDSYMQM+/BB+/dVVwwBSs1ClijyecQb07OnqspmWJs+PHJGulL//LrUL77wD97j97UdESJfMiRNllMi//4Z//pFahPXrpXZi1SoZ+Mk5emNkpETMbdu6lnbtXLkU7pKTZeTKiROl2i48HC68UBrHL7nE83gRSvnJmWeeydGjR6lfvz5169bluuuu45JLLqFNmzZ06tSJls5J2nxw9913c9ddd9GmTRsiIiKYOHEi5cuXZ+rUqXz66adERkZSp04dRo8ezZIlS3jwwQcJCwsjMjKS8ePHB+AuA2oJ0BxjmiABxdVA3sFijGkJxAABncRCm0LcPPmk5FgMGBCQ06vSaM0aCSYmTZJaiDp1JKkxJgbuvz/v/j/9JB/Ys2bJsNE1auRcbrtNah5275aaD+f6/EaJzC0jI2eg4Vyc82GABCjOQKN5c5g7V9oC09KkhuSmm+C661wTZ6lSrSQ0haicijRtujEXAa8j3U0/wtpnMeYpYCnWznDsMxaogLWjAlNyR1E0sFDKR0eOSBfLN9+UD3FjXDUUzz0nAcPOnfDzz5LT4B44xMYGp6vjvn3SM8Q92FizRoKJGjUkkLjxRomstamjTNHAouQpUmBRgmhTiJusLOlJ17ChdHVX6qTsbAkmJk+GefNkdEZjJPehc2dpLujXTwZZAklsvPXWoBY5h5o1oXdvWZwyM6V/tf7CqxCzevVqhgwZkmNd+fLlWbx4cZBKpNxpYOFm+nSZYmD5cvnipsq4gwdh2jR4/33p3J+ZKYHEbbdJ0JCeLs0JVaoEu6RFExEhA18pFWLatGnDCn8PuKH8RgMLN+49QzSwKEEOHYLffpOExfr1Zfjohg0lCdGfg45kZEhvjvbtJRdi6FDpwQHShHHxxfDAA9LdUymllEcaWLhp1kyS4bVnSJDt3y8jO86fL8vKlTl7WThFRkqA0bChBBvOxf21c0bM/GzeLJNm/fqrjNlw/LgkN+7dK7kHQ4bAqFE5h7hWSimVLw0s3JQrJ0ny69YFuyRlzO7dsGCBK5BYu1bWR0XB2WfDE0/IpFdxcbLvv//Ksn276/mCBdKLIivXQHJVq+YMOBo0kPyHZs1g6VJXz43y5SWR0ZkzMXSo9N7QyWOUUsonGljkEhfn+lxTAbJ9uwQQzmBi40ZZX6kSdO8uPRR69JAP+NxJhc6ukp5kZcn8F7mDji1b5E1NSJDgwZNGjeCWW+CGG2TeDKWUUkWigUUuw4ZB6M0/U4JZKwM5OWsjFiyQ1yC1CeedJ+M+nH++JLacSlfM8HCpkWjQQF6npcFFF8k1MzMlT+LKK2UirthYCT5275YynHuudrNUqhTLzMwkQme1LRb6U86lV6/C91GF2L5dxnBwBhM7HCPL1qghNREjRkgg0aaNBAP+kJUFf/wB338vo1G+8YY0b9SsCf/9r4x61rWr/66nlPKbSy+9lO3bt5OamsqIESMYOnQov/zyC6NHjyYrK4vY2Fhmz55NSkoKw4cPZ+nSpRhjeOKJJ7jiiityzB8ybdo0fvjhByZOnMhNN91EhQoV+Ouvv+jevTtXX301I0aMIDU1laioKD7++GPOOOMMsrKyePjhh/nll18ICwvj9ttv58wzz+TNN9/k22+/BWDWrFm88847TJ8+PYg/qdCggUUuGRkyqnL9+tIMr3xw9KgMEPXqq9IVs04dCSB69JDHVq38P3Xs7Nkyr8VPP8lkXBERkhthrdRATJ7s3+spVdr17Jl33VVXwd13S3LzRRfl3X7TTbLs3y+1gu7mzSv0kh999BHVq1fnxIkTdO7cmYEDB3L77bezYMECmjRpwkHH3DpPP/00VatWZfVqmeQzOTm50HMnJSXx+++/Ex4ezpEjR1i4cCEREREkJCQwevRovv76ayZMmMDWrVtZsWIFERERHDx4kJiYGO6++2727dtHzZo1+fjjj7nlllsKvZ7SwCKPzEyptRgzBsaODXZpQkR2Nnz2mfSe2LVL8hQeeUTmxfB388LWrVIrcdttkty5YAH8+KP8s7vkErjgAmliUUqFjDfffPNkTcD27duZMGECPXr0oEmTJgBUd8zKm5CQwGS3LwsxMTGFnnvQoEGEO2oqDx8+zI033simTZswxpDhmFcnISGBO++882RTifN6Q4YM4bPPPuPmm2/mjz/+YNKkSX6649JNA4tcoqJkRmrtGeKlxYulacM53/w330C3bv47v7WSeDl1qoxgtmaNrG/VCuLj4cEH4fHHgzNMtlKlUUE1DBUrFrw9NtarGoqcl5tHQkICf/zxBxUrVqRnz560b9+e9evXe30O4/YFJjU1Nce26GjXKNiPP/44vXr1Yvr06WzdupWenmpn3Nx8881ccsklVKhQgUGDBmmOhpf8XC9dOsTF6VgWhdq5U+aW6NZNhoX+5BPJcfBHUGGt5EmAjHjZpg08+6zkaLzyivQiiY+X7ZUqaVChVAg7fPgwMTExVKxYkfXr17No0SJSU1NZsGAB/zgSvZ1NIX379mXcuHEnj3U2hdSuXZt169aRnZ1dYA7E4cOHqV+/PgATJ048ub5v37689957ZGZm5rhevXr1qFevHs888ww333yz/266lNPAwoO4ONiwQZpFVC6pqfD889CiheQvjBolH/Q33HBq+RPWSm3EE0/IGzBypKxv315mD92xQ74J3X+/DDailCoV+vfvT2ZmJq1atWLUqFF069aNmjVrMmHCBC6//HLatWvH4MGDAXjsscdITk6mdevWtGvXjrlz5wLw/PPPc/HFF3POOedQt4Du4g899BCPPPIIHTp0OBlEANx2222cdtpptG3blnbt2vHFF1+c3HbdddfRsGFDnajNBzq7qQeffCJ5SOvXS5qAQj74Z8yQD/YtW2DgQKk98MdcE6+9BhMmyA88LEySPW+5RUa9VEoFlM5uWrBhw4bRoUMHbi3GSQV1dtNS6MILYdEiGTNJITkOI0fKAFNxcTL8dd++RTuXM2fixx/hoYckuXPzZulBcu+9cPnlMgeIUkoF2VlnnUV0dDSvvPJKsIsSUjSw8KBWLVnKvIMHpWli/HiZc+PNN+HOO30f5toZTHz1lSRhOmsmLrlEApW339bBqZRSJc6yZcuCXYSQpIFFPpzjLA0aFOySBEFmpkwV/vjjkJwMd9wBTz0lGd/eslbOExkJs2ZJN1BnM8fw4VIzUaeO7KtBhVJKlRqavJmPd96B//0v2KUIgrlzoWNHGQynTRv46y/5YXgbVKSlwUsvSU3Es8/Kuh495Bw7dsj5777bFVQopZQqVTSwyEerVjKWRe7JMkutf/6BK66A3r3hyBGYNg3mzMl/wi9PZs6UYOShh6Qt6cwzZX2FCnDXXRpMKKVUGaCBRT7i4qQpZNu2YJckwI4dg8cek0jql1/g6aclorriCt+aKJ56Cvr3l+e//CJzhJTJdiSllCrbNMciH3Fx8rhunYzEWepYC1OmwAMPSBPFtdfCCy+4Zgb1RmoqnDgBMTGSMxERIRN+lS8fuHIrpZQq0bTGIh/OLsQ+jCobOlavlglRrrlGmix++w0+/9y3oOLnn6XZY9gwed26NYwerUGFUiqgKlWqFOwiqEJoYJGPmBhISpLxoEqNQ4dkXo8OHSS4ePddWLIEunf3/hxbt8Kll8qkX2FhMqy3UkqVMZk6NHO+tCmkAI4h5UNfdjZMnCjDb+/fL2NRPP20zL3hi++/l+mTw8Kky8x992kNhVKlyciRMj+PP7VvD6+/nu/mUaNG0bBhQ+655x4Axo4dS0REBHPnziU5OZmMjAyeeeYZBg4cWOilUlJSGDhwoMfjJk2axMsvv4wxhrZt2/Lpp5+yZ88e7rzzTrZs2QLA+PHjqVevHhdffDFrHBMevvzyy6SkpDB27NiTE6T99ttvXHPNNbRo0YJnnnmG9PR0atSoweeff07t2rVJSUlh+PDhLF26FGMMTzzxBIcPH2bVqlW87vhZvP/++yQmJvLaa68V/WdbQmlgUYDZs2U6jAkTQniohSVLpLnizz/hnHMksbJjR9/OkZIik3116SKBxTPPQMOGgSmvUqpMGTx4MCNHjjwZWEydOpWZM2dy7733UqVKFfbv30+3bt0YMGBAjllMPalQoQLTp0/Pc1xiYiLPPPMMv//+O7GxsScnGbv33ns5//zzmT59OllZWaSkpJyc2Cw/6enpLF26FJBJ0BYtWoQxhg8++IAXX3yRV155haeffpqqVauyevXqk/tFRkby7LPP8tJLLxEZGcnHH3/Me++9d6o/vhJJA4sCbNoEH3wAY8aE4Ofovn2S8/Dhh5JHMWkSXH+9bxHS1q3yDWbvXsnDqF1bJlJRSpVOBdQsBEqHDh3Yu3cvO3fuZN++fcTExFCnTh3uu+8+FixYQFhYGDt27GDPnj3UKaTLurWW0aNH5zluzpw5DBo0iFjHeDzVq1cHYM6cOUyaNAmA8PBwqlatWmhg4ZwQDSApKYnBgweza9cu0tPTadKkCQAJCQlMnjz55H4xMTEA9O7dmx9++IFWrVqRkZFBmzZtfPxphQbNsSiAe8+QkJGZCePGyeyjEydKc8XGjTKhl7dBRWqqdB9t1UrmBxk4UJpTlFIqAAYNGsS0adOYMmUKgwcP5vPPP2ffvn0sW7aMFStWULt2bVJTUws9T1GPcxcREUG22/+73MdHR7vmARs+fDjDhg1j9erVvPfee4Ve67bbbmPixIl8/PHHpXoa9oAFFsbQ0BjmGkOiMaw1hhEe9ulpDIeNYYVjGROo8hSFM7BITAxuOby2cCGcdZY0fZx1FqxcKTOQVqni/TnWr5eBrZ54AgYMkNcPPyxdSZVSKgAGDx7M5MmTmTZtGoMGDeLw4cPUqlWLyMhI5s6dyzYvBxTK77jevXvz1VdfceDAAYCTTSF9+vRh/PjxAGRlZXH48GFq167N3r17OXDgAGlpafzwww8FXq++IxnvE7fa3L59+zJu3LiTr521IF27dmX79u188cUXXHPNNd7+eEJOIGssMoH/Wksc0A24xxjiPOy30FraO5anAlgen8XGQs2aIRBY7NwpzRw9esjcHl99JfNzxHn6cefDmeHcqBG0bCnHT5niWxdUpZQqgjPPPJOjR49Sv3596taty3XXXcfSpUtp06YNkyZNomXLll6dJ7/jzjzzTB599FHOP/982rVrx/2O7n5vvPEGc+fOpU2bNpx11lkkJiYSGRnJmDFj6NKlC3379i3w2mPHjmXQoEGcddZZJ5tZAB577DGSk5Np3bo17dq1Y+7cuSe3XXXVVXTv3v1k80hpZKy1xXMhw3fA29Yyy21dT+ABa7nY2/NER0fbY8eOBaCEnsXHS2rB558X2yW9l54Ob7whzRbp6TKU9qhR4FZVV6gTJ+DFFyWIWLYMoqICV16lVImzbt06WjkH7lEBd/HFF3PffffRp0+ffPfx9J4YY45ba3345x48xVK/bQyNgQ7AYg+bzzaGlcBOJMhYWxxl8tasWSW0R8isWTJL6IYNcPHF8Npr0KyZb+dITJSpy7dsgcGD4fhxDSyUUioADh06RJcuXWjXrl2BQUVpEPDAwhgqAV8DI63lSK7Ny4FG1pJiDBcB3wLNPZxjKDAUoFy5wJbXw7VLlm3bZNSub76B00+HH36A//zH9/MsXSpze5QrJwmapfwXXSlVeqxevZohQ4bkWFe+fHkWL/b03bVkqFatGhs3bgx2MYpFQJtCjCES+AGYaS2verH/VqCTtezPb5/ibgrZtElm+X7ySRkGImhSU6XJ4n//kwGqHn1UAowKFYp2vv79pbYjIUECFKVUmaRNISVPkZpCjOkPvAGEAx9g7fMe9rkKGAtYYCXWXuu/UrsErMbCGAzwIbAuv6DCGOoAe6zFGkMXJJn0QKDKVBTR0a4el0ELLDIz4bLLZHCrq66Cl18u+sAa1ko1zJdfStNHqRleVClVVNbaQgefUsWjSF/2jQkHxgF9gSRgCcbMwNpEt32aA48A3bE2GWNq+aXAHgSyV0h3YAjQ26076UXGcKcx3OnY50pgjSPH4k3gamspnmxSL9WtC1WrBrlnyP33S1Dx7ruSZFnUoGLKFJnjIzVVJkPRoEKpMq9ChQocOHCgaB9oyq+stRw4cIAKvtdEdwE2Y+0WrE0HJgO5x0C/HRiHtcmOi+091fLmJ2A1FtbyG1BgCGwtbwNvB6oM/mCM9NoM2iBZ48bBW2/JdOR33FH083zwAQwdCueeKz1IitqEopQqVRo0aEBSUhL79u0LdlEUEug18L2bf31gu9vrJKBrrn1aAGDM/yHNJWOx9pciFrNAITfqUfXq1Zk3b16xXvOOO2Ri0GK+LDF//knbRx7hwDnnsObCC4tcgAZTp9Js/HgOdOnC2tGjyV6+3L8FVUop5TeeBgSLhQiMWeq2agLWTvDhtBFI54ieQANgAca0wdpDp1DUfC8UUg4ePEjPnj2L9ZoffiidL+64oxi/6CcmwrPPQps2xM6cSc9KlYp2nldegfHjYdAganz2GT2Ku1uNUkqpU7YfMrG2Uz6bdwDubeQNHOvcJQGLsTYD+AdjNiKBxhJ/l7XYBsjyl+LuFRIU+/ZB164yeNWff57aDGhr10pk9NJLEB7uvzIqpZQqNgX2CjEmAtgI9EECiiXAtVi71m2f/sA1WHsjxsQCfwHtsdbvHSZ0ErKSJi1NeoDs2gXffVe0oCIzU+Z7t1bm/Xj1VQ0qlFKqtLI2ExgGzATWAVOxdi3GPIUxAxx7zQQOYEwiMBd4MBBBBWiNhdc6d4bzz5eengFjLdx4I3z6qfTguOoq38+RlgbXXQdffw1z50IxNxsppZTyPx3Su5RatSrAF/jf/ySoePrpogUVx47BFVfAzJkyxLcGFUoppYqZNoV4KS4uwGNZTJsmo2led508+urwYbjgAplD5MMPYeRIvxdRKaWUKowGFl6Ki4MdO+Tz2++WLIEbbpChPT/4oGgTlPz5JyxfLrkVt9zi/zIqpZRSXtDAwkvOYdv9PlDW9u0wYIDMzT59uu/9WdPT5bFvX5mldNAgPxdQKaWU8p4GFl5q3x5uuknmDvGblBQJKo4dk4Eyavk4dPvmzVKVMmOGvK5Tx4+FU0oppXynyZteOu00+PhjP54wK0vyKVatgh9/lG6hvli9Gvr1k66lOueHUkqpEkJrLHxgLRzwV6/fRx6RmoY33pApzH3x55/S9zUsDBYsgLPO8lOhlFJKqVOjgYUPbr4ZOuU3oKovnCNh3nMPDBvm27FbtkCfPjI76W+/uZI/lFJKqRJAAwsfnH46bN0qKRFFNm8e3HmnNGO8/rrvxzdpAo8/DgsXynOllFKqBNHAwgdxcfK4YUMRT7BpE1x+ObRoAVOnQoQPKS6//CJdUoyBhx6CevWKWAillFIqcDSw8IEzsCjSQFkHD8LFF8ucHd9/D1Wren9sZiYMHw4jRhThwkoppVTx0V4hPmjWTCoZfA4sMjLgyiulHWX2bGja1Lfjv/hCupYGdKISpZRS6tRpYOGDyEjJuezY0YeDrIW775YJwSZNgnPP9e2imZnwzDMykMaAAYXurpRSSgWTBhY+8nkKjtdek2G6H30Uhgzx/YJffim5GdOnF22ob6WUUqoYaY6Fj44dg0WLXCNpF+j77+GBB6QZ5KmninbBpCTo2hUGDiza8UoppVQxMtbaYJfBJ9HR0fbYKfX3PDWTJ8M118iAmW3aFLDjypXQvbuMMzF/PlSsWPSLZmVJ0qdSSqkyyRhz3Frrz0klAkZrLHzkVc+QXbvgkktkEKsZM4oWVGRlwR9/yHMNKpRSSoUIDSx81KKFjKRdYGBx7bXSvfT776Fu3aJdaPJkmUZ93ryiHa+UUkoFQZlP3nS2BHmbF1mhgvQWzTew2LlTgoHnnpOeHEWRlSU5GW3bQo8eRTuHUkopFQRlusZi/nyZGHTdOt+Oi4sr4JjZs+XR14nF3E2eDBs3whNPSPWIUkopFSLKdI1Fo0aSDpGQ4Mqd8Mbo0TLmlUcJCRAbC+3aFa1QztqKNm3g0kuLdg6llFIqSMr01+HGjWVisYQE347r2jWfca6shVmzZPbRotY0bNggc7NrbYVSSqkQVKZrLADi42XE7IwMGVnTGydOwI8/wpln5pq1fN06qQKJjy96geLi4J9/IDokehUppZRSOZT5r8Tx8XD0KCxZ4v0x2dkwaBB8/XWuDc6qj6IGFv/+K00hlStrbYVSSqmQVOY/vXr1kh4hzpxLb0RHS35Gnp4hs2bJTGWNG/tekKws6NcPrrrK92OVUkqpEqLMBxY1asikYr7mWeTpGZKRId1Mi1pbMWWK5Fdcc03RjldKKaVKgDIfWIDEAn/8ASkp3h8TFwfr10tFAwB//iknKEpgkZUFTz8NrVvD5Zf7frxSSilVQmhggcQCGRmwcKH3x8TFQWoqbN3qWJGQIG0qvXv7XoCpUyVKGTNGcyuUUkqFNP0UQ+YKK1/et+aQSy+Fv/+GJk0cK2bNgk6dZH4QX02eLF1MrrjC92OVUkqpEqTMdzcFiIqScSl8CSyqV5cFgCNHZC71hx4qWgG++QZ27NDaCqWUUiFPP8kc+vSRqdD37PH+mI8/hokTgQULJE/C1/yKrCzJywgPh9NO8+1YpZRSqgTSwMLBGRPMmeP9MV98Ae+8gzSDREXJbKS+mDZN2lI2bvTtOKWUUqqE0sDCoWNHqFbNt+aQuDgZy8ImJMB558nUp95yzglSq5aMfaGUUkoVlTH9MWYDxmzGmFEett+EMfswZoVjuS1QRdEcC4fwcOnQkZAgU354M416q1ZQ5dhOTGIi3HSTbxecNk2ikilTNLdCKaVU0RkTDowD+gJJwBKMmYG1uYdxnIK1wwJdHP1EcxMfL6Nq//23d/vHxUEfHEN29u3r/YWys6W2Ii4OrrzS94IqpZRSLl2AzVi7BWvTgcnAwGAVRgMLN848C2+bQ+LioC+zOFEpFtq29f5Cc+ZIbYWOW6GUUurU1Qe2u71OcqzL7QqMWYUx0zCmYaAKE3JNIdWrV2fevHkBO/+bb0K5cjI6d6GsZXCNnzjcti2LFyzw/iIREVR5802OxMZ6eSGllFJlWSxEYMxSt1UTsHaCD6f4HvgSa9Mw5g7gE6AIIzoWzlhrA3HegImOjrbHjh0L2PlvvRWmT4d9+yTvokCJiTKw1fvvw21e5sFkZXlxYqWUUsrFGHPcWhudz8azgbFYe4Hj9SMAWPu/fPYPBw5ibdVAlFXr4XOJj4fkZPjrLy92njULgDu/7otX8Vl2NnTtCi+9dEplVEoppdwsAZpjTBOMKQdcDczIsYcxdd1eDQDWESAaWOTinOrDqzyLhAQO1WzGe780YvduL/afNg2WLYOGAWvaUkopVdZYmwkMA2YiAcNUrF2LMU9hzADHXvdizFqMWQncC9wUqOJoU4gHbdvK8BIFBhcZGVC9Okk9r6fhD+OZPbuQ+ceys+XEWVmwZo02hyillPJagU0hgbngN8CHwM9Ym+3LoVpj4UF8PPz2G5w4UcBOjmnSoy+VbqaJuXsL5/b117B2rfQE0aBCKaVUyfYOcC2wCWOex5gzvD1QAwsP4uMhLQ3+7/8K2GnWLDCGapf1olq1QgILa+HZZ6FlS7jqKj+XVimllPIzaxOw9jqgI7AVSMCY3zHmZoyJLOhQDSw86NEDIiIKaQpJSIBOnTDVYzj3XIgs6MdsDEydCh9+qLUVSimlQoMxNZBcjNuAv4A3kEBjVoGHaY6FZz16wPHjsHSph41Hjsic6Q89BM89F/CyKKWUKtuCkGMxHTgD+BSYiLW73LYtxdpO+R2qNRb5iI+H5cvh4EEPG+fPlyRMb4bx/uYbuOwyOHDA72VUSimlAuRNrI3D2v/lCCqAgoIKCGBgYQwNjWGuMSQaw1pjGOFhH2MMbxrDZmNYZQwdA1UeX8XHS2rE3LkeNiYkyDTpZ58NwMqV0L49/P57rv2ys2HsWEnAqFYtsAVWSiml/CcOY6qdfGVMDMbc7c2BgayxyAT+ay1xQDfgHmOIy7XPhUBzxzIUGB/A8vikc2eoXDmfPItc06THxEhwsXp1rv2+/VZWak8QpZRSoeV2rD108pW1ycDt3hwYsMDCWnZZy3LH86PIoB25J0UZCEyyFmsti4BqxlCXEiAyEnr29BBY7NwpNRBuzSANG0KlSrl6hmRnw5NPQosWcPXVxVFkpZRSyl/CMcacfCXDgJfz5sBiybEwhsZAB2Bxrk3ezsgWFPHxsHkzbN3qttIZaTinQkU6fbRsmSuw+PZbWLVKayuUUkqFol+AKRjTB2P6AF861hUq4IGFMVQCvgZGWsuRIp5jqDEsNYalmZn+LV9B+vSRx9mz3VYmJEBs3mnS4+JgnfvI6+efDy+8oLUVSimlQtHDwFzgLscyG3jImwMDOm26MUQiQcXn1vKNh112AO4TZzRwrMvBWiYAEwCioym2/rFxcVCnjsQSt94qBSEhQSKOsJwxWe/ekJkpS0QEUKOGdEdVSimlQo0M4z2eIuQ+BrJXiEHGGV9nLa/ms9sM4AZH75BuwGFr2ZXPvsXOGGnxmD1bUiZITIRduzx2M73xRvj8c0dQcfvt+XQnUUoppUKAMc0xZhrGJGLMlpOLF7wKLIxhhDFUcQQAHxrDcmPoV8hh3YEhQG9jWOFYLjKGO43hTsc+PwFbgM3A+4BXXVmKU3w87Nvn6PHhIb/CnbWQceQEfPQRzJtXbGVUSiml/OxjpLYiE+gFTAI+8+ZAb5tCbrGWN4zhAiAGCRg+BX7N7wBr+Q0w+W137GOBe7wsQ1A48ywSEqDdvARo1gwaNcqzn7Vw2mkwstdG/pudLe0oSimlVGiKwtrZGGOwdhswFmOWAWMKO9DbphBngHAR8Km1rKWQoKG0aNBAenzMm5UhtRD5jLZpjKRVZK12dA3RwEIppVToSsOYMGR202EYcxlQyZsDvQ0slhnDr0hgMdMYKgM+zc8eyuLj4cS8xZCSkm8zCEgsUeGfdZLY2aJFMZZQKaWU8qsRQEXgXuAs4HrgRm8O9DawuBUYBXS2luNAJHCz7+UMTfHxcG5aAtYY6NUr3/3i4iD78BGyW8ZB+fLFWEKllFLKT2QwrMFYm4K1SVh7M9ZegbWLvDnc2xyLs4EV1nLMGK5Hpk19o4hFDjk9e0INEthRtxMNYmLy3S8uDq7gdc6bmM1ZxVc8pZRSyn+szcKYc4t6uLc1FuOB48bQDvgv8DeSIVomVDVH6MYiZpuCZzM96yx48EGoVl0njVVKKRXS/sKYGRgzBGMuP7l4wdtPwExHD46BwNvWMg6oXNTShpz584kgi093xXP4cP67NUrbyItLe3P6wSXFVzallFLK/yoAB4DewCWO5WJvDvS2KeSoMTyCdDM9zxjCkDyLsiEhgazyUSxMO4f582HAgHz2W7UK5s4laVc4DYq1gEoppZQfWVvkPEpvaywGA2nIeBa7kaG3XyrqRUNOQgKmRw/Co8p7nkbdad06sjFcdH/LYiuaUkop5XfGfIwxH+VZvOBVjYW17DaGz4HOxnAx8Ke1ZSTHYscOSEwk7Oab6RHmYRp1d4mJHKrWmLX/VCQ1FSpUKLZSKqWUUv70g9vzCsBlwE5vDvR2SO+rgD+BQcBVwGJjuNLHQoYm59Sm8fHEx8sMpjvyTJPmkJjIiSZxZGfDxo3FVkKllFLKv6z92m35HPns7+TNod42hTyKjGFxo7XcAHQBHi9aaUNMQgLUrAlt254cGyvHNOrumjQhrMd5gMxXppRSSpUSzYFa3uzobfJmmLXsdXt9gADOjFpi5JomvW1biI2VwOKGGzzs/+23xKRC2Fuwdm2xl1YppZTyD2OOAtZtzW7gYW8O9Taw+MUYZgJfOl4PRmYmLd2c06Q7qirCwiTGSEiQmMN4mC2lQgV4/nm49tpiLqtSSinlL9YWeUgJr2odrOVBYALQ1rFMsNa7yCWkeZgmPT4edu6E9etz7fvSS3DGGZCWxoMPQv36xVdMpZRSyq+MuQxjqrq9roYxl3pzqNfNGdbytbXc71im+17KEJSQAM2b55gm3Rlj5OkdsmoVnDhxco6QZcuk1iI9vZjKqpRSSvnPE1jrGhLS2kPAE94cWGBgYQxHjeGIh+WoMRw5pSKXdBmOadJzzWbauDGcfrqHwCIxEVq1Ovly/3748kv4yKtev0oppVSJ4ik+8Cp9osDAwloqW0sVD0tla6lSpKKGisX5T5Pepw/MnQuZmY4V2dnSDzUu7uQ+/fpB9+7w7LOQmlpMZVZKKaX8YynGvIoxpzuWV4Fl3hxY+nt2FFVCgmRrepgmPT4ejh6FJc4pQf79V5pB3AILY+CppyApCd5/v5jKrJRSSvnHcCAdmAJMBlKBe7w5UAOL/CQkQKdO4GGa9F69JHA42RxiLdx6K3Tpkme/88+H556TuEMppZQKCdYew9pRWNsJaztj7WisPebNoRpYeHLkCCxa5LEZBGQsiw4d3AKLJk3ggw+gXbsc+xkjTSH33Rfg8iqllCrbjOmPMRswZjPGjCpgvyswxmJMwaNoGjMLY6q5vY7BmJneFEUDC0/mz4esrHwDC5BNf/wBx44BycmSZ+FB9+7w0EMQFRWgsiqllCrbjAkHxgEXAnHANRgT52G/ysAIYLEXZ4119AQR1ibj5cibGlh4kpAgkcA55+S7S3y8dBxZuBC48EL4z3/y3dda+Pxz+PjjAJRVKaVUWdcF2Iy1W7A2HcmJGOhhv6eBF5B8icJkY8xpJ18Z05icI3Hmy9uRN0uM6tWrM2/evIBeo/N335HWujWr/vgj330iIuCVV2D/Pkvm6tXs6dePTQWU6/hxWebMkZxQpZRSyluxEIExS91WTcDaCY7n9YHtbtuSgK45TmBMR6Ah1v6IMQ96cclHgd8wZj5ggPOAod6UNeQCi4MHD9KzZ8/AXWDHDti2jehhwwq9zjPPQPjuHVx//Dj1+/alfgH7R0dLbuczz8Cjj/q3yEoppUq3/ZCJtV7NLpqHMWHAq8BNXh9j7S+OPIyhwF/At4BX3RD0u3NubtOkFyY+HqxzGtO4vM1Z7jp3hksugZdfhkOHTrGMSimllMsOoKHb6waOdU6VgdbAPIzZCnQDZhSYwGnMbcBs4L/AA8CnwFhvCqOBRW5u06QXJj4e4vAusAB48kkJKl5//dSKqJRSSrlZAjTHmCYYUw64Gphxcqu1h7E2FmsbY21jYBEwAGuXejybGAF0BrZhbS+gA3DIm8JoYOEu1zTphenYEVZV6s70s56RYKQQHTrAf//rVcyilFJKecfaTGAYMBNYB0zF2rUY8xTGDCjiWVOxVpI8jSmPteuBM7w50FjrVZJniREdHW2PHfNqjA7frV0LrVvLmBS33urVIZdfLhOObd3qeRp1pZRS6lQZY45ba6OL8YLTgZuBkUBvIBmIxNqLCjtUayzcOUe86tvXu/2t5bqmf5D87xH+/tv7y6SkwAsvwL59vhdRKaWUCjhrL8PaQ1g7Fngc+BC41JtDNbBwN2uWTJN+2mmF7wuwdy9XvHIONzEx72ynBUhKgtGj4aWXilZMpZRSqthYOx9rZzjGyCiUBhZO+UyTXiBHj5D9NeN8CixatoRrr4W334Y9e3wrplJKKVWSaWDhtHixjM9dhMCiTq9WzJkjo4B7a8wYSE+XJhGllFKqtNDAwqmAadLzlZgIVarQaUA9kpNhxQrvD23eHIYMgfHjYedOn0urlFJKlUgaWDjNmpXvNOn5WrcO4uLoEy/dQXxpDgF4/HE47zw4etS345RSSqmSSrubgkyTXr06PPywzHPurSVLZAKQ88+nbVuoXVviE6WUUsqfir276SnQGgtwTZPubTdTp86d4fzzAUnNWLgQTng1knpOSUkwebLvxymllFIljQYWINUMUVFw9tneH7N1K0yZIrUdyGCdaWnw++++X/755+GGG+SUSimlVCjTwAIkOaJHDyhf3vtjfv0Vrr4aDh4E5PCICN/zLABGjZK80Wee8f1YpZRSqiTRwGLHDknC9KWbKcgxFSueHEyrcmXo1q1ogUWDBnDHHTBxIj6N4KmUUkqVNBpYOKdJ9zW/IjERWrXKMVlZfLzMG+KoxPDJI49AuXLw1FO+H6uUUkqVFBpYzJolM5O2aePbcYmJeaZKj4+XCVLnzvW9GHXqwPDh0pySne378UoppVRJEBHsAgSVj9Okn3TkiHTlyBVYdOkClSrJKa+4wvfiPP+8zpCqlFIqtJXtwCIxEXbv9r0ZpHJl6cIRFZVjdWQk9Ozpal3xlTOoWL4cqlSBZs2Kdh6llFIqWMp2U0hqKlxwgdRY+MIYaNQIatXKsyk+HjZtgm3bilaklBQZVfyRR4p2vFJKKRVMZTuwOOss+OUXCRJ88dVXMG6cx03OziVFrbWoVAlGjIBp02DlyqKdQymllAoWHdK7KP7zH+mm6mHWMWuhSRNXEmfTpr6fPjlZztGzJ3z77akWVimlVKjTIb1LO2dXUw+MgenTpUmjZ8+ijUsREwP33w/ffSfdV5VSSqlQoYGFr44dk8TNXD1C3HXoIE0hjvnJ2LTJ98uMHAmNG8OGDUUtqFJKKVX8NLDwlfOTvoDAAqB9e5gzR+YP6dkTNm707TJVqkhAcu21RSqlUkopFRQaWPhq2zYZ86KQwAKgbVvJs8jIkOBi/XrfLhURIbkav/1WtKIqpZRSxU0DC19ddpk0h5xxhle7t24twUVWlgQX69b5drmJE+G88+D//s/nkiqllFLFTnuFFJPEROjdW2og5syBM8/07rjjx6VnyZlnFr0Lq1JKqdCmvUIAY/jIGPYaw5p8tvc0hsPGsMKxjAlUWfzqllvgk098PiwuDubNg/BwGQBrjcefSl4VK8q06nPmyPFKKaVUSRbIppCJQP9C9lloLe0dS8mf1zM1VYKKIs5t3rKlBAeRkRJcrFrl3XF33AH16kmAcfx4kS6tlFJKFYuABRbWsgAowgTiJdimTTL1qBeJm/lp0UKCi/LlpWnEwxhbeURFwUsvwc6dcPhwkS+tlFJKBVywkzfPNoaVxvCzMeSbdWAMQ41hqTEszcwszuLlkpgoj6cQWAA0by7BRVSUTFPy11+FH3PttXL5unUlEdTb2g6llFKqOAUzsFgONLKWdsBbwLf57WgtE6ylk7V0igjmfKyJidLVtEWLUz5Vs2Ywf77MDdKnj3cjbFaqJI8vvgidO8PHH59yMZRSSim/ClpgYS1HrCXF8fwnINIYYoNVHq8YA926QYUKfjld06YSXFSpIpOXLVni3XF33AE9ekge6f33Q1BrcZRSSik3QQssjKGOMRjH8y6OshwIVnm8Mnas3weUaNxYgotq1aBvX1i8uPBjqleHn3+WWVBfe03mREtO9muxlFJKqSIJZHfTL4E/gDOMIckYbjWGO43hTscuVwJrjGEl8CZwtbWE1qAaftKokQQXNWpAv36waFHhx0REwOuvwwcfyP5btgS8mEoppVShdIAsb23YAFdeCePGSTtEAGzfLt1Q9+6FX36Bc87x7rjkZJkRFWTY8JYtA1I8pZRSQVLoAFnG9AfeAMKBD7D2+Vzb7wTuAbKAFGAo1iYGoqzB7hUSOtaskcWZQRkADRtKzUWdOnDBBd7PEeIMKqZPlxE6X35ZRvhUSilVBhgTDowDLgTigGswJnf3xS+wtg3WtgdeBF4NVHE0sPCWs6upl3OEFFX9+tIVtV496N8fFizw/th+/eDyy+HBB+HGG2U8L6WUUqVeF2Az1m7B2nRgMjAwxx7WHnF7FQ2BSz3QwMJbiYmSaRkd+KHa69WT4KJhQ7jwQqnF8EZ0NEydCk89BZ9+CuefL4NqKaWUKtXqA9vdXic51uVkzD0Y8zdSY3FvoAoTzFEhiqR69erMC8KkGZ2WLCGtdm1WF+O133pLUjuWL4cjR6ByZe+OO+88aRb55x/pZeJsKlFKKRWaYiECY5a6rZqAtRN8Oom144BxGHMt8Bhwox+LeFLIBRYHDx6kZ8+exX/hXr2o1KZNsV+7bVsZ+nvLFpgxQ8a78NaePVC7tjzftk16nyillAo9+yETazvls3kH0NDtdQPHuvxMBsb7q2y5aVOIt95/H+4NWM1RvmrVgrlzZaTOfv1gyBDv50BzBhUrV0pqyKhRMhy4UkqpUmUJ0BxjmmBMOeBqYEaOPYxp7vbqP8CmQBVGAwtvZGQEtZtFzZqSxPnAA/D119Kd9I47ICnJu+NbtYKbboIXXoCBA6VZRSmlVClhbSYwDJgJrAOmYu1ajHkKYwY49hqGMWsxZgVwPwFqBgEdx8I7zz8vE3QkJUHFisV77Vx27YLnnoP33pNpS+66S2oinLUTBRk/HoYPl6lOZsyQWhCllFIlX6HjWJQgWmPhjXXrJKAIclABMrvpW2/JDO7XXSfPmzaF0aMLH9b7rrtg1iwZgOuzz4qnvEoppcoWrbHwRufO0rXi11+L97pe2LgRnngCJk+GqlWluWTEiIJ7kCQlSYASHg67d0tthzHFV2allFK+0RqL0iQ7W2os4nIPYlYytGgBX34pCZo9e8Ljj0sNxiuvwIkTno9p0ECCir17oUMHGaF84cJiLbZSSqlSSgOLwmzfDseOldjAwqltW/j2Wxm3okMHqblo1kzyKtLTPR8TGyu1HX//LcHFhRfCsmXFWmyllFKljAYWhYmMlOzI7t2DXRKvdOkiLTbz5kGTJnD33dLVdOJEyMzMuW9YGNx5J2zeDC+9BH/+CZ06Se2HUkopVRSaY1GKWQszZ8Jjj0lNxBlnyHDfV14pQUVuhw/DtGlwyy2SczFlCnTtKiOZK6WUCh7NsShNtm2DlJRgl6JIjJGJzJYskfEvwsNh8GDo2BF++CHv0BxVq8Ktt8pxx45JbUaLFtJFdffu4NyDUkqp0KKBRWGuvhouuSTYpTglxsisp6tWSTfTlBS5pXPOgdmzPY/9FR0Nq1dL7cX48ZIQ+sgjhXdpVUopVbZpYFEQa2VW0xKeuOmt8HAZ+2LdOpgwQbqdxsfDWWfBhx/C8eM592/QAN59F9avl8Dk5Ze15kIppVTBNLAoyM6dMv51KQksnCIj4fbbZZCtd9+VEctvu00CiQceyDsXSbNmUtOxdasMDw4y2NYbb0BaWrEXXymlVAmmgUVB1q2Tx1IWWDhVqCBzjqxaBfPnS+3FG29A8+Zw0UXw448yjIdT/frymJYmQcnIkbLvRx/l7XGilFKqbNLAoiCJifJYSgMLJ2NkHIupUyVXdcwY+OsvuPhiCRxefhkOHnTtX748JCTIUreuJHyeeSYsXx68e1BKKVUyaGBRkL59JXOxVq1gl6TY1KsHY8dKgDF5stRSPPigPN5yS84BtPr0gUWLZGCu2Fg47TRZf/BgUCeDVUopFUQ6joUq1OrVMG4cfPqpJHh26wb33AODBknthTtrZeyLtDQYMgSuvVaCFaWUUkWn41iUBtbC999LAmcZ16aNJHnu3Ck5GAcPStDQsKHMqvrvv659s7Nh6FDJ33jwQdmnX78SOX+bUkqpANDAIj/79sGAAZJ4oAAZQOveeyWn9ddfZRyMF16QocMvu0xyLsLCpIfJ4sXSTXX0aEn03LZNznHwoByblRXce1FKKRUY2hSSn/nzZbrQmTPlK7fyaNs2qc344APYv1+GDb/7brj+eqheXfbJzpZAIjJSUlbuvluSPq+9Vmo+2rUL7j0opVRJF0pNIRpY5Mf5Cbh9uwzwoAqUmgpffSW5GIsXS81F585wwQWydOkCERGy3w8/SL7GTz9JN9W2beGPP6BixWDfhVJKlUwaWARQsQUWw4fDJ5/IzFzGBP56pcjy5TBjhlT2/Pmn1FhUqya9SJyBxmmnSQ3HlCmwdi28844c++STMunZ5ZdD5crBvAullCo5NLAIoGILLPr0kUk1Fi8O/LVKsYMHZT6SmTNlSUqS9S1buoKM88+X2oqMDKm9WL9eXl96qTSVxMdLbYdSSpVVGlgEULEFFlu2wKFDMhWo8gtrXYmfM2fCvHnSNFKuHJx3ngQZ/frB0aMyhPjUqTLp2f/+B6NGSbNJeLhWICmlyh4NLAJIx7EoPVJTYeFCV23GmjWyvm5dCTB695ZmlN69penkq6+kV0r//nDhhTJ+WUxMcO9BKaWKgwYWAVQsgcXmzfJJd/XVUKNGYK+lTtqxw1WbMWuWNKMYI7OvXnCBjO45Z44EI4cOSYJot24yp0m1asEuvVJKBY4GFgFULIHF++/LKE///COZhKrYZWXJ8OHO2oxFi1xjX1SsKKN5RkRI88jDD0OLFtJ8cvy41GY4AxGllCoNNLAIoGIJLO67DyZMkMb+MB1DrCQ4fFh6mGzaJBVKmzbJsmWLJH16Ureu5OAOHSqTqdWurfkZSqnQpIFFABVLYHHBBdIX0n3GLVUiZWbKkOLOgGPjRnnb1q/POxlaZKTUdLRrB61bS7DRogV06ABRUcG7B6WUKowGFgFULIHFaadJH8hPPw3sdVRAZWZKa9bff8sAXC+9BCdO5N2vXDk4+2zo1UuWrl3zTq6mlFLBpIFFAAU8sEhJgSpV4Nln4ZFHAncdVeyys2HlSvj5Zxn1848/4IknpMXr++9hwwbZr0IFOPdcCTJ694ZOnXQcDaVUcGlgEUDFUmORkiKZglWrBvY6KqgOHYLoaGkief99mQrema8RGel6XqmSjLPRu7cEG+3by3gaSilVXDSwCCAdx0IFSlqaDEf+++9Sm7F8OTz3HCxYIEOPHzwo+0VHQ48ekorTuzeceabm+CqlAksDiwAKeGAxaZI0yj/5ZOCuoULOK6/I1DFr1uRMCAXp1tq1q3Rz7dNHZnjV3idKKX/SwCKAAh5YXHKJzAW+alXgrqFC1rFjsHSp1GgcPixBxNy58PnnrnE2KleGuDjpedKypeQCN2okS61aWruhlPKdBhYBFPDA4vTTZb7vyZMDdw1VqmRnS0XXzJkyKuiOHbK+XDlIT8+5b/ny0LChBBnuAYfzdcOGcpxSSrkrNLAwpj/wBhAOfIC1z+fafj9wG5AJ7ANuwdptASmrBhZujh+XTL2xY2HMmMBcQ5V6R47AX39B9eoSLCxYAAMHuppQypWTcTMiIuDAgZzHGiMDe7kHHbmfa06xUmVPgYGFMeHARqAvkAQsAa7B2kS3fXoBi7H2OMbcBfTE2sGBKKt2onO3YYP894+LC3ZJVAirUkWGQXG65BLpaLR6tSSELl8ugcezz0LPnjKL69ChUltRvbr0SElPl4G+pk/PW+tRpYoEGO5Lw4au5/XryzmUUmVGF2Az1m4BwJjJwEDAFVhYO9dt/0XA9YEqjAYW7vbskdmsWrUKdklUKVOxoiR4du2ad1v79nDbbRJwrFwpeRwggUX79jLuxoIFElAYI7+m//4ry59/yiCx7oyREUZzBx/uS0yMJpgqVYrUB7a7vU4CPPy3OelW4OdAFSbkmkIaNmxoPw3kiJjOn4f+11VBkpoqrXLOD/8dO2D3btf2cuVkEK9mzWR7WpokjmZlyfP0dBmDw/k8PT1vT5awMDlP7qV8eXmMjNQ/AaVKkkG9eqXvg9VuqyZg7QQAjLkS6I+1tzleDwG6Yu2wPCcy5npgGHA+1qYFoqwhV2Nx8OBBevbsGexiKFVsrJWOSitXQmIirFgBO3fC7Nmy/ZprJNe4Xj1pxYuLk/lPhg51Hb9vn6uWw33Ztg22b5daEHfutR7ueR7OGo9GjTTXQ6nitB8ysbZTPpt3AA3dXjdwrMvJmHjgUQIYVEAI1lgENHnziiuk0Xv48MCcX6kAWLBAppVfu1YCj3XrZIK1v/6S7ZdfLqOMOoOOuDgZ1KtmTdc5UlMlwNi2LWfQ4R58eMr1yB1sOB8bN5YkVK31UMo/CknejECSN/sgAcUS4FqsXeu2TwdgGlKzsSmQZQ25GouASUuDb7/VxE0Vcnr0kMUpOxuSk12vGzWSGo5Jk2ReFICLL5b5UQAeeABq1JCe1qefLnOjVKuW8xrZ2a7cDk/Bx++/57wmSF5Js2ayNG+e87FePQ06lPIbazMxZhgwE+lu+hHWrsWYp4ClWDsDeAmoBHzl+OP7F2sHBKI4WmPhtHo1tG0LX3whdctKlTLWSr5GYqJ0dz3vPMnFOO20nDkcAP/9L7z8sswQ++STrqDj9NPzr4k4etQVbPzzj0xj75zOfssW19wrINcvKOjQQcSUyimUBsjSGgundevkUWssVCllDDRoIItTZCTs2iVBwZYtMpr9339LjgZIIPLcc1Jj4RQVBa+/LjkcBw5Ifocz6GjRQppZcsvKkqDDPdjYtEn+7H78MWczS1SUnMs92GjWDJo2le64lSpp4KFUSaaBhVNiovy3atEi2CVRqthVrgzt2snirlEjyb/Yts0VdGze7AoeVq+GYW5552FhUgPywQcyb8r27TIaaZMmssTHQ9++Oa+RlSX75Q46NmyQ6e1z53YYI+WtWjXnUqVK3nX5ra9SRQYoU0r5X8D+tIzhI+BiYK+1tPaw3SDDj14EHAduspblgSpPoapWhf795euSUuqkyEhXrUFu558vtRrOoMO51Kol2+fPhyFDXPtHRUli51dfSXCyfr3E9E2aSG5HfHzO82dlQVKSBBv//CNJqIcPy+imhw+7lt27YeNG1+vcwYgnFSvKn32jRjLnS8uWruX003WQMaWKKmA5FsbQA0gBJuUTWFwEDEcCi67AG9YWOKAHoNOmKxVKTpyQgCD3Mm6c5Go8/zw88ohr/2rVJMiYOVN6rfz1lySeNm4sS7SXLcypqXmDD08ByaFDUp4NG+Q6TuHhEly0bJkz6DjjDEl0Vaq4hVKORUCTN42hMfBDPoHFe8A8a/nS8XoD0NNadhV0Tg0slCo9jhxx1UZs3ep6/PZbaaq4+24YP961f0yM1DAsWybNLj/9JAFBgwYylHmDBhKcFKXHyZEjEmBs2CA1Kc5l06acNSCxsXkDjpYtJfDR5hUVKBpYOE9ecGDxA/C8tfzmeD0beNhalhZ0zoAEFhs2SH+9Tz6R5hClVImwf798sDsDjh07ZMjziRNl+8CBMGNGzmOaN5dmEYBXX5XBwZxJq/XrSw6Is6nGG1lZcu3163MGHRs2wN69rv0iI+XaLVvKNaKiPC8VKhS+rUIFTVBVOYVSYBES8bUxDAWGQoCmlE5MlP8QsbEBOLlSqqhiY2U5+2zP27/6Snq1JCVJ0JGUlPMDefZs+PVX6Tbr1K0b/PGHPL/pJpkgrk4daZqpU0c6hjmvl53tahY5/XT4z39yXv/gwZy1HBs2yL+TWbOkGcj9ur4qXz5n0BEdLYGRc6Zb96VuXSmnUiVBMAML74YgBaxlAjABIDoa/1exJDomgGvZ0u+nVkoFTrlyrg9XT378UYKDfftcwYf7l5Njx+TPf/ZsybcAuPJKCVjANWaHe+BxwQVw9dWyff16qf1o00a6weaWmSkBhnNJTc352pdtR4/KPSxdmnfiuchIqZHxFHQ0aiSz35Yvf0o/aqW8FszAYgYwzBgmI8mbhwvLrwiYxET56/P0n0EpFdLCwqB2bVnOOivnNmcAAfLh7T5QmLVw112Sw7F7t9SMrFkjSaVXXy0f+N27u/avVEkCj5Ej4Z57ZCK511+Xde7L6aefei7GsWPSBdjTkpAgZXZv5TZGAiNPQUdMTM4J6Nyf66R0qigC2SvkS6AnEAvsAZ4AIgGs5V1Hd9O3gf5Id9ObC8uvgADlWHToIH/xPwdsFlmlVCmTkQHz5knA4Qw8du+Gyy6Dq66Sbreeuui+/jqMGCEDkt1xR97Ao0cPqWHIzpYP86J8oKenS+1GfsHHv//mHAnVG55mwfUUhJQrJ0GWM6/FuTRsKKOqas1J0WiOBWAtBY6LbS0WuCdQ1/fJhRdKHzellPJSZGTewb7cnX661Frs2SMBx+7d8txZy3H8uOR3/PabBCVpjrkmp02TD+E5c+Cii6SmpU4deaxRAx5+WPJAtm6FP/+UddWry1KjhuRilCsnI5U2beq5bNnZUp5t21zjfqSlyWN+z73d7myymT1betrkVquWK9DwFHzUry/Jqyp06VwhSikVZNbKh/Du3RJEVK0q+RuffOIKSnbvlmTRr76CLl2kZ8zNN+c917Jl0LGj7Pfmm67Aw/l4113SJXfHDhmS3ZkgG4jE+CNHXEm127fLo/uyfbsrt8VdbGze4KN+fWm2qVJFRl51f4yKKv1NNaFUY6GBRUqKNHhqiKyUCiFHj0qNw8GDshw4II+33ioBxDffwFtv5dx24oTUjtSpA088AU895TpfTIzkjyxdKh/Y330Hy5dLDUPNmvJYqxa0auXfD/GUFFfwkV8AcuBAwecID3cFGZ4Cj4Kex8S4gquSPA6JBhYB5PfA4sUXYfRomfO5cmX/nVcppUqYEyfkO5QxMtbHqlXSw2TfPulxv28ffPmlbB8xQgIT94+IqChJHHVunzPHFXDUqiXJoPffL/uuXSt5HNWqyYd35cpFH5vj+HFJSHWOnnr0aM7HwtYdOSIBTGEfd84go2ZNWdyf534dG+v9SLD+oIFFAPk9sLjpJul0vsNjT1ellCqzsrKktmDvXllSUmDAANn25pswd65r27598oG7aZNs79NHAg+nsDAZQ+T//k9e33uv/Nt1Bh7VqkmP/yuvlO0rV0oei3PbqU7jlJ0tQZF7sHHkiHyn3LfPtTgDLffn+Y1HEhWVf9AxYoR/Aw8NLALI74FFly7SoDlrlv/OqZRSZVBmpqs5YelSVw5FcrI8xsTAfffJ9iFDZC4Y5/bjxyUZ9tdfZXvTpjLiqlP58tLbZtIk1/Eg53QuHTrIxHgA69bJv/aYmFMLSqyVmpLcQUd+Qci+fRLApKRoYBEy/BpYWCv1c7feCm+84Z9zKqWU8ll6uowlUqWKvJ4zR2pCnIFHcrLkdzgTVrt3l3yRgwflgx9g6FB47z2pnYiIcDV9lC8vAca998qkd6mpsq+zNqRKFQlCunaVwc4yMmQOm6pVZVt0tG95JSdO+H+i7FAKLEpwqkox2L5dQsu4uGCXRCmlyjTnGBhOvXsXvL+zSQWkycYZXIAEFpMnS9DhDEqSk13jihw9CgsWyDr3LrHPPy+BxfbtOT8WwsMlwHjlFQls/vlHghRnQOIMQAYOlOP8HVSEmrIdWFSsKL8pPXsGuyRKKaWKKDxcesI4RURIs0l+ataUcUBAghBn3oVz8OXYWPjiC1l3+LArabR5c9l+/LjkhyQmuvbJyJDARb+nlvWmEKWUUuoUWSvNK+HhAZooE20KUUoppcoMY7T5w10RexUrpZRSSuWlgYVSSiml/EYDC6WUUkr5jQYWSimllPIbDSyUUkop5TcaWCillFLKbzSwUEoppZTfaGChlFJKKb/RwEIppZRSfqOBhVJKKaX8JuTmCjHGZAMn/HjKCCDTj+crKUrjfZXGe4LSeV96T6GjNN5XabynKGttSFQGhFxg4W/GmKXW2k7BLoe/lcb7Ko33BKXzvvSeQkdpvK/SeE+hJCSiH6WUUkqFBg0slFJKKeU3GljAhGAXIEBK432VxnuC0nlfek+hozTeV2m8p5BR5nMslFJKKeU/WmOhlFJKKb8pM4GFMaa/MWaDMWazMWaUh+3ljTFTHNsXG2MaB6GYPjHGNDTGzDXGJBpj1hpjRnjYp6cx5rAxZoVjGROMsvrCGLPVGLPaUd6lHrYbY8ybjvdqlTGmYzDK6S1jzBluP/8VxpgjxpiRufYJiffJGPORMWavMWaN27rqxphZxphNjseYfI690bHPJmPMjcVX6oLlc08vGWPWO36/phtjquVzbIG/q8GUz32NNcbscPs9uyifYwv8fxks+dzTFLf72WqMWZHPsSX2vSp1rLWlfgHCgb+BpkA5YCUQl2ufu4F3Hc+vBqYEu9xe3FddoKPjeWVgo4f76gn8EOyy+nhfW4HYArZfBPwMGKAbsDjYZfbh3sKB3UCjUHyfgB5AR2CN27oXgVGO56OAFzwcVx3Y4niMcTyPCfb9FHBP/YAIx/MXPN2TY1uBv6sl8L7GAg8Uclyh/y9L0j3l2v4KMCbU3qvStpSVGosuwGZr7RZrbTowGRiYa5+BwCeO59OAPsYYU4xl9Jm1dpe1drnj+VFgHVA/uKUqFgOBSVYsAqoZY+oGu1Be6gP8ba3dFuyCFIW1dgFwMNdq97+dT4BLPRx6ATDLWnvQWpsMzAL6B6qcvvB0T9baX621zgGWFgENir1gpyif98ob3vy/DIqC7snx//oq4MtiLZTKo6wEFvWB7W6vk8j7AXxyH8c/lMNAjWIpnR84mm46AIs9bD7bGLPSGPOzMebM4i1ZkVjgV2PMMmPMUA/bvXk/S6qryf8fX6i9T061rbW7HM93A7U97BPK79ktSA2ZJ4X9rpZEwxxNPB/l02wVqu/VecAea+2mfLaH4nsVkspKYFGqGWMqAV8DI621R3JtXo5Uu7cD3gK+LebiFcW51tqOwIXAPcaYHsEukD8YY8oBA4CvPGwOxfcpDyt1zqWmq5kx5lFkaOjP89kl1H5XxwOnA+2BXUjTQWlxDQXXVoTaexWyykpgsQNo6Pa6gWOdx32MMRFAVeBAsZTuFBhjIpGg4nNr7Te5t1trj1hrUxzPfwIijTGxxVxMn1hrdzge9wLTkapZd968nyXRhcBya+2e3BtC8X1ys8fZFOV43Othn5B7z4wxNwEXA9c5AqY8vPhdLVGstXustVnW2mzgfTyXNxTfqwjgcmBKfvuE2nsVyspKYLEEaG6MaeL41ng1MCPXPjMAZ6b6lcCc/P6ZlBSONsUPgXXW2lfz2aeOM1fEGNMFec9LbMBkjIk2xlR2PkeS6Nbk2m0GcIOjd0g34LBbVXxJlu83qlB7n3Jx/9u5EfjOwz4zgX7GmBhH9Xs/x7oSyRjTH3gIGGCtPZ7PPt78rpYouXKRLsNzeb35f1nSxAPrrbVJnjaG4nsV0oKdPVpcC9KTYCOS7fyoY91TyD8OgApIFfVm4E+gabDL7MU9nYtUO68CVjiWi4A7gTsd+wwD1iKZ3YuAc4Jd7kLuqamjrCsd5Xa+V+73ZIBxjvdyNdAp2OX24r6ikUChqtu6kHufkMBoF5CBtL3fiuQizQY2AQlAdce+nYAP3I69xfH3tRm4Odj3Usg9bUbyDJx/V84eY/WAnwr6XS0pSz739anjb2YVEizUzX1fjtd5/l+WhMXTPTnWT3T+LbntGzLvVWlbdORNpZRSSvlNWWkKUUoppVQx0MBCKaWUUn6jgYVSSiml/EYDC6WUUkr5jQYWSimllPIbDSyUUkop5TcaWCillFLKbzSwUEoppZTf/D+qcycbjGL18wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "his = history.history \n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ln1 = ax.plot(his['loss'], 'b--',label='loss')\n",
    "ln2 = ax.plot(his['val_loss'], 'b-',label='val_loss')\n",
    "ax.set_ylabel('loss', color='blue')\n",
    "ax.tick_params(axis='y', colors=\"blue\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ln3 = ax2.plot(his['accuracy'], 'r--',label='accuracy')\n",
    "ln4 = ax2.plot(his['val_accuracy'], 'r-',label='val_accuracy')\n",
    "ax2.set_ylabel('accuracy', color='red')\n",
    "ax2.tick_params(axis='y', colors=\"red\")\n",
    "\n",
    "\n",
    "lns = ln1 + ln2 + ln3 + ln4 \n",
    "labels = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labels)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize using Tensorboard on the same jupyter notebook, we first need to load the TensorBoard extension. Then just calling the tensorboard with log file directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\monash stuff\\education stuff\\3rd yr\\FIT3181 Deep Learning\\week 3\\tute 3\\Tutorial_03_with_answers\\FIT5215_Tut_03b_DNN_with_answers.ipynb Cell 46\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/monash%20stuff/education%20stuff/3rd%20yr/FIT3181%20Deep%20Learning/week%203/tute%203/Tutorial_03_with_answers/FIT5215_Tut_03b_DNN_with_answers.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load the TensorBoard notebook extension.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/monash%20stuff/education%20stuff/3rd%20yr/FIT3181%20Deep%20Learning/week%203/tute%203/Tutorial_03_with_answers/FIT5215_Tut_03b_DNN_with_answers.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/monash%20stuff/education%20stuff/3rd%20yr/FIT3181%20Deep%20Learning/week%203/tute%203/Tutorial_03_with_answers/FIT5215_Tut_03b_DNN_with_answers.ipynb#X63sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mtensorboard\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m--logdir tf_logs/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\tf2_cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2305\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2303\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2304\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2305\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2306\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\tf2_cpu\\lib\\site-packages\\tensorboard\\notebook.py:117\u001b[0m, in \u001b[0;36m_start_magic\u001b[1;34m(line)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_start_magic\u001b[39m(line):\n\u001b[0;32m    116\u001b[0m     \u001b[39m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m start(line)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\tf2_cpu\\lib\\site-packages\\tensorboard\\notebook.py:152\u001b[0m, in \u001b[0;36mstart\u001b[1;34m(args_string)\u001b[0m\n\u001b[0;32m    149\u001b[0m         handle\u001b[39m.\u001b[39mupdate(IPython\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mPretty(message))\n\u001b[0;32m    151\u001b[0m parsed_args \u001b[39m=\u001b[39m shlex\u001b[39m.\u001b[39msplit(args_string, comments\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, posix\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 152\u001b[0m start_result \u001b[39m=\u001b[39m manager\u001b[39m.\u001b[39;49mstart(parsed_args)\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(start_result, manager\u001b[39m.\u001b[39mStartLaunched):\n\u001b[0;32m    155\u001b[0m     _display(\n\u001b[0;32m    156\u001b[0m         port\u001b[39m=\u001b[39mstart_result\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mport,\n\u001b[0;32m    157\u001b[0m         print_message\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m         display_handle\u001b[39m=\u001b[39mhandle,\n\u001b[0;32m    159\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\tf2_cpu\\lib\\site-packages\\tensorboard\\manager.py:428\u001b[0m, in \u001b[0;36mstart\u001b[1;34m(arguments, timeout)\u001b[0m\n\u001b[0;32m    426\u001b[0m end_time_seconds \u001b[39m=\u001b[39m start_time_seconds \u001b[39m+\u001b[39m timeout\u001b[39m.\u001b[39mtotal_seconds()\n\u001b[0;32m    427\u001b[0m \u001b[39mwhile\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m<\u001b[39m end_time_seconds:\n\u001b[1;32m--> 428\u001b[0m     time\u001b[39m.\u001b[39;49msleep(poll_interval_seconds)\n\u001b[0;32m    429\u001b[0m     subprocess_result \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mpoll()\n\u001b[0;32m    430\u001b[0m     \u001b[39mif\u001b[39;00m subprocess_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">6. Playing around with different optimizers</span>\n",
    "In the following code we will try different optimizers to find which has the best performance (evaluate on the validation set). \n",
    "It can be done easily by passing an specific optimizer when compiling model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Evaluating with Nadam\n",
      "\n",
      "1500/1500 [==============================] - 0s 20us/sample - loss: 0.7491 - accuracy: 0.7680\n",
      "The valid accuracy is 0.7680000066757202\n",
      "\n",
      "*Evaluating with Adam\n",
      "\n",
      "1500/1500 [==============================] - 0s 19us/sample - loss: 0.6767 - accuracy: 0.7920\n",
      "The valid accuracy is 0.7919999957084656\n",
      "\n",
      "*Evaluating with Adadelta\n",
      "\n",
      "1500/1500 [==============================] - 0s 20us/sample - loss: 0.6694 - accuracy: 0.7953\n",
      "The valid accuracy is 0.7953333258628845\n",
      "\n",
      "*Evaluating with Adagrad\n",
      "\n",
      "1500/1500 [==============================] - 0s 18us/sample - loss: 0.6641 - accuracy: 0.8007\n",
      "The valid accuracy is 0.8006666898727417\n",
      "\n",
      "*Evaluating with RMSprop\n",
      "\n",
      "1500/1500 [==============================] - 0s 17us/sample - loss: 0.6345 - accuracy: 0.7953\n",
      "The valid accuracy is 0.7953333258628845\n",
      "\n",
      "*Evaluating with SGD\n",
      "\n",
      "1500/1500 [==============================] - 0s 17us/sample - loss: 0.6213 - accuracy: 0.8040\n",
      "The valid accuracy is 0.8040000200271606\n",
      "\n",
      "The best valid accuracy is 0.8040000200271606 with SGD\n"
     ]
    }
   ],
   "source": [
    "optimizer_names = [\"Nadam\", \"Adam\", \"Adadelta\", \"Adagrad\", \"RMSprop\", \"SGD\"]\n",
    "optimizer_list = [keras.optimizers.Nadam(learning_rate=0.001), keras.optimizers.Adam(learning_rate=0.001), keras.optimizers.Adadelta(learning_rate=0.001), \n",
    "                  keras.optimizers.Adagrad(learning_rate=0.001), keras.optimizers.RMSprop(learning_rate=0.001), keras.optimizers.SGD(learning_rate=0.001)]\n",
    "best_acc = 0\n",
    "best_i = -1\n",
    "for i in range(len(optimizer_list)):\n",
    "    print(\"*Evaluating with {}\\n\".format(str(optimizer_names[i])))\n",
    "    dnn_model.compile(optimizer=optimizer_list[i], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=30, validation_data=(X_valid, y_valid), verbose=0)\n",
    "    acc = dnn_model.evaluate(X_valid, y_valid)[1]\n",
    "    print(\"The valid accuracy is {}\\n\".format(acc))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_i = i\n",
    "print(\"The best valid accuracy is {} with {}\".format(best_acc, optimizer_names[best_i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">7. Fine-tuning the learning rate</span>\n",
    "Learning rate plays an important role when training a deep learning model. In the following code, we will try a simple greedy search to find a good learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Evaluating with learning rate = 0.01\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dnn_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\monash stuff\\education stuff\\3rd yr\\FIT3181 Deep Learning\\week 3\\tute 3\\Tutorial_03_with_answers\\FIT5215_Tut_03b_DNN_with_answers.ipynb Cell 50\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/monash%20stuff/education%20stuff/3rd%20yr/FIT3181%20Deep%20Learning/week%203/tute%203/Tutorial_03_with_answers/FIT5215_Tut_03b_DNN_with_answers.ipynb#Y100sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(lr)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/monash%20stuff/education%20stuff/3rd%20yr/FIT3181%20Deep%20Learning/week%203/tute%203/Tutorial_03_with_answers/FIT5215_Tut_03b_DNN_with_answers.ipynb#Y100sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*Evaluating with learning rate = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(lr[i])))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/monash%20stuff/education%20stuff/3rd%20yr/FIT3181%20Deep%20Learning/week%203/tute%203/Tutorial_03_with_answers/FIT5215_Tut_03b_DNN_with_answers.ipynb#Y100sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     dnn_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mlr[i]), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/monash%20stuff/education%20stuff/3rd%20yr/FIT3181%20Deep%20Learning/week%203/tute%203/Tutorial_03_with_answers/FIT5215_Tut_03b_DNN_with_answers.ipynb#Y100sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     dnn_model\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mX_train, y\u001b[39m=\u001b[39my_train, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_valid, y_valid), verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/monash%20stuff/education%20stuff/3rd%20yr/FIT3181%20Deep%20Learning/week%203/tute%203/Tutorial_03_with_answers/FIT5215_Tut_03b_DNN_with_answers.ipynb#Y100sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     acc \u001b[39m=\u001b[39m dnn_model\u001b[39m.\u001b[39mevaluate(X_valid, y_valid)[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dnn_model' is not defined"
     ]
    }
   ],
   "source": [
    "lr = [1e-2, 5e-3, 1e-3, 1e-4, 1e-5]    # a list of candidate learning rates\n",
    "\n",
    "best_acc = 0\n",
    "best_i = -1\n",
    "for i in range(len(lr)):\n",
    "    print(\"*Evaluating with learning rate = {}\\n\".format(str(lr[i])))\n",
    "    dnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr[i]), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=30, validation_data=(X_valid, y_valid), verbose=0)\n",
    "    acc = dnn_model.evaluate(X_valid, y_valid)[1]\n",
    "    print(\"The valid accuracy is {}\\n\".format(acc))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_i = i\n",
    "print(\"The best valid accuracy is {} with learning rate {}\".format(best_acc, lr[best_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">8. Save and Load Models</span>\n",
    "\n",
    "There are different ways to save TensorFlow models depending on the API you're using. As we used the Keras model in this tutorial, saving and loading it quite simple. It can be done by calling `model.save()` and `load_model()` methods. \n",
    "When calling `model.save()`, the entire model will be saved including: \n",
    "- The architecture, or configuration, which specifies what layers the model contain, and how they're connected.\n",
    "- A set of weights values (the \"state of the model\").\n",
    "- An optimizer (defined by compiling the model).\n",
    "- A set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trung\\Anaconda3\\envs\\tf2x_cpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/assets\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True]]\n"
     ]
    }
   ],
   "source": [
    "# Saving the entire model to a directory\n",
    "dnn_model.save('models/')\n",
    "\n",
    "# Loading the model back \n",
    "from tensorflow import keras\n",
    "loaded_model = keras.models.load_model('models/')\n",
    "\n",
    "# Checking the loaded model \n",
    "print(dnn_model.predict(X_new) == loaded_model.predict(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">Save model during training</span>\n",
    "\n",
    "One major disadvantage of the above saving method is that we cannot save the model during training but only when the training is finished. Therefore, it can be the case when the training was stopped/interrupted and we have to retrain again. To save model during training process, we can use the `ModelCheckpoint` callback allows you to continually save the model both during and at the end of training. \n",
    "Some important arguments of the `ModelCheckpoint` callback: \n",
    "- `filepath`: checkpoin directory \n",
    "- `save_weights_only`: if True, then only the model's weights will be saved (i.e., equal with model.save_weights(filepath)), else the full model is saved (i.e., equal with model.save(filepath) which saves: model' weight, model architecture, optimizer, etc.)\n",
    "- `save_best_only`: if True, it only saves when the model is considered the \"best\" and the latest best model according to the quantity monitored will not be overwritten. The \"best\" model is evaluated based on \"mode\" and \"monitor\". For example, if `monitor=val_accuracy` it means that validation accuracy is used to monitor the best checkpoint, and `mode` should be set to `max`. If `monitor=val_loss` it means that validation loss is used instead, and `mode` in this case should be `min`. \n",
    "\n",
    "More detail can be found in the link: \n",
    "https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "11616/12000 [============================>.] - ETA: 0s - loss: 0.2964 - accuracy: 0.9074\n",
      "Epoch 00001: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 70us/sample - loss: 0.2986 - accuracy: 0.9066 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 2/20\n",
      "11648/12000 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.9065\n",
      "Epoch 00002: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 59us/sample - loss: 0.2986 - accuracy: 0.9068 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 3/20\n",
      "10912/12000 [==========================>...] - ETA: 0s - loss: 0.2958 - accuracy: 0.9082\n",
      "Epoch 00003: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 57us/sample - loss: 0.2986 - accuracy: 0.9068 - val_loss: 0.3896 - val_accuracy: 0.8727\n",
      "Epoch 4/20\n",
      "11552/12000 [===========================>..] - ETA: 0s - loss: 0.2997 - accuracy: 0.9064\n",
      "Epoch 00004: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 55us/sample - loss: 0.2986 - accuracy: 0.9066 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 5/20\n",
      "11456/12000 [===========================>..] - ETA: 0s - loss: 0.2994 - accuracy: 0.9066 ETA: 0s - loss: 0.2992 - accuracy: 0.90\n",
      "Epoch 00005: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 53us/sample - loss: 0.2986 - accuracy: 0.9069 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 6/20\n",
      "11424/12000 [===========================>..] - ETA: 0s - loss: 0.2992 - accuracy: 0.9059\n",
      "Epoch 00006: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 53us/sample - loss: 0.2986 - accuracy: 0.9064 - val_loss: 0.3898 - val_accuracy: 0.8727\n",
      "Epoch 7/20\n",
      "11584/12000 [===========================>..] - ETA: 0s - loss: 0.2980 - accuracy: 0.9068\n",
      "Epoch 00007: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 54us/sample - loss: 0.2986 - accuracy: 0.9062 - val_loss: 0.3898 - val_accuracy: 0.8727\n",
      "Epoch 8/20\n",
      "10880/12000 [==========================>...] - ETA: 0s - loss: 0.3012 - accuracy: 0.9066\n",
      "Epoch 00008: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 85us/sample - loss: 0.2986 - accuracy: 0.9065 - val_loss: 0.3896 - val_accuracy: 0.8727\n",
      "Epoch 9/20\n",
      "11104/12000 [==========================>...] - ETA: 0s - loss: 0.2986 - accuracy: 0.9060\n",
      "Epoch 00009: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 53us/sample - loss: 0.2986 - accuracy: 0.9066 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 10/20\n",
      "11264/12000 [===========================>..] - ETA: 0s - loss: 0.2968 - accuracy: 0.9078\n",
      "Epoch 00010: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 56us/sample - loss: 0.2986 - accuracy: 0.9065 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 11/20\n",
      "11648/12000 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.9067\n",
      "Epoch 00011: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 53us/sample - loss: 0.2986 - accuracy: 0.9065 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 12/20\n",
      "11488/12000 [===========================>..] - ETA: 0s - loss: 0.2981 - accuracy: 0.9065\n",
      "Epoch 00012: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 54us/sample - loss: 0.2986 - accuracy: 0.9064 - val_loss: 0.3898 - val_accuracy: 0.8727\n",
      "Epoch 13/20\n",
      "11296/12000 [===========================>..] - ETA: 0s - loss: 0.2990 - accuracy: 0.9066\n",
      "Epoch 00013: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 57us/sample - loss: 0.2986 - accuracy: 0.9068 - val_loss: 0.3899 - val_accuracy: 0.8727\n",
      "Epoch 14/20\n",
      "11104/12000 [==========================>...] - ETA: 0s - loss: 0.3004 - accuracy: 0.9054\n",
      "Epoch 00014: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 54us/sample - loss: 0.2986 - accuracy: 0.9066 - val_loss: 0.3899 - val_accuracy: 0.8727\n",
      "Epoch 15/20\n",
      "10592/12000 [=========================>....] - ETA: 0s - loss: 0.2956 - accuracy: 0.9074\n",
      "Epoch 00015: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 70us/sample - loss: 0.2986 - accuracy: 0.9067 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 16/20\n",
      "11424/12000 [===========================>..] - ETA: 0s - loss: 0.2962 - accuracy: 0.9070\n",
      "Epoch 00016: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 51us/sample - loss: 0.2986 - accuracy: 0.9067 - val_loss: 0.3898 - val_accuracy: 0.8727\n",
      "Epoch 17/20\n",
      "11456/12000 [===========================>..] - ETA: 0s - loss: 0.2990 - accuracy: 0.9069\n",
      "Epoch 00017: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 55us/sample - loss: 0.2986 - accuracy: 0.9068 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 18/20\n",
      "11200/12000 [===========================>..] - ETA: 0s - loss: 0.3010 - accuracy: 0.9053\n",
      "Epoch 00018: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 56us/sample - loss: 0.2986 - accuracy: 0.9067 - val_loss: 0.3899 - val_accuracy: 0.8727\n",
      "Epoch 19/20\n",
      "10784/12000 [=========================>....] - ETA: 0s - loss: 0.2985 - accuracy: 0.9068\n",
      "Epoch 00019: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 57us/sample - loss: 0.2986 - accuracy: 0.9066 - val_loss: 0.3897 - val_accuracy: 0.8727\n",
      "Epoch 20/20\n",
      "11584/12000 [===========================>..] - ETA: 0s - loss: 0.3012 - accuracy: 0.9059\n",
      "Epoch 00020: saving model to models/cp.ckpt\n",
      "12000/12000 [==============================] - 1s 54us/sample - loss: 0.2986 - accuracy: 0.9065 - val_loss: 0.3897 - val_accuracy: 0.8727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ac40d193c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tf.keras.callbacks.ModelCheckpoint callback that saves weights only during training\n",
    "checkpoint_path = \"models/cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "dnn_model.fit(x=X_train, y=y_train, batch_size=32, \n",
    "                        epochs=20, \n",
    "                        validation_data=(X_valid, y_valid), \n",
    "                       callbacks=[tensorboard_callback, # Callback for writing log \n",
    "                                 cp_callback]) # Callback for saving model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">Save model during training</span>\n",
    "If we only saved the model's weight, we need to recreate a same architecture before loading the model weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2ac40d6f588>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we alreary created a model, therefore, we just need to load the weight \n",
    "# dnn_model = create_model() # skip this step\n",
    "dnn_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we saved the entire model (by set `save_weights_only=False`), then the pretrained model can be reloaded by `load_model` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.3 Two Approaches to Build Up Models with TensorFlow 2.x</span> <span style=\"color:red\">*** (relatively important)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two approaches to build up a model with tensorflow 2.x, a simple method using **Sequential API** and a more flexible method using **Functional API**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> Approach 1: Using `Sequential API`</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(units=10,  input_shape=(16,), activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=15, activation='relu'))\n",
    "dnn_model.add(Dense(units=26, activation='softmax'))\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> Approach 2: Using `Functional API`</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.layers.Input(shape=(16,)) #declare input layer\n",
    "h = Dense(units=10, activation= 'relu')(X)\n",
    "h = Dense(units=20, activation= 'relu')(h)\n",
    "h = Dense(units=15, activation= 'relu')(h)\n",
    "h = Dense(units=26, activation= 'softmax')(h)\n",
    "dnn_model = tf.keras.Model(inputs= X, outputs=h)\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also declare a class inherited from `tf.keras.Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDNN(tf.keras.Model):\n",
    "    def __init__(self, n_classes= 26):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dense1 = tf.keras.layers.Dense(units=10, activation= 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=20, activation= 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=15, activation= 'relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(units=self.n_classes, activation= 'softmax')\n",
    "    \n",
    "    def call(self,X): #X is the input, method call specifies how to compute the output from the input X\n",
    "        h = self.dense1(X)\n",
    "        h = self.dense2(h)\n",
    "        h = self.dense3(h)\n",
    "        h = self.dense4(h)\n",
    "        return h\n",
    "dnn_model = MyDNN(n_classes= 26)\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.4 Other approaches to Train a Model with TensorFlow 2.x</span> <span style=\"color:red\">*** (relatively important)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main approaches to training a model with Tensorflow 2.x. The simplest method is the `fit` method as we did before. This method automatically helps us to process data when training (e.g., split an entire dataset into multiple mini-batches), applies callback methods such as saving model or writing TensorBoard and monitors validation performance. \n",
    "\n",
    "However, some projects require more handly on training process (for example, doing data augmentation in self-supervised learning or training a generative model that we will learn later in this unit). In this case, we need an ability/understanding to train a model manually. In Tensorflow 2.X, we can do that with `train_on_batch` method. Basically, we will need to *(1) manually split entire dataset into mini-batches and applied data augmentaion (if any)* and *(2) feed training data to `train_on_batch` method*. It returns a training loss (which is pre-defined when compiling model) and an updated model. \n",
    "\n",
    "The following code is a simple example (without any data-augmentation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train acc=0.1510, train loss=2.8678 | valid acc=0.1573, valid loss= 2.8721\n",
      "Epoch 2: train acc=0.3644, train loss=2.0786 | valid acc=0.3533, valid loss= 2.0877\n",
      "Epoch 3: train acc=0.5075, train loss=1.6448 | valid acc=0.4947, valid loss= 1.6496\n",
      "Epoch 4: train acc=0.5758, train loss=1.4298 | valid acc=0.5633, valid loss= 1.4345\n",
      "Epoch 5: train acc=0.6065, train loss=1.3327 | valid acc=0.5880, valid loss= 1.3390\n",
      "Epoch 6: train acc=0.6285, train loss=1.2727 | valid acc=0.6080, valid loss= 1.2805\n",
      "Epoch 7: train acc=0.6465, train loss=1.2245 | valid acc=0.6293, valid loss= 1.2329\n",
      "Epoch 8: train acc=0.6597, train loss=1.1807 | valid acc=0.6387, valid loss= 1.1892\n",
      "Epoch 9: train acc=0.6717, train loss=1.1417 | valid acc=0.6580, valid loss= 1.1502\n",
      "Epoch 10: train acc=0.6824, train loss=1.1079 | valid acc=0.6667, valid loss= 1.1171\n",
      "Epoch 11: train acc=0.6892, train loss=1.0780 | valid acc=0.6820, valid loss= 1.0883\n",
      "Epoch 12: train acc=0.6977, train loss=1.0516 | valid acc=0.6893, valid loss= 1.0622\n",
      "Epoch 13: train acc=0.7035, train loss=1.0282 | valid acc=0.6927, valid loss= 1.0394\n",
      "Epoch 14: train acc=0.7093, train loss=1.0080 | valid acc=0.6980, valid loss= 1.0197\n",
      "Epoch 15: train acc=0.7138, train loss=0.9897 | valid acc=0.7027, valid loss= 1.0017\n",
      "Epoch 16: train acc=0.7193, train loss=0.9732 | valid acc=0.7093, valid loss= 0.9852\n",
      "Epoch 17: train acc=0.7221, train loss=0.9582 | valid acc=0.7120, valid loss= 0.9700\n",
      "Epoch 18: train acc=0.7256, train loss=0.9448 | valid acc=0.7140, valid loss= 0.9563\n",
      "Epoch 19: train acc=0.7286, train loss=0.9320 | valid acc=0.7207, valid loss= 0.9436\n",
      "Epoch 20: train acc=0.7314, train loss=0.9204 | valid acc=0.7233, valid loss= 0.9325\n"
     ]
    }
   ],
   "source": [
    "n_epochs =20\n",
    "batch_size = 64\n",
    "for epoch in range(n_epochs):\n",
    "    for idx_start in range(0, X_train.shape[0], batch_size):\n",
    "        idx_end = min(X_train.shape[0], idx_start + batch_size)\n",
    "        X_batch, y_batch = X_train[idx_start:idx_end], y_train[idx_start:idx_end]\n",
    "        train_loss_batch = dnn_model.train_on_batch(X_batch, y_batch)  #return the batch loss\n",
    "        \n",
    "    train_loss, train_acc = dnn_model.evaluate(x= X_train, y= y_train, batch_size= 64, verbose= 0)\n",
    "    valid_loss, valid_acc = dnn_model.evaluate(x= X_valid, y= y_valid, batch_size= 64, verbose= 0)\n",
    "    print('Epoch {}: train acc={:.4f}, train loss={:.4f} | valid acc={:.4f}, valid loss= {:.4f}'.format(epoch +1, \n",
    "                                                                                                        train_acc, \n",
    "                                                                                                        train_loss, \n",
    "                                                                                                        valid_acc, \n",
    "                                                                                                        valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> Additional Exercises </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write your own code to save a trained model to the hard disk and restore this model, then use the restored model to output the prediction result on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Insert new code to the above code to enable outputting to TensorBoard the values of `training loss`, `training accuracy`, `valid loss`, and `valid accuracy` at the end of epochs. You can refer to the code [here](https://www.tensorflow.org/tensorboard/get_started)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write code to do regression on the dataset `cadata` which can be downloaded [here](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html). Note that for a regression problem, you need to use the `L2` loss instead of the `cross-entropy` loss as in a classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the problem in this tutorial, however, using a much deeper network (i.e., $16 \\rightarrow 100 (ReLU) \\rightarrow 200 (ReLU) \\rightarrow 200 (ReLU) \\rightarrow 100 (ReLu) \\rightarrow 26$). Applying callback methods to save the model on training and writing a TensorBoard. Visualize `training loss`, `training accuracy`, `valid loss`, and `valid accuracy`. Provide observation and explanation of any issue if happen (hint, overfitting issue). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Build up a more complex feedforward neural network with `Functional API` method  as shown in figure below. The network splits into two branches and then merges in the last layer. The concatenate operation is in the last dimenstion (for example, two arrays [10,15], [10,15] will be concatenated to an array [10,30]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/feed-forward-2branches.PNG\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Keras model can be saved and restored via two functions `save()` and `load_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt/tf2\\assets\n",
      "Model is saved to: ckpt/tf2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models \n",
    "checkpoint_path = \"ckpt/tf2\"\n",
    "\n",
    "dnn_model.save(checkpoint_path)\n",
    "reconstructed_model = models.load_model(checkpoint_path)\n",
    "\n",
    "print(\"Model is saved to: {}\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate the reconstructed model on the test sett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 689us/step - loss: 0.9864 - accuracy: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9864100813865662, 0.7200000286102295]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we define a deep learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "X = tf.keras.layers.Input(shape=(16,)) # declare input layer\n",
    "h = Dense(units=10, activation= 'relu')(X)\n",
    "h = Dense(units=20, activation= 'relu')(h)\n",
    "h = Dense(units=15, activation= 'relu')(h)\n",
    "h = Dense(units=26, activation= 'softmax')(h)\n",
    "dnn_model = tf.keras.Model(inputs= X, outputs=h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us combine the defined model with an optimizer, loss, and metrics.\n",
    "Adding a `tf.keras.callbacks.TensorBoard` callback will enable outputting the values of `training loss`, `training accuracy`, `valid loss`, and `valid accuracy` at the end of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9862 - accuracy: 0.1168 - val_loss: 2.3230 - val_accuracy: 0.2913\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 1.8472 - accuracy: 0.4440 - val_loss: 1.5941 - val_accuracy: 0.5400\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 0s 686us/step - loss: 1.4707 - accuracy: 0.5722 - val_loss: 1.3960 - val_accuracy: 0.5980\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 0s 671us/step - loss: 1.3151 - accuracy: 0.6125 - val_loss: 1.2630 - val_accuracy: 0.6373\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 1.2262 - accuracy: 0.6387 - val_loss: 1.1913 - val_accuracy: 0.6573\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 1.1632 - accuracy: 0.6650 - val_loss: 1.1486 - val_accuracy: 0.6793\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 1.1128 - accuracy: 0.6813 - val_loss: 1.1014 - val_accuracy: 0.6940\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 0s 677us/step - loss: 1.0722 - accuracy: 0.6920 - val_loss: 1.0595 - val_accuracy: 0.7053\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 0s 675us/step - loss: 1.0378 - accuracy: 0.6995 - val_loss: 1.0357 - val_accuracy: 0.7073\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 1.0065 - accuracy: 0.7080 - val_loss: 0.9987 - val_accuracy: 0.7233\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.9778 - accuracy: 0.7151 - val_loss: 0.9872 - val_accuracy: 0.7200\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 0s 681us/step - loss: 0.9541 - accuracy: 0.7213 - val_loss: 0.9559 - val_accuracy: 0.7247\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 0s 673us/step - loss: 0.9333 - accuracy: 0.7285 - val_loss: 0.9471 - val_accuracy: 0.7180\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 0s 690us/step - loss: 0.9160 - accuracy: 0.7297 - val_loss: 0.9425 - val_accuracy: 0.7287\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 0s 677us/step - loss: 0.8987 - accuracy: 0.7333 - val_loss: 0.9012 - val_accuracy: 0.7433\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.8816 - accuracy: 0.7389 - val_loss: 0.8976 - val_accuracy: 0.7373\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.8680 - accuracy: 0.7413 - val_loss: 0.8829 - val_accuracy: 0.7460\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.8533 - accuracy: 0.7473 - val_loss: 0.8714 - val_accuracy: 0.7480\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.8423 - accuracy: 0.7497 - val_loss: 0.8495 - val_accuracy: 0.7540\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.8285 - accuracy: 0.7536 - val_loss: 0.8412 - val_accuracy: 0.7573\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.8176 - accuracy: 0.7574 - val_loss: 0.8358 - val_accuracy: 0.7567\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 0s 675us/step - loss: 0.8067 - accuracy: 0.7607 - val_loss: 0.8290 - val_accuracy: 0.7587\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.7952 - accuracy: 0.7601 - val_loss: 0.8160 - val_accuracy: 0.7647\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.7854 - accuracy: 0.7663 - val_loss: 0.8111 - val_accuracy: 0.7620\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.7781 - accuracy: 0.7680 - val_loss: 0.7913 - val_accuracy: 0.7673\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.7663 - accuracy: 0.7687 - val_loss: 0.7873 - val_accuracy: 0.7707\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.7587 - accuracy: 0.7692 - val_loss: 0.7776 - val_accuracy: 0.7727\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.7507 - accuracy: 0.7701 - val_loss: 0.7816 - val_accuracy: 0.7667\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.7419 - accuracy: 0.7734 - val_loss: 0.7643 - val_accuracy: 0.7767\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.7368 - accuracy: 0.7766 - val_loss: 0.7555 - val_accuracy: 0.7760\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.7273 - accuracy: 0.7763 - val_loss: 0.7481 - val_accuracy: 0.7793\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.7203 - accuracy: 0.7816 - val_loss: 0.7457 - val_accuracy: 0.7800\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.7142 - accuracy: 0.7828 - val_loss: 0.7494 - val_accuracy: 0.7740\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.7087 - accuracy: 0.7828 - val_loss: 0.7335 - val_accuracy: 0.7767\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.7005 - accuracy: 0.7862 - val_loss: 0.7268 - val_accuracy: 0.7813\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 0s 725us/step - loss: 0.6954 - accuracy: 0.7883 - val_loss: 0.7184 - val_accuracy: 0.7887\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.6917 - accuracy: 0.7874 - val_loss: 0.7315 - val_accuracy: 0.7867\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.6850 - accuracy: 0.7884 - val_loss: 0.7187 - val_accuracy: 0.7853\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6801 - accuracy: 0.7897 - val_loss: 0.7219 - val_accuracy: 0.7800\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6747 - accuracy: 0.7895 - val_loss: 0.7091 - val_accuracy: 0.7887\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.6692 - accuracy: 0.7943 - val_loss: 0.7146 - val_accuracy: 0.7940\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.6651 - accuracy: 0.7962 - val_loss: 0.6943 - val_accuracy: 0.7967\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 0s 712us/step - loss: 0.6607 - accuracy: 0.7954 - val_loss: 0.6905 - val_accuracy: 0.8027\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.6556 - accuracy: 0.8001 - val_loss: 0.6813 - val_accuracy: 0.8013\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.6523 - accuracy: 0.8000 - val_loss: 0.6876 - val_accuracy: 0.7960\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.6466 - accuracy: 0.8006 - val_loss: 0.6964 - val_accuracy: 0.7973\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6407 - accuracy: 0.8027 - val_loss: 0.6712 - val_accuracy: 0.7973\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.6379 - accuracy: 0.8040 - val_loss: 0.6760 - val_accuracy: 0.8007\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.6343 - accuracy: 0.8043 - val_loss: 0.6740 - val_accuracy: 0.8027\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.6305 - accuracy: 0.8043 - val_loss: 0.6616 - val_accuracy: 0.8080\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6261 - accuracy: 0.8072 - val_loss: 0.6632 - val_accuracy: 0.8020\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.6225 - accuracy: 0.8082 - val_loss: 0.6616 - val_accuracy: 0.8067\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.6210 - accuracy: 0.8088 - val_loss: 0.6595 - val_accuracy: 0.8087\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 0s 725us/step - loss: 0.6165 - accuracy: 0.8091 - val_loss: 0.6534 - val_accuracy: 0.8007\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.6116 - accuracy: 0.8096 - val_loss: 0.6436 - val_accuracy: 0.8120\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6088 - accuracy: 0.8102 - val_loss: 0.6449 - val_accuracy: 0.8053\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6061 - accuracy: 0.8092 - val_loss: 0.6459 - val_accuracy: 0.8100\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 0s 667us/step - loss: 0.6002 - accuracy: 0.8127 - val_loss: 0.6400 - val_accuracy: 0.8113\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 0s 677us/step - loss: 0.5976 - accuracy: 0.8137 - val_loss: 0.6414 - val_accuracy: 0.8040\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.5982 - accuracy: 0.8142 - val_loss: 0.6414 - val_accuracy: 0.8087\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.5917 - accuracy: 0.8163 - val_loss: 0.6308 - val_accuracy: 0.8107\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 0s 701us/step - loss: 0.5908 - accuracy: 0.8153 - val_loss: 0.6336 - val_accuracy: 0.8080\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.5873 - accuracy: 0.8191 - val_loss: 0.6261 - val_accuracy: 0.8127\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 0s 659us/step - loss: 0.5836 - accuracy: 0.8157 - val_loss: 0.6195 - val_accuracy: 0.8133\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.5801 - accuracy: 0.8188 - val_loss: 0.6297 - val_accuracy: 0.8073\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 0s 715us/step - loss: 0.5763 - accuracy: 0.8223 - val_loss: 0.6216 - val_accuracy: 0.8093\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5740 - accuracy: 0.8227 - val_loss: 0.6233 - val_accuracy: 0.8080\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 0s 616us/step - loss: 0.5713 - accuracy: 0.8222 - val_loss: 0.6178 - val_accuracy: 0.8207\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.5720 - accuracy: 0.8227 - val_loss: 0.6186 - val_accuracy: 0.8180\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.5661 - accuracy: 0.8232 - val_loss: 0.6105 - val_accuracy: 0.8200\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.5649 - accuracy: 0.8229 - val_loss: 0.6068 - val_accuracy: 0.8120\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.5609 - accuracy: 0.8248 - val_loss: 0.6070 - val_accuracy: 0.8173\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.5602 - accuracy: 0.8259 - val_loss: 0.6138 - val_accuracy: 0.8113\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.5570 - accuracy: 0.8268 - val_loss: 0.6159 - val_accuracy: 0.8087\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5543 - accuracy: 0.8273 - val_loss: 0.6117 - val_accuracy: 0.8187\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.5532 - accuracy: 0.8283 - val_loss: 0.6087 - val_accuracy: 0.8200\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.5531 - accuracy: 0.8299 - val_loss: 0.5976 - val_accuracy: 0.8200\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.5479 - accuracy: 0.8282 - val_loss: 0.6000 - val_accuracy: 0.8180\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.5469 - accuracy: 0.8287 - val_loss: 0.6035 - val_accuracy: 0.8133\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.5458 - accuracy: 0.8327 - val_loss: 0.6065 - val_accuracy: 0.8120\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.5451 - accuracy: 0.8294 - val_loss: 0.6005 - val_accuracy: 0.8220\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 0s 715us/step - loss: 0.5418 - accuracy: 0.8320 - val_loss: 0.6043 - val_accuracy: 0.8207\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5392 - accuracy: 0.8317 - val_loss: 0.6140 - val_accuracy: 0.8093\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 0s 713us/step - loss: 0.5398 - accuracy: 0.8316 - val_loss: 0.5950 - val_accuracy: 0.8207\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 0s 700us/step - loss: 0.5385 - accuracy: 0.8294 - val_loss: 0.5947 - val_accuracy: 0.8233\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 0s 743us/step - loss: 0.5332 - accuracy: 0.8327 - val_loss: 0.5981 - val_accuracy: 0.8200\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.5339 - accuracy: 0.8351 - val_loss: 0.6049 - val_accuracy: 0.8187\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 0s 692us/step - loss: 0.5302 - accuracy: 0.8331 - val_loss: 0.5930 - val_accuracy: 0.8213\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 0s 686us/step - loss: 0.5269 - accuracy: 0.8354 - val_loss: 0.5790 - val_accuracy: 0.8273\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.5294 - accuracy: 0.8339 - val_loss: 0.5855 - val_accuracy: 0.8233\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 0s 738us/step - loss: 0.5255 - accuracy: 0.8361 - val_loss: 0.5878 - val_accuracy: 0.8233\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.5274 - accuracy: 0.8350 - val_loss: 0.5839 - val_accuracy: 0.8180\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.5225 - accuracy: 0.8365 - val_loss: 0.6119 - val_accuracy: 0.8127\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5229 - accuracy: 0.8367 - val_loss: 0.5874 - val_accuracy: 0.8233\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5203 - accuracy: 0.8361 - val_loss: 0.5763 - val_accuracy: 0.8273\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 0s 695us/step - loss: 0.5195 - accuracy: 0.8358 - val_loss: 0.5741 - val_accuracy: 0.8267\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.5167 - accuracy: 0.8411 - val_loss: 0.5663 - val_accuracy: 0.8273\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 0s 676us/step - loss: 0.5153 - accuracy: 0.8401 - val_loss: 0.5783 - val_accuracy: 0.8213\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.5131 - accuracy: 0.8403 - val_loss: 0.5752 - val_accuracy: 0.8273\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 0s 689us/step - loss: 0.5137 - accuracy: 0.8391 - val_loss: 0.5734 - val_accuracy: 0.8227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24b27a1feb0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "log_dir = \"logs/tf2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # declare the directory to save logs.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open command line, nevigate to the folder of this tute and run **> tensorboard --logdir \"logs/tf2\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (20640, 8)\n",
      "y data shape: (20640, 1)\n",
      "x-min=-124.35, x-max=39320.0\n",
      "We need to scale the features of this data into [-1,1]\n"
     ]
    }
   ],
   "source": [
    "# We load and process the dataset\n",
    "data_file_name= \"cadata.libsvm\"\n",
    "data_file = os.path.abspath(\"./data/\" + data_file_name)\n",
    "X_data, y_data = load_svmlight_file(data_file)\n",
    "X_data= X_data.toarray()\n",
    "y_data= y_data.reshape(y_data.shape[0],-1)\n",
    "print(\"X data shape: {}\".format(X_data.shape))\n",
    "print(\"y data shape: {}\".format(y_data.shape))\n",
    "print(\"x-min={}, x-max={}\".format(np.min(X_data), np.max(X_data)))\n",
    "print(\"We need to scale the features of this data into [-1,1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-min=-1.0, x-max=1.0\n"
     ]
    }
   ],
   "source": [
    "# We scale the features of this data into [-1,1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_data= MinMaxScaler(feature_range= (-1,1)).fit_transform(X_data)\n",
    "print(\"x-min={}, x-max={}\".format(np.min(X_data), np.max(X_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: y-min =14999.0, y-max =500001.0\n",
      "After scaling: y-min =-0.9999999999999999, y-max =1.0\n",
      "Next step is to split the dataset into train (80%), valid (10%), and test (10%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before scaling: y-min ={}, y-max ={}\".format(np.min(y_data), np.max(y_data)))\n",
    "y_data= MinMaxScaler(feature_range= (-1,1)).fit_transform(y_data)\n",
    "print(\"After scaling: y-min ={}, y-max ={}\".format(np.min(y_data), np.max(y_data)))\n",
    "print(\"Next step is to split the dataset into train (80%), valid (10%), and test (10%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 8) (2064, 8) (2064, 8)\n",
      "(16512,) (2064,) (2064,)\n",
      "Three sets are ready! Next step is to build up a deep neural network.\n"
     ]
    }
   ],
   "source": [
    "# We split train, valid and test data\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = train_valid_test_split(X_data, y_data, train_size=0.8, test_size=0.1)\n",
    "y_train= y_train.reshape(-1)\n",
    "y_test= y_test.reshape(-1)\n",
    "y_valid= y_valid.reshape(-1)\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)\n",
    "print(\"Three sets are ready! Next step is to build up a deep neural network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = Sequential()\n",
    "regression_model.add(Dense(units=1)) # output has only one neuron\n",
    "regression_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "516/516 [==============================] - 0s 503us/step - loss: 1.1897 - val_loss: 0.9961\n",
      "Epoch 2/50\n",
      "516/516 [==============================] - 0s 399us/step - loss: 0.8215 - val_loss: 0.7060\n",
      "Epoch 3/50\n",
      "516/516 [==============================] - 0s 391us/step - loss: 0.5978 - val_loss: 0.5356\n",
      "Epoch 4/50\n",
      "516/516 [==============================] - 0s 392us/step - loss: 0.4707 - val_loss: 0.4409\n",
      "Epoch 5/50\n",
      "516/516 [==============================] - 0s 395us/step - loss: 0.4016 - val_loss: 0.3885\n",
      "Epoch 6/50\n",
      "516/516 [==============================] - 0s 392us/step - loss: 0.3617 - val_loss: 0.3550\n",
      "Epoch 7/50\n",
      "516/516 [==============================] - 0s 395us/step - loss: 0.3342 - val_loss: 0.3292\n",
      "Epoch 8/50\n",
      "516/516 [==============================] - 0s 383us/step - loss: 0.3118 - val_loss: 0.3070\n",
      "Epoch 9/50\n",
      "516/516 [==============================] - 0s 383us/step - loss: 0.2923 - val_loss: 0.2875\n",
      "Epoch 10/50\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.2753 - val_loss: 0.2705\n",
      "Epoch 11/50\n",
      "516/516 [==============================] - 0s 407us/step - loss: 0.2602 - val_loss: 0.2556\n",
      "Epoch 12/50\n",
      "516/516 [==============================] - 0s 382us/step - loss: 0.2470 - val_loss: 0.2423\n",
      "Epoch 13/50\n",
      "516/516 [==============================] - 0s 399us/step - loss: 0.2352 - val_loss: 0.2304\n",
      "Epoch 14/50\n",
      "516/516 [==============================] - 0s 395us/step - loss: 0.2245 - val_loss: 0.2197\n",
      "Epoch 15/50\n",
      "516/516 [==============================] - 0s 391us/step - loss: 0.2147 - val_loss: 0.2099\n",
      "Epoch 16/50\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.2056 - val_loss: 0.2009\n",
      "Epoch 17/50\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.1971 - val_loss: 0.1923\n",
      "Epoch 18/50\n",
      "516/516 [==============================] - 0s 392us/step - loss: 0.1891 - val_loss: 0.1843\n",
      "Epoch 19/50\n",
      "516/516 [==============================] - 0s 396us/step - loss: 0.1815 - val_loss: 0.1768\n",
      "Epoch 20/50\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.1744 - val_loss: 0.1698\n",
      "Epoch 21/50\n",
      "516/516 [==============================] - 0s 388us/step - loss: 0.1677 - val_loss: 0.1631\n",
      "Epoch 22/50\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.1613 - val_loss: 0.1570\n",
      "Epoch 23/50\n",
      "516/516 [==============================] - 0s 406us/step - loss: 0.1553 - val_loss: 0.1510\n",
      "Epoch 24/50\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.1497 - val_loss: 0.1456\n",
      "Epoch 25/50\n",
      "516/516 [==============================] - 0s 390us/step - loss: 0.1444 - val_loss: 0.1404\n",
      "Epoch 26/50\n",
      "516/516 [==============================] - 0s 420us/step - loss: 0.1394 - val_loss: 0.1355\n",
      "Epoch 27/50\n",
      "516/516 [==============================] - 0s 412us/step - loss: 0.1347 - val_loss: 0.1311\n",
      "Epoch 28/50\n",
      "516/516 [==============================] - 0s 402us/step - loss: 0.1304 - val_loss: 0.1269\n",
      "Epoch 29/50\n",
      "516/516 [==============================] - 0s 396us/step - loss: 0.1263 - val_loss: 0.1231\n",
      "Epoch 30/50\n",
      "516/516 [==============================] - 0s 395us/step - loss: 0.1226 - val_loss: 0.1196\n",
      "Epoch 31/50\n",
      "516/516 [==============================] - 0s 393us/step - loss: 0.1191 - val_loss: 0.1163\n",
      "Epoch 32/50\n",
      "516/516 [==============================] - 0s 378us/step - loss: 0.1160 - val_loss: 0.1134\n",
      "Epoch 33/50\n",
      "516/516 [==============================] - 0s 400us/step - loss: 0.1131 - val_loss: 0.1107\n",
      "Epoch 34/50\n",
      "516/516 [==============================] - 0s 404us/step - loss: 0.1104 - val_loss: 0.1084\n",
      "Epoch 35/50\n",
      "516/516 [==============================] - 0s 385us/step - loss: 0.1081 - val_loss: 0.1062\n",
      "Epoch 36/50\n",
      "516/516 [==============================] - 0s 389us/step - loss: 0.1059 - val_loss: 0.1043\n",
      "Epoch 37/50\n",
      "516/516 [==============================] - 0s 394us/step - loss: 0.1040 - val_loss: 0.1027\n",
      "Epoch 38/50\n",
      "516/516 [==============================] - 0s 383us/step - loss: 0.1023 - val_loss: 0.1012\n",
      "Epoch 39/50\n",
      "516/516 [==============================] - 0s 380us/step - loss: 0.1009 - val_loss: 0.1000\n",
      "Epoch 40/50\n",
      "516/516 [==============================] - 0s 387us/step - loss: 0.0996 - val_loss: 0.0990\n",
      "Epoch 41/50\n",
      "516/516 [==============================] - 0s 388us/step - loss: 0.0984 - val_loss: 0.0980\n",
      "Epoch 42/50\n",
      "516/516 [==============================] - 0s 389us/step - loss: 0.0974 - val_loss: 0.0972\n",
      "Epoch 43/50\n",
      "516/516 [==============================] - 0s 376us/step - loss: 0.0966 - val_loss: 0.0965\n",
      "Epoch 44/50\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.0958 - val_loss: 0.0959\n",
      "Epoch 45/50\n",
      "516/516 [==============================] - 0s 408us/step - loss: 0.0952 - val_loss: 0.0955\n",
      "Epoch 46/50\n",
      "516/516 [==============================] - 0s 389us/step - loss: 0.0946 - val_loss: 0.0951\n",
      "Epoch 47/50\n",
      "516/516 [==============================] - 0s 393us/step - loss: 0.0942 - val_loss: 0.0948\n",
      "Epoch 48/50\n",
      "516/516 [==============================] - 0s 401us/step - loss: 0.0938 - val_loss: 0.0945\n",
      "Epoch 49/50\n",
      "516/516 [==============================] - 0s 403us/step - loss: 0.0935 - val_loss: 0.0943\n",
      "Epoch 50/50\n",
      "516/516 [==============================] - 0s 390us/step - loss: 0.0932 - val_loss: 0.0941\n"
     ]
    }
   ],
   "source": [
    "history = regression_model.fit(x= X_train, y= y_train, batch_size= 32, epochs= 50, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses during training\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate our regression model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 372us/step - loss: 0.0942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0941537469625473"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.evaluate(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the problem in this tutorial, however, using a much deeper network (i.e., $16 \\rightarrow 100 (ReLU) \\rightarrow 200 (ReLU) \\rightarrow 200 (ReLU) \\rightarrow 100 (ReLu) \\rightarrow 26$). Applying callback methods to save the model on training and writing a TensorBoard. Visualize `training loss`, `training accuracy`, `valid loss`, and `valid accuracy`. Provide observation and explanation of any issue if happen (hint, overfitting issue). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a new model with much more parameters \n",
    "X = tf.keras.layers.Input(shape=(16,)) #declare input layer\n",
    "h = Dense(units=1000, activation= 'relu')(X)\n",
    "h = Dense(units=2000, activation= 'relu')(h)\n",
    "h = Dense(units=2000, activation= 'relu')(h)\n",
    "h = Dense(units=1000, activation= 'relu')(h)\n",
    "h = Dense(units=26, activation= 'softmax')(h)\n",
    "dnn_model = tf.keras.Model(inputs= X, outputs=h)\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# Declare a callback for writing a TensorBoard \n",
    "logdir = \"tf_logs/\"\n",
    "\n",
    "# Init a tensorboard_callback \n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 1.0179 - accuracy: 0.6851\n",
      "Epoch 00001: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 1.0179 - accuracy: 0.6851 - val_loss: 0.5464 - val_accuracy: 0.8280\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8552\n",
      "Epoch 00002: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 18s 48ms/step - loss: 0.4501 - accuracy: 0.8552 - val_loss: 0.3642 - val_accuracy: 0.8793\n",
      "Epoch 3/20\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.2937 - accuracy: 0.9042\n",
      "Epoch 00003: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.2933 - accuracy: 0.9043 - val_loss: 0.3454 - val_accuracy: 0.8827\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.9247\n",
      "Epoch 00004: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.2291 - accuracy: 0.9247 - val_loss: 0.2873 - val_accuracy: 0.9113\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.9403\n",
      "Epoch 00005: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 18s 49ms/step - loss: 0.1791 - accuracy: 0.9403 - val_loss: 0.2567 - val_accuracy: 0.9240\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9457\n",
      "Epoch 00006: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.1601 - accuracy: 0.9457 - val_loss: 0.2174 - val_accuracy: 0.9387\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.9503\n",
      "Epoch 00007: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.1553 - accuracy: 0.9503 - val_loss: 0.2020 - val_accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 0.9554\n",
      "Epoch 00008: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.1263 - accuracy: 0.9555 - val_loss: 0.2200 - val_accuracy: 0.9327\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9675\n",
      "Epoch 00009: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.0974 - accuracy: 0.9675 - val_loss: 0.3147 - val_accuracy: 0.9233\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9679\n",
      "Epoch 00010: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.1041 - accuracy: 0.9679 - val_loss: 0.2195 - val_accuracy: 0.9373\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9709\n",
      "Epoch 00011: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0940 - accuracy: 0.9709 - val_loss: 0.2214 - val_accuracy: 0.9360\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9699\n",
      "Epoch 00012: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 52ms/step - loss: 0.1010 - accuracy: 0.9699 - val_loss: 0.1966 - val_accuracy: 0.9480\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9694\n",
      "Epoch 00013: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.0946 - accuracy: 0.9694 - val_loss: 0.2626 - val_accuracy: 0.9413\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9688\n",
      "Epoch 00014: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.1050 - accuracy: 0.9688 - val_loss: 0.1882 - val_accuracy: 0.9460\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9788\n",
      "Epoch 00015: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 20s 53ms/step - loss: 0.0657 - accuracy: 0.9788 - val_loss: 0.1962 - val_accuracy: 0.9473\n",
      "Epoch 16/20\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9807\n",
      "Epoch 00016: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.0647 - accuracy: 0.9806 - val_loss: 0.1920 - val_accuracy: 0.9520\n",
      "Epoch 17/20\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9742\n",
      "Epoch 00017: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 0.2810 - val_accuracy: 0.9267\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9782\n",
      "Epoch 00018: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 51ms/step - loss: 0.0753 - accuracy: 0.9782 - val_loss: 0.1868 - val_accuracy: 0.9513\n",
      "Epoch 19/20\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9831\n",
      "Epoch 00019: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.2388 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9772\n",
      "Epoch 00020: saving model to models/cp_deeper.ckpt\n",
      "375/375 [==============================] - 19s 50ms/step - loss: 0.0785 - accuracy: 0.9772 - val_loss: 0.2159 - val_accuracy: 0.9480\n"
     ]
    }
   ],
   "source": [
    "# Create a tf.keras.callbacks.ModelCheckpoint callback that saves weights only during training\n",
    "checkpoint_path = \"models/cp_deeper.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "history = dnn_model.fit(x=X_train, y=y_train, batch_size=32, \n",
    "                        epochs=20, \n",
    "                        validation_data=(X_valid, y_valid), \n",
    "                       callbacks=[tensorboard_callback, # Callback for writing log \n",
    "                                 cp_callback]) # Callback for saving model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate the trained model on the testing set or any subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2093 - accuracy: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20930108428001404, 0.9506666660308838]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(X_test, y_test)  #return loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the TensorBoard notebook extension.\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAEvCAYAAADhOnPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3iUxRbA4d+QBAgJvfcaeuhgu3QFCzYE6QIKXCwI6EUQFFEUEcEKgoiAFC8ognoBUVCKolTpHamhhx5CSJv7x8kmIaRswm425bzP8z3J7ld2loTs+WbOnDHWWpRSSiml3C2HpxuglFJKqexBgw6llFJKpQsNOpRSSimVLjToUEoppVS60KBDKaWUUulCgw6llFJKpQtvTzcgtXLkyGF9fX093QyllFIq3YSGhlprbabvKMh0QYevry/Xrl3zdDOUUkqpdGOMue7pNrhCpo+alFJKKZU5aNChlFJKqXShQYdSSiml0kWmy+lQSinlOhEREQQFBREWFubppiggd+7clClTBh8fH083xS006FBKqWwsKCiIvHnzUqFCBYwxnm5Otmat5fz58wQFBVGxYkVPN8ctdHhFKaWysbCwMAoXLqwBRwZgjKFw4cJZutdJgw6llMrmNODIOLL6z0KDDqWUUh7l7+/v6SaodKJBh1JKKaXShQYdSimlMgRrLUOGDKF27doEBgYyf/58AE6dOkWzZs2oV68etWvX5vfffycqKopevXrFHvvhhx+m5oXg0CHYvNlN70QlJVvPXjl6FF59FQYOhDvu8HRrlFIqe1u4cCFbt25l27ZtBAcH07hxY5o1a8bXX39N27ZtGTFiBFFRUYSGhrJ161ZOnDjBzp07Abh06VLyF1+yBFauhL//hi1b4NIlqFsXtm6V/V27gr8/3HMP3H03VKkCWTy/whPcFnQYw3SgHXDWWmonst8AHwMPAqFAL2v5213tSYyPD/z3v/I7pkGHUipbCAuDixfhwgW4dAnv69ehRo3Y3S1a3HrKk0/Cc89BaCg8+OCt+3v1ki04GDp0uHnfqlXON+2PP/6gS5cueHl5Ubx4cZo3b87GjRtp3LgxTz/9NBERETz22GPUq1ePSpUqcejQIQYMGMBDDz1EmzZtIDwcdu+WwOLvv+HwYVi8WIKHuXNh4UIJNDp1ggYNoFEjeWFr4do1+Okn+OILea5YMXj5ZXjlFXkcHg45czr/ZlSi3NnTMROYCMxKYv8DQEDMdgcwOeZruilZEvz84MCB9HxVpZS6TZGRcqfuCB4KFoSqVSEiAt57T567eDFuf5cu8OyzcPq0/OGLJwDg3Xdh2DAIC6P09SBO5K7skbt8a22izzdr1ow1a9awZMkSevTowZAhQ3iqQwd2fPEFy86eZdKkSVx+/XU6bd8uwQFIr0X9+hJM+PvDxInw1Vdyt5mQMfDDDxAdDXv2wNq1shUvLvtPn4YKFSRIcfSE3H03FC3qnn+ILMwk9UN2ycUNFYDFSfR0fA6sspb/xjzeB7SwllPJXdPPz8+6cpXZ+vXl/+DSpS67pFJKuc6pU3DiRNxdeYkScObMzcf07QtTp8qHpo8P+PpCoUISjBQsCN27Q58+8oE8frw8V6gQ5M/P6T/+oESHDlCvHvz6K9x7L5QqBc2by9asGVSv7tYgxN/fn5CQEBYuXMjnn3/O0qVLuXDhAo0aNWL9+vXcuHGD0pGReP/wA3u+/poChw9T4tIlTHQ0bN7M1hw5+OyJJ5jaoYP0YDRoAJUrQw4XpS2ePAkffCCByObNEtwBfPMNdOwI58/D2bMu+3fas2cPNeL1PgEYY0KttX63fXEP82ROR2ngeLzHQTHPJRt0uFrVqtILp5RSGUZkpNwJffml5CLUqgXbtsm+vn3B2/vmoKJyZdmXI4cMnyRVQjtnThg+/KanLpYvTwnHB1ytWjBlioyJrFol488AGzdK0HPwoIyx1K7tug90h/BwHq9YkWs5c/JZyZJUDA9nS+HCFNq6la/OnOH3N95g2tGjFM6ZE/9//YszVaowbvlyNvTsSYiXF+9OnAgPPODaNjmUKiXBGsD167BpE/z5Z9y4/MKF0K+f/EzuvluSBe++2z1tyeQ8GXQkFg4m2u1iDP2AfuD6IbU6deT/UXS06/8PKaVUqk2fDq+9Jj0cxYvDf/4DTz8dt3/06OTPv501O0qUgH//WzZr5Y/jmjXSCwLwySfw6afy4dq0aVxvSP36zt3hR0fD8eOwb59s+/fDffcREhICe/diGjSgh+PYcuUkmPL2pmfPnvTs1AmuXKFYsWIA5AE+SPs7TTtfX3nvTZvGPffAAxIgrl0rwYhjiEfdwpNBRxBQNt7jMsDJxA60lqnAVAA/v8QDk7QaMUI2pZTyiNBQ+O47aNtWkhd9faVX4ZlnJGvTUwt/GQMBAbI5DBkCDRvC6tWy/fCDBConY/50L10KRYrIzI+DByWwKF4c2rSRHoIiReT9OuTLJ8EFSIAxfz5UqyavmSfPze3JnVu2jKhMGQkM4weHKlGezOl4CHgBmb1yB/CJtTRJ6ZquzulQSql0Z62M606bBl9/DVeuwGefSbJnOkssf8BpQUFw5Aj861/yuGJFeRzf44/L8APAqFEyVFGtmmzFi+u01ERoTkcaGMN/gRZAEWMIAt4AfACsZQqwFAk4DiJTZnu7qy3JuX5dgvCePSXPSiml3OrGDbjrLqkVkTu3zDHt00cSNjObMmVkc/jzT/j9dzh2THo7qlWLyzcBCTpUtua2oMNauqSw3wLPu+v1neXrC7t2SUKyBh1K3QZrJYnR11ceHzggz+XJE7flypX97myjoyUp8++/JT8jVy4JMPr2lamsBQp4uoWuU7KkFPVQKgnZuiKpQ9WqWqtDqRSFh0v1p1Kl5PH06bB+vdzVOrZatWDdOtnfqZPczcfXooVUhXR8f+bMzUFJs2ZxSVavvy6zOBz7fH2liFXLlrL/u+8kgPHxkS1nTihbVvIBrIUdO2SWh2O/j4/kEOTNK/vDw+U5d2WQnzgBM2fKv9OhQ1C4MPTvLzUjPvrIPa+pVAanQQfyN2r1ak+3QikPshbOnZOEQMdMhenTpUKjI6A4c0buZE+ckP0//gh//SWJgNWqwX33SdDhMG6c1C4IDY3bSpeO29+woeQEOPZduSIFrxxmz5YZHPFnAvTsGRd0dOkSVy/B4YUXZHZFeLhUnkxo2DAphHXhgiQ1Anh5ScCSMye88QYMHizvsVUrec4R0OTMCYMGQfv28u/x8stxzzuO69FDplHOmwfdukkvR8uW8NZbcp6jF0ipbEqDDqSnY84cye/QvwkqQzp+XGYG3LghH7ZFi0qtgKVL5YM3MjJuGzFCPlCXLpXiRfH3RUZKVcb8+WWK31dfSbXFY8fk2sbIVx8fqcy4Y4cEFQ89JF/Ll49r03ffyQd2Uu69N/n3NGFC8vsdCYmRkfKf8/r1m+fMb90q7z08XL5GRMRV2/T2hgUL5FzHvoiIuEAkd254552bzw0Pl/oTjvMbNJDnHFtERFyvSGiojMs6znNsTZtK0NG0qQQ4Tz99c06DUtmcW2evuIM7Zq/89BNMmiSJ5CVKuPTSSt2e3bulx2DuXPkABckNqF8fJk+WBTEgbvjA21v2V64s+8eOjXvesa1YIUHJl19KtF2smAQUju2BB3SNiWzktmaveICjemlijhw5Qrt27WIXgcussvLsFQ06lMqoDhyQbjhfX8lyfu456eHIn1+Ch6go6ZnQqnbqNmjQkfFk5aBD/1rFk8niL5XVWCslrx3DDgEB0htx7JhUgqxeXZIRvWNGRb28NOBQmd7QoUP57LPPYh+PGjWKN998k9atW9OgQQMCAwP54YcfUn3dsLAwevfuTWBgIPXr12dlTALzrl27aNKkCfXq1aNOnTocOHCAa9eu8dBDD1G3bl1q167N/PnzXfb+1M00pyPGnXdCYGDcqsZKpZuICEk8HDcOdu6U+gYDBsgQh1Y4VOlo0CBJlXGlevWSn6zTuXNnBg0axHMxQ4XffPMNy5YtY/DgweTLl4/g4GDuvPNOHnnkEUwqpltPmjQJgB07drB3717atGnD/v37mTJlCgMHDqRbt26Eh4cTFRXF0qVLKVWqFEuWLAHg8uXLaX/DKll6mxQjVy7Yu9fTrVDZzqpVEmQ89ZQ8njVL8jg0p0JlE/Xr1+fs2bOcPHmSbdu2UbBgQUqWLMnw4cOpU6cO9957LydOnOBMwpV1U/DHH3/Qo4es5FK9enXKly/P/v37ueuuuxgzZgzvvfceR48exdfXl8DAQFasWMHQoUP5/fffyZ8/vzveqkJ7OmIFBMDixZ5uhcoWgoNlemilSjIbpGJFKYH94IPZr3CWylA8VT6kQ4cOLFiwgNOnT9O5c2fmzp3LuXPn2Lx5Mz4+PlSoUIGwsLBUXTOpfMWuXbtyxx13sGTJEtq2bcu0adNo1aoVmzdvZunSpbz66qu0adOGkSNHuuKtqQS0pyNG1apShuDKFU+3RGVZR4/Ciy9KoDFggDxXsaL0djz0kAYcKtvq3Lkz8+bNY8GCBXTo0IHLly9TrFgxfHx8WLlyJUePHk31NZs1a8bcuXMB2L9/P8eOHaNatWocOnSISpUq8eKLL/LII4+wfft2Tp48SZ48eejevTv/+c9/+Pvvv139FlUM7emIUbWqfD1wQGoWKeUyO3fCe+/Bf/8rgUX37rJap1IKgFq1anH16lVKly5NyZIl6datGw8//DCNGjWiXr16VK9ePdXXfO655+jfvz+BgYF4e3szc+ZMcuXKxfz585kzZw4+Pj6UKFGCkSNHsnHjRoYMGUKOHDnw8fFh8uTJbniXCnTKbKzDh+VzYdAgmSSg1G1x/L8yBkaPll+ufv2k2mXZsp5tm1LxZLYps9lBVp4yq0GHUq4SGSnZyBs2SKW5QYNk8asrV2RfoUKebqFSt9CgI+PJykGHDq/EExUFFy/GLcmgVJKio2WdkEKFJKBo1UqWKg4Nlf0VKsSVCM+Xz2PNVCor2rFjR+zMFIdcuXKxfv16D7VIOUuDjnjatYPz5+VGVambHD4svxibNsm2ebOsr7FkiRTrKlNG1upo1Ei2qlW1cJdSbhIYGMhWVxcUyeyMuR/4GPACpmHt2AT7CwLTgcpAGPA01u6M2XcEuApEAZFY28hdzdSgI55KlWTRTGt1IkG2Za0srrZpk6w06phl0qsXrFkj9TPq1ZPVRJs3jzvv66890lylUi06Gv75B7Zvh9278a1SBTLD8Ir+YU6aMV7AJOA+IAjYiDE/Yu3ueEcNB7Zi7eMYUz3m+Nbx9rfE2mB3N1WDjniqVoXLl6WMQtGinm6Ncrv4yZ7ffAMzZ0qwce6cPJ8nD/TvLwumvfeeVJCrVUsLd6nM49IlWSl4+3bYtk2+7tgRNwwIlMuZU9bzefBBDzY0BcuWQdeustJw3rxxW758aX+cO3dWCmKaAAex9hAAxswDHgXiBx01gXcBsHYvxlTAmOJYm7qqa7dJg454AgLk6/79GnRkOSEhcX9wd+6Ur46tVCnp3Th+XOplNG4sQyR16kjAAVInX6mMKioKDh68ObjYvl1qwzgUKgR160LfvvK1Th0oWZIbbdrg+/jjsGABPPyw595DUhYtgk6doGZNaNMGrl6V5OyrV2U7fVpqHTgeOzvRwMtLgpACBSSRL7mtcOG4r94Z8mOzNHA83uMg4I4Ex2wD2gN/YEwToDxQBjgDWOAXjLHA51g71V0NzXSzV8qWLWtnz57tlmvfuCGfRxUqyO+WynxMRAR5jh3D79Ah/I4c4fT993O9bFmK//ILNd6VID/S15drFStyrWJFjvbowY3ixT3capUSExWF3+HDhJYrR3Q272nyvnoVv3/+wf/QIfz/+Ud+1w8fxuvGDQBsjhyElitHSKVKhFSpwrVKlQipVInwIkUSvbOPDA6myeuv43/wILtHjiS4adP0fktJKrZiBTXefZcrNWqwY+xYIv39Uz4pKgqv69fxvn4dr9BQvK5di/s+NBTvmK+O771DQvC5fPmmzSuZ6qcR/v5E5M+f6BaZL1/s91eqV8c6blpSKSwsjNy5c9/0XMeWLcPPwY54T02NDQ6M6Qi0xdo+MY97AE2wdkDs0cbkQ3I+6iPXqQ70wdptGFMKa09iTDFgOTAAa9ekqfEpyHRBhzunzEZGSi/6ww/LTYDKwKKj5S7O1xdKlIBdu+RuaN8++UGC3JHMnw/t28OpUzJ0EhgoFUGzTrdq1hYaKivtTpggP+9cueCee2S2UKtW0iOVxj/sHhUeHndnHv+uPannrlyBCxfk9/x4vBvaIkXiei0cX2vUkKEDJ+3Zs4capUrBAw/Axo1SxK5DBze86VSaNk1q2zRvDv/7HzgTcCQjMjISb2d7Ka5fl1kFwcFxXxPbHPvOnYOEgcrFi9KLkgapnjJrzF3AKKxtG/P4VQCsfTeJ4w1wGKiDtVcS7BsFhGDt+DQ1PgUadKjMITRUlgB2DI3s2iVDJm+/DSNGyH/6Z56RoKJ2bflatarmX2RW58/DpEnwySfy/d13SzLvnj3w228yhAAyNt+sWVwQUqeOZ2YNWQvHjsUNaxw+nHwAER7u3HVz547LQShQQAKK+AFGiRK3HUDHfsBdvSp5HX/9BXPmQOfOt3Xd1Hjsscc4fvw4YWFhDBw4kH5hYTBwIGvz5mVw+fLkLVaMX3/9lZCQEAYMGMCmTZswxvDGG2/wxBNP4O/vT0hICAALFixg8eLFzJw5k169elGoUCG2bNlCgwYN6NSpE4MGDeL69ev4+voyY8YMqlWrRlRUFEOHDuXnn3/GGEPfvn2pWbMmEydOZNGiRQAsX76cyZMns3DhwsTfRGjozQHJffel+WeThqDDG9iPJIaeADYCXbF2V7xjCgChWBuOMX2Bplj7FMb4ATmw9mrM98uBt7B2WZoan4IMOTjlScHBcOSI3EApD4iMlIBiwwa56woIkJLhPj7w6qvg5ycBRe/e8rVZMzmvaFH48UfPtl3dvmPH4IMPJMAMDZUcm2HD4F//uvm4c+dkzZrffpMtZklyCheGli0lAGndWn5/XN2rde2aBL8J8yfiL4deooQkZzoChgoVUp/0mDdv+vbi5M0LP/0k07+7dIE33wTH0OOTT8Jzz8nPJLGE0169ZAsOvrWXZNWqFF96+vTpFCpUiOvXrzOlQgU4e5afcuem+oYNbKhenQsXLgAwevRo8ufPz44dMspw8eLFFK+9f/9+VqxYgZeXF1euXGHNmjV4e3uzYsUKhg8fznfffcfUqVM5fPgwW7ZswdvbmwsXLlCwYEGef/55zp07R9GiRZkxYwa9e/dO+oXy5IFy5WRLb9ZGYswLwM/IlNnpWLsLY/rH7J8C1ABmYUwUkmD6TMzZxYFFMf9PvIGv3RVwOF5AxTNmDHz+uQT9WmbBzayVu1hHNbYnn5Slfq9fl8cFC0LPnvK9jw8EBclzOjSS9ezaBePGxU097tIFXnlFeq0SU7QodOwoG8iQw8qVEoD8+qskRQKULh3XC9K6depK0FsrdyCOoMIRYBw8GDfzKW9e6XHo2jWuB6J2bXk+M/L3l2B+506prmutBFBu9sknn7Bo4UKeP3OGwWfPsqNOHb6uWZPZMWtSFIqp5rtixQrmzZsXe17BggVTvHbHjh3xiinUd/nyZXr27MmBAwcwxhARERF73f79+8cOvzher0ePHsyZM4fevXvz119/MWvWLNe9aVezdimwNMFzU+J9/xcQkMh5h4C67m1cHA06EggIkGD+5EkJ+JULBQdLD0b8LW9e6YoG+cfv1w+aNJGtcuWbAwwtI571/PGHJFItXix3is8/Dy+9lPq7xbJl4amnZLNW6lD8+qsEIT/9BI7k8ypV4oKQli2hWDF5PiTk1qml27fL3QfI72HlyhJUdO8eF2CUL5/17k5+/13+CD72GKxYIT2Nz8TcFOfJk3zPRZEiTvVsxLdq1SpWLF/OpubN8Zk4kcUlShA9ahT2u+9uOdZaG5OOcLP4z4UlyK3w84sbkXj99ddp2bIlixYt4siRI7Ro0SLZ6/bu3ZuHH36Y3Llz07FjR+dzQlSS9F8wgfirzWrQcRtCQuDvvyV5c+BAmZ722mvSjWSM1Lt49FGZnuoo+vPOO55utUoP0dEyHPLee7B2rQyJjBoFL7zgmmljxkhwUaUK/Pvf8nq7dsX1gsybB1NjZgTWqiUJgP/8E3d+/vwSVDz1VFxwUavWbScyZip58shw5eOPQ58+Muz573+75aUuX7zIiKAgfP78kws9etBh/nxmR0ayevVqDh8+TMWKFblw4QKFChWiTZs2TJw4kY8++giQ4ZWCBQtSvHhx9uzZQ7Vq1Vi0aBF5k+hpunz5MqVLlwZg5syZsc+3adOGKVOm0KJFi9jhlUKFClGqVClKlSrF22+/zfLly93y/rMbDToSiF+ro2VLz7YlU9qxQ1ZSXblS/tiDjAFXry53sV27Srnw7PQHXImICJkZMW6cBAHly0ui6NNPS66Ou+TIIUMGgYESAEdGSkD822+werX0tvXqFZecWa6cDuGBJLF+/z088YQUyYuMlP/DrhQZSbsFC/A6doxpRYvyc2god951F0WLFmXq1Km0b9+e6OhoihUrxvLly3nttdd4/vnnqV27Nl5eXrzxxhu0b9+esWPH0q5dO8qWLUvt2rVjk0oTeuWVV+jZsycffPABrVq1in2+T58+7N+/nzp16uDj40Pfvn154YUXAOjWrRvnzp2jZs2arn3v2ZTOXkkgOlr+/j3/PIx3y4ShLGzDBpllUKCA/JG66y7pyXB0Yd+OrVulq7dqVflw0A+GzCMkRKY/fvCB5F4EBkq+RqdOmXO6axaT4iqzN27Iz+qHH+CjjyRwc4XwcLkJ+e67uFloGdALL7xA/fr1ecYxxJQOdJXZbCRHDrkZq1bN0y3JJKyFQ4dkvLtRI/nj0bev66qrnT4twzLTp8cl70FcF7hjcyTwufOOOauJjJT6B1evJj2bwt8/7TkLwcHw6acwcaLUmGjWDKZMkXoQGjBmHrlyyTIBXbrAoEHye/Pyy7d3zbAwmeWyZAl8+KFcNwNq2LAhfn5+TJgwwdNNyTK0p0Ol3Z49Mg6/ebOMR7miR8MhLEzuqt55R+60XnxR/jAdP+5csl/8YKRCBf2Qi89aCTaGDZOfYUr8/FKe4plw3++/S+/G9euSkDh0qJaSz6BS7OlwiIiQJNpvvoGxY+VnmhYhIZLPtXKlBKH9+qXtOlmY9nRkM8eOyd/MTp0yapl9D7t2DUaPlu5yPz94913X9WxYK9MdX3lFpis+9pjkADiSbcqUkWGb+Mc7pjXGD0QWLrx1WmPCXpHMOq3xdqxbJ7MR/vhDhqoWLJBVcxMrZJXU91evyn+S+PtiSnDH8vGRD6ghQzLHCqYqZT4+MHeu/FEcNkyCkNdeS901Ll+WHK9162DWLPkdUdmKfqQmYsUKmSF2112y3L2K5+JF+ZA6dkyS7957z3U9HJs3S2/GH39IcPDrrzK1MTnGQMWKsj36aNzzISGSrBg/GPn6a5g8Oe6YSpUkv6BYscQLMyV1Z58rV+brOdm/X4qrLVwoBZ8mT5ZfclflVERE3ByEFCsWV1hKZR3e3hIseHnB66/LUMsbbzj3/+H8eWjbVv4vfvONJKiqbEeDjkTEn8GiQUeMS5ckQdRRsKtNm1urRKbVyZMwfDh89ZV8WE2dKjMaYgr6pIm/P9xxh2wOCUtVb9smRZDWrZMPy3jLfSfL2zvpCpKO52rVkjFrT9cWOXNGKktOnSrr1Lz5ptTBcPXsIR8fea+efr/K/by8YMYM+X/w5puywu1bbyUfeJw+LWXBDxyQGTGJVTVV2YIGHYmIX6vj/vs92xaPu35dhk8++EDWZAgMlD8wrrr2hAkyPhwRIWPEw4fLB7c7GCPTNMuXT3wJ76go6SFJbK2MlBbkunRJ8k0c+65cgQEDpIx3jx7yRzZXLve8r8RcvSr/tuPHy9BH//5yZ6q9D8oVvLwkZ8fbW5LHIyLk70Rigcfx43DvvVJReMkSqQyrsi0NOhJRrJjcrO7f7+mWeNjixZLAefiwTG1zlCu/XdZKgaahQ+UP0hNPSN6Gp7uVvLxkVkz+/Ld3HWtliu/s2TKks2iR9BB16iRj2Hff7b7hmYgIWbfkzTfh7FnpbRkzJq77TilXyZFDEkG9vWWYNTIS3n//5t/tQ4dkiPTiRfjlF1khWGVv1tpMteXJk8emh4YNrW3TJl1eKuOJjra2Y0drwdoaNaz97TfXXXvdOmvvukuuXb++tatWue7aGVFEhLXLllnbrZu1efLI+65UydqRI63dv991rxMdbe2331obECCv0ayZ/FsrlYLdu3ff3gWio60dMEB+7wYOlMfWWrtnj7WlSllbqJC1mzbdfkNj+Pn5uexaGVViPxPgms0An8G3u2lPRxK++kpuTrOVyEi5azFGZng0aiSJna5YHj4oSBIZ58yRBaSmT5cy07eTt5EZeHtL8lzbtjLksWiR/Bu8/bYMU91xhwy/dOqU9p6kNWtkts/69ZJL8r//ybBOZkt2VZmTMfDxx/K7/uGH8nekTx/J+8qRQ9ZiCQz0dCtdLjIyUtdiSQOt06HE8uVSc+Pjj12byHLtmnS5jhsn5V7/8x8ZVsmO01XjO3lShl7mzJGEVm9vKZrVo4fkm+TOnfI1du2SqYuLF8tqqm+9JUm+WT2QUy51U02IQYNkaDAtHIUCg4IkEMmZU2ah3X231NxJwtChQylfvjzPPfccAKNGjcIYw5o1a7h48SIRERG8/fbbPBozO83f3z/JMuchISE8+uijiZ43a9Ysxo8fjzGGOnXqMHv2bM6cOUP//v05dOgQAJMnT6ZUqVK0a9eOnTt3AjB+/HhCQkIYNWoULVq04O6772bt2rU88sgjVK1albfffpvw8HAKFy7M3LlzKV68OCEhIQwYMIBNmzZhjOGNN97g0qVL7Ny5kw8//BCAL774gj179vDBBx/c8j60Tkc2dPy4fCZ065bFF34LCpLZDN9+K+P+vr6uuW50tMzpf/VVOHFC7uTHjpVCXQpKlZIA7D//kfVqZs+Wf6///e0QaskAACAASURBVE8SaTt2lACkadNbK4KeOCHTFGfMkFkoY8ZIaeo8eTzzXpQCCTQqVZKg98IFqFnTqeC5c+fODBo0KDbo+Oabb1i2bBmDBw8mX758BAcHc+edd/LII48kuhJsfLlz52bRokW3nLd7927eeecd1q5dS5EiRbhw4QIAL774Is2bN2fRokVERUUREhLCxYsXk32NS5cusXr1akAWnFu3bh3GGKZNm8a4ceOYMGECo0ePJn/+/OzYsSP2uJw5c1KnTh3GjRuHj48PM2bM4PPPP0/x3yer0aAjCadPy01k9epZOOj49luZmhoZKcW+hgxxzQyLP/6QQGbjRll7Zf58TSBLTmCg9AS9+65UaZwzR/7NvvxS1pjp1k0CkFKlJGHvo4/kZ/bii7JehasSfJVKpkfCXerXr8/Zs2c5efIk586do2DBgpQsWZLBgwezZs0acuTIwYkTJzhz5gwlSpRI9lrWWoYPH37Leb/99hsdOnSgSMz/lUIxU7t/++03Zs2aBYCXlxf58+dPMejo1KlT7PdBQUF06tSJU6dOER4eTsWKFQFYsWIF8+bNiz2uYMxYfatWrVi8eDE1atQgIiKCwCw47JQSDTqSEL9WR5Z15Yp0f86ZI8W1btfq1dLF/9tv8gE5a5Z8YKZ17Y7sxstLphbeey9MmiQLbM2ZExeQ+PrKNOOuXSUnxBU/M6UygA4dOrBgwQJOnz5N586dmTt3LufOnWPz5s34+PhQoUIFwsLCUrxOUudZa1PsJXHw9vYm2rFCNtzyun7x1ncaMGAAL730Eo888girVq1i1KhRAEm+Xp8+fRgzZgzVq1end+/eTrUnq9FPgyQUKABFi0qtjizl/Hmp9AlSkXL16tv78LJWrte8ObRoAbt3S02P/fvl7lwDjrTx85PgYulSGU758EN5vHmzDMNowKGykM6dOzNv3jwWLFhAhw4duHz5MsWKFcPHx4eVK1dy9OhRp66T1HmtW7fmm2++4fz58wCxwyutW7dmckyV4qioKK5cuULx4sU5e/Ys58+f58aNGyxevDjZ1ytdujQAX331Vezzbdq0YeLEibGPHb0nd9xxB8ePH+frr7+mS5cuzv7zZCn6iZCMgIAs1tOxZYvMSOnYUXo5IO2Ly1gLP/8sVUnvvRf++Qc++UQSyQYP1tVeXal4cUnwmzYNGjTwdGuUcrlatWpx9epVSpcuTcmSJenWrRubNm2iUaNGzJ07l+rVqzt1naTOq1WrFiNGjKB58+bUrVuXl156CYCPP/6YlStXEhgYSMOGDdm1axc+Pj6MHDmSO+64g3bt2iX72qNGjaJjx440bdo0dugG4LXXXuPixYvUrl2bunXrsnLlyth9Tz75JPfcc0/skEt249bZK8ZwP/Ax4AVMs5axCfbnB+YA5ZChnvHWMiO5a6bn7JXeveUm/tixdHk595ozR5acL1JE1t9o3Dht17FWqgq+9ZbkbJQrJ8mivXunb8VNpZRLOL3KrHKJdu3aMXjwYFonU5k1K89ecVtPhzF4AZOAB4CaQBdjqJngsOeB3dZSF2gBTDAGFxSFcI0PP5Qb+EzNWrlL7tFDakJs3py2gCM6WtZMaNhQpnQGB0vlywMHpMS2BhxKKZWkS5cuUbVqVXx9fZMNOLI6dyaSNgEOWsshAGOYBzwK7I53jAXyGoMB/IELQKQb25QqBQp4ugUuYIwEHgMHSr2M1K4qGh0tPSOjR8siaVWqyFTNbt1ct0KpUkqlwo4dO+jRo8dNz+XKlYv169d7qEUpK1CgAPuz1Hh92rgz6CgNHI/3OAi4I8ExE4EfgZNAXqCTtUSTQZw/L+UQnnwSmjXzdGtSaeNGmQ3RoIFMg0ttdcqoKFl++u23JTm0enUZounUKe15IEop5QKBgYFsTWsRM+VR7kwkTexTLmECSVtgK1AKqAdMNIZblhg1hn7GsMkYNkWmYz9I7twyc/H339PvNV1ixgwpKjV4sDxOTcARGSmFqmrVktkSxsjibDt3Su+GBhxKZTmZrTJ1VpbVfxbuDDqCgLLxHpdBejTi6w0sjFkH5iBwGLglVdhaplpLI2tplJ6feX5+Ul060/SIhYfD889Lwa9//Qu++875cyMiJFipXl3WRMmVCxYskCGVTp20tLZSWVTu3Lk5f/58lv+wywystZw/f57cziyDkEm58yN8IxBgDBWBE0BnoGuCY44BrYHfjaE4UA0kBySjqFo1kwQdFy9KgufatVJZdMwY53olwsNh5kwpPnXkiAzHfP+9XEtrbCiV5ZUpU4agoCDOnTvn6aYoJAgsk2XLYLsx6LCWSGN4AfgZmTI73Vp2GUP/mP1TgNHATGPYgQzHDLWWYHe1KS0CAlLXYeAxefPKdNh586Rnwhl79sgiY0ePysyWSZPksa5OqlS24ePjE1u+Wyl3c+tghbUsBZYmeG5KvO9PAm3c2YbbVa2aVJ8OCZG1tTKcmTNlVdgSJWTZdGcDhhMnZLn18HBYtkyWodZgQymllBtp/3kKBg+WFWczXMBx44YU++rdW5ajB+eDhkuXJFC5dAl++kmCDw04lFJKuZlORUhBhvwsDgqCDh1g/XoYPlyqgzorLAwefRT27ZOAo35997VTKaWUikd7OlJgLTzxhKQ7ZAhbtkhV0F27JNnknXecn1kSFQXdu8OaNbICbDauiqeUUir9adCRAmNg69YMVKujQgUJOtavh/btnT/PUZX0u++kvnvnzm5rolJKKZUYDTqcEBCQAZa4X79ehkYKFpTlzmsmXMYmBWPGSHfNkCGyFotSSqmsw5j7MWYfxhzEmGGJ7C+IMYswZjvGbMCY2k6f60IadDjBUavDY7VzgoPhvvukpyItpk+H116ToZWxY1M+XimlVOZhzC0LrGJMwjvT4cBWrK0DPIWsAO/suS6jQYcTAgJkyuyZMx5qwNixcO1a2nooFi+Gfv1kSuyXX2rBL6WUynqaAAex9hDWhkPsAqvx1QR+BcDavUAFjCnu5Lkuo59ATggMhDvvhMuXPfDiQUEwcaKUJq9RI3Xnrlsnq9XVqyclzXPmdE8blVJKeVJiC6yWTnDMNkASAY1pApRHlidx5lyXyXRTZgsVKsSqVavS/XXffRdOnZItPVWdMIESUVFsaNuWsFS87zzHjlF/wAAiCxbk7xEjiNi82X2NVEop5VZFwBtjNsV7airWTo353pkFVscCH2PMVmAHsAWIdPJcl8l0QceFCxdo0aKFp5uRPiIjJRfj2We5MzWzTU6ehF69IHdufNas4Z7Kld3WRKWUUu4XDJFY2yiJ3SkvsGrtFWSRVTDGIAusHgbypHiuC2W6oMNTnnxSlrqfNSsdX9TbW+bq3rjh/DmXL8v6KefPw6pVoAGHUkpldRuBAIxJeoFVYwoAoTF5G32ANVh7BWNSPteFNOhwUng47N6dji949CjkyQNFi0q044wbN+Cxx6ShS5dKPQ+llFJZm7WRGHPTAqtYuwtj+sfsnwLUAGZhTBSwG3gm2XPdxFiPzQNNGz8/P3vt2rV0f90hQ+DTTyE0NJ0mgDz8MGzbBocOObdEfXS0FPz69luYMwe6dXN/G5VSSqULY0yotdbP0+24XTp7xUlVq0pHwvHjKR972/78U6a6PvuscwGHtTKd9ttvYfx4DTiUUkplSBp0OCkgQL7u3+/mF7JWFnErXhxefNG5c957T7phXnoJXn7Zve1TSiml0khzOpxUowZ07Aj58rn5hZYvh9WrJYjwc6InbeZMePVV6NIF3n/fzY1TSiml0k5zOjKakSMlJ2Pv3pSLef30k+R+tGwJS5Zo8S+llMqiskpOhwYdqRQW5vxkkjS7ehXy5k3+mA0bJNioVk2mxrq9C0YppZSnZJWgQ3M6UuGZZ6QkultERUnvBqQccOzfDw89JHkfS5dqwKGUUipT0KAjFUqWhMOHISLCDRefMwdq1YKNG5M/7vRpaNtWvv/5ZyhRwg2NUUoppVxPg45UCAiQDonDh1184Rs34I03oH59aJRUlVvgyhWpNnrunPRwOKbUKKWUUpmABh2pULWqfHX5tNkvvpAKpGPGgEls7R3g+nVo3x527pQVYxs3dnEjlFJKKffSKbOp4OhYOHDAhRe9dg3efhuaN5fhlbVrpSvl8GGpRur4PihIqo7OmgX33+/CBiillFLpQ4OOVChcGIYNu40lTS5evDWg2LQJzp6VfWXK3Hx8yZJQsSI0bRr3tU2b234fSimllCfolFl32LsXVqyICzAc2+XLNx9XoIAEE2XKyNTXihXjtvLlwdfXM+1XSimVoWSVKbPa05FKYWFw5AhUr57EAcHBkm8REiIFPRxBxD333BxUVKwIFy7I16TyOJRSSqksRIOOVBo3TiaahIYm0RExfrzkaWzcKOMwSQUUp09L0Y9XX4XXXnNrm5VSSqmMQGevpJJjBsvBg4nsPHcOJk6UdVAaNUq+B+Odd2SqbOfObmmnUkopldFo0JFKyc5gGT9epra+/nryFzlyBD7/XEqcVqni6iYqpZRSGZIGHamU5BL38Xs5kkz4iDFqFOTIIYu7KaWUUtmEBh2plC+fLHlyS0/H++9LlmlKvRwhIbJ8/QsvQOnSbmunUkopldFoImkafPwxlC0b74mzZ2HSJOjaVaa+JsffX7pJoqLc2kallFIqo9GgIw06dUrwhLO9HGfOQKFC4Jfpp1orpZRSqabDK2lw/jwsWybTZmN7Obp1i5vakpSnnpJy55msIJtSSinlChp0pMGaNbLY6549SOGOGzdSrrWxahX88gs88YQWA1NKKZUtadCRBo4ZLMc2noHPPoPu3ZPv5bAWhg+XxNHnnkufRiqllFIZjOZ0pEHlytJZUWLWOAgPT7mXY8kS+Osvqc2h66kopZTKprSnIw18faFh6dM02DBZejkcXR9JmTtXioD17p0+DVRKKaUyIO3pSKNhOcbhFeVELwdI0BEUBD4+7m+YUkoplUFpT0danD7N42cmc/WxHsmXMY+IgEuXpPpouXLp1z6llFIqA9KgIy3ee48ckREUHJ9CL8eMGVCpEhw6lD7tUkoppTIwYzNZzQg/Pz977do1zzXg1CmoVImw9l2Y3WI6rVtLXHGL69cl16NcOVi7VqfJKqWUSjNjTKi1NtNXltSejtR67z2IiOD00yPo109qdiTqs8/gxAl4910NOJRSSincHHQYw/3GsM8YDhrDsCSOaWEMW41hlzGsdmd7btupUzLttWdPyjSvjLd3IqvNAly5IsFGmzZSgVQppZTKKoz5DmMewphUxxBuCzqMwQuYBDwA1AS6GEPNBMcUAD4DHrGWWkBHd7XHJcaOhchIGDECb28ZVrlltVmAH36QWuljxqR7E5VSSik3mwx0BQ5gzFiMqe7sie7s6WgCHLSWQ9YSDswDHk1wTFdgobUcA7CWs25sz+05eTK2l8ORxBEQkERPR48esHs3NGyYvm1USiml3M3aFVjbDWgAHAGWY8yfGNMbY5KtDeHOoKM0cDze46CY5+KrChQ0hlXGsNkYnnJje27P2LGyHP2IEbFPVa0qPR3R0YkcX6NG+rVNKaVU9mbM/RizD2MOYsyt6QzG5MeY/2HMNozZhTG94+07gjE7MGYrxmxy8vUKA72APsAW4GMkCFme3GnuDDoSy55MOFXGG2gIPAS0BV43hlsWMTGGfsawyRg2RUa6vqEpOnECpk6FXr2gYsXYp4cNg+PHpQxHrG3b4PHHYe/edG+mUkqpbMiYW9IZMKZmgqOeB3ZjbV2gBTABY3LG298Sa+thbSMnXm8h8DuQB3gYax/B2vlYOwDwT+5UdwYdQUDZeI/LACcTOWaZtVyzlmBgDVA34YWsZaq1NLKWRt6eqKGaSC8HQLFiULhwgmO3bIHvv08QiSillFJu0wQ4iLWHsDapdAYL5MUYgwQGF4C03sZPxNqaWPsu1p66+VWSD1rc+cm4EQgwhorGkBPoDPyY4JgfgKbG4G0MeYA7gD1ubFPqOXo5eveGChVu2hUWBm+8Ab/+Gu/J/fvB2/umHhGllFLKjZxJZ5gI1EBu/ncAA7HWkRxggV8wZjPG9HPi9WpgTIHYR8YUxBinllB3W7+BtUQawwvAz4AXMN1adhlD/5j9U6xljzEsA7YD0cA0a9mZ3HULFSrEqlWr3NXsWwR8/DElo6LY0KoVYYm8bv78MpPWsavWH3/gV7IkG9auTbc2KqWUytqKgHeCfIupWDs15ntn0hnaAluBVkBlJPnzd6y9AtyDtScxpljM83uxNqkqVAB9sXZS3CvZixjTF5mNmiytSJqcoCBZx75XL5m5kojAQOnU+NHRh1O7tsxu+TFhp45SSimVNslWJDXmLmAU1raNefwqANa+G++YJcBYrP095vFvwDCs3ZDgWqOAEKwdn0xjtgN1cQQQklOyHWtrpfQ+NPEgOe++C9bC8OFJHuKYwQLIsYUL61RZpZRS6WkjEIAxFWOSQxNLZzgGtAbAmOJANeAQxvhhTN6Y5/2ANpD8iAMygvENxrTGmFbAf4FlzjRUl7ZPyvHjMG0aPP00lC+f5GEBAfC//0nNMG9vA6szdlFVpZRSWYy1kRhzUzoD1u7CmP4x+6cAo4GZGLMDGY4ZirXBGFMJWBSzXIc38DXWphRADAX+DTwbc61fgGnONFWHV5Ly3HMSdBw8mOyy9NOnw4ABsG8flCnj/mYppZTKfnTBt6zM0cvxzDPJBhwgxUdDQmICji++gCZN5AmllFIqKzImAGMWYMxujDkUuznBqaDDGAYaQz5jMMbwpTH8bQxtbq/VGZhjzZRXX03xUB+feIvIbtkiU2b9Mn0wqpRSSiVlBrL+SiTQEpgFzHbmRGd7Op62litIgklRoDcwNvXtzASOHYMvv4Q+fVLs5XAYOBA+/hgZY6lWTZeyV0oplZX5Yu2vgMHao1g7CpmKmyJngw7Hp+iDwAxr2Ubi84IzvzFjJGhwopfDYe1a+Okn4oIOpZRSKusKi1nW/gDGvIAxjwPFnDnR2aBjszH8ggQdPxtDXqSYV6Z2+rRUFL1+PeaJo0clM7RPHyhbNtlz46taFYL2hkj1Ug06lFJKZW2DkHVXXkTWT+sO9HTmRGeDjmeAYUBjawkFfJAhlkxt71546y2YNSvmiTT0coBMm71wLISox5+QRFKllFIqK5JCYE9ibQjWBmFtb6x9AmvXOXO6s0HHXcA+a7lkDN2B14DLaWxyhtG8OTRqBBMmQNShmF6Ovn1TPfe1alU4ZUuw/50FcN99bmqtUkop5WHWRgENYxaOSzVng47JQKgx1AVeAY4i2aqZmjEwZIhUFD3W/x1ZGXbYsFRfp3p1qBEQyeVMH4YppZRSKdoC/IAxPTCmfezmBKeKgxnD39bSwBhGAieslWmz1tLgNhueaq4uDhYZCS0rHmHliQC8nuuPmfhp2i7UrZsUElu/3mVtU0oppSCDFQczZkYiz1qsfTqlU50tg37VGF4FeiBL0XsheR2Znrc3TCn7DpFBXvzdehhpzsjYt0/WXVFKKaWyMmvTnNPpbNDRCeiK1Os4bQzlgPfT+qIZyuHD1Nw4ky9yPcuSmaX54fE0XMNawrbvY1XF3tzv8gYqpZRSGYj0dNw6TOJET4dTOR3WchqYC+Q3hnZAmLWZP6cDgHfewXh5cfnZYfz4o8xoSbVTp8gdEcKaMzpdVimlVJa3GFgSs/0K5AOcWv/D2TLoTwIbgI7Ak8B6Y+iQpqZmJIcOwVdfwb//Tc9XS5E7t8xkSbV9+wDYeLmqLruilFIqa7P2u3jbXCQuqO3Mqc7OXhmB1OjoaS1PAU2A19PW2gzk/Hlo0ACGDqVYMejVS2p2nD6dyusUK8aBBweyg0AOHnRHQ5VSSqkMKwBwat0QZ4OOHNZyNt7j86k4N+Nq3Fhmm5QqBcBLL0FEBHya2gkstWoROuYjzlCC/ftd30yllFIqwzDmKsZcid3gf8BQZ051NpF0mTH8DPw35nEnYGnqW5qxBQTA44/D5MlSlNTf38kTjx+nStlitGqVi7x53dpEpZRSyrOsTfMnnVN1OgCM4QngHmShtzXWsiitL3o7XF2nI6F16+Cuu+Cjj2T1WKdUqQING8L8+W5rl1JKqewrg9XpeBz4DWsvxzwuALTA2u9TPNXZoCOjcHfQAdC0KRw/LrW+vFPqCwoPB19fGD4cRo8mOloKmyqllFKuksGCjq1YWy/Bc1uwtn5Kpyb78WgMV43hSiLbVWO4cpvNzrCGDJEFZ7/91omD//kHoqOhWjVGjkzV4rRKKaVUZpRY7OBUukayQYe15LWWfIlsea0lX5qamgm0ayfrqbz/PqTYERQzXZZq1cifH06ehAsX3N5EpZRSylM2YcwHGFMZYyphzIfAZmdO1IGAROTIAS+/DFu2wG+/pXCwY7pKtWoEBMi3Bw64tXlKKaWUJw0AwoH5wDfAdeB5Z07UoCMJ3btD8eLS25GsNm1kjm2+fFStKk9p0KGUUirLsvYa1g7D2kYx23CsdSrZUoOOJOTODS++CD//DNu3J3NgvXrwwgsAVKokvSRaq0MppVSWZczymBkrjscFMeZnZ07VoCMZzz4Lfn4wfnwyB61YAWelblrOnDBokBQ5VUoppbKoIlh7KfaRtReBYs6cqEFHMgoWhD594L//lSm0t7hwAe67D2bPjn1qwgR47LH0a6NSSimVzqIxJq7suTEVSGzV2URo0JGCwYNlBsvHHyeyM14SqYO1cOqUE7NelFJKqcxpBPAHxszGmNnAauBVZ07UoCMF5cvDk0/C1Klw+XKCnfGmyzp89pks5XLmTPq1USmllEo31i4DGgH7kBksLyMzWFKkQYcThgyBq1fh888T7Ni3T0qWVqgQ+1SVKvJVk0mVUkplScb0AX5Fgo2XgdnAKGdO1aDDCfXrQ+vWMsQSHh5vx759ULky+PjEPqXTZpVSSmVxA4HGwFGsbQnUB845c6IGHU4aMkSqjX79dbwn334bvvjipuPKlZNZLHv2pG/7lFJKqXQShrVhABiTC2v3AtWSP0Xogm9OslZKckRFwY4dYEzSx95/P2zeDIcPg79/+rVRKaVU1pTBFnxbBPQGBgGtgIuAD9Y+mOKpGnQ4b/ZseOopWLIEHmwSDD/8AA8+CCVL3nTc1q1w4oTsSi44UUoppZyRoYKO+IxpDuQHlmFteIqHa9DhvIgIqTpapQqsHLoMHngA1qyBpk090h6llFLZQ4pBhzH3Ax8DXsA0rB2bYH9+YA5QDlkRdjzWznDqXBfSnI5U8PGRiqOrVsGx5bdOl43PWhg5EkaMSL/2KaWUyoaM8QImAQ8ANYEuGFMzwVHPA7uxti7QApiAMTmdPNdlNOhIpb59IV8+2PPDPihQAIoWTfQ4YyTxdPx4OHo0nRuplFIqO2kCHMTaQzFDHPOARxMcY4G8GGMAf+ACEOnkuS6jQUcq5csH/fuD1z/7CStfNdmkjTfekN2jRqVf+5RSSmU7pYH4i3UExTwX30SgBnAS2AEMxNpoJ891GW93XdhdChUqxKpVqzzahnvvhTs+384J/3ocT6Et06ZJddJly2TlWqWUUiq1ioA3xmyK99RUrJ0a831id78JEzbbAluR2SaVgeUY87uT57pMpgs6Lly4QIsWLTzdDAY8sJufvr/ButqlKVIk6ePOn5fk01atYNGi9GufUkqprCMYIrG2URK7g4Cy8R6XQXo04usNjEVmjxzEmMNAdSfPdRkdXkmj/q8V4Z+w0nz2WfLHFS4svR1vvpk+7VJKKZXtbAQCMKYixuQEOgM/JjjmGNAaAGOKI8W8Djl5rsu4NegwhvuNYZ8xHDSGYckc19gYooyhgzvb4zJ//UWtBW/yxH1XmDgRrqewzE3HjlCnTvo0TSmlVDZjbSTwAvAzsAf4Bmt3YUx/jOkfc9Ro4G6M2YGsmzIUa4OTPNdN3Fanwxi8gP3AfUj3zUagi7XsTuS45UAYMN1aFiR3XU/W6Yj11lswahRrfrpG8/t9mTxZkkuTc/48vPgi9OwJbdqkTzOVUkplDRm2OFgqubOnowlw0FoOWUty03AGAN8BZ93YFtfatw/KlaNpG18aNYIJE6Q8enLy5oU//4RXX4Xo6PRpplJKKZWRuDPoSHEajjGUBh4HprixHa63bx9UrYoxshDcwYNSET05OXPC6NHw99+wINm+HKWUUiprcmfQ4cw0nI+AodaSbD+BMfQzhk3GsCky0mXtSxtrJeiIqUTavj1UrAjvvy+7ktOlC9SuDa+9JiXVlVJKqezEnUGHM9NwGgHzjOEI0AH4zBgeS3gha5lqLY2spZG3pyf5nj8PkZGxQYe3N7z8MqxbB2vXJn+qlxeMGQMHDsCMGenQVqWUUioDcWciqTeSSNoaOIEkkna1lkSzYo1hJrA4UySSRkdL4JEzJwChoVCuHNxzT8rDLNZKDkj37lCiRDq0VSmlVKaniaQpsJZbpuFYyy5j6G8MKcz1yOBy5IgNOADy5IHnn4cff4S9e5M/1Rj4z3804FBKKZX96NL2qfXZZxJZfPLJTU+fOye9Hd27wxdfpHyZbdtg+HCYO1fWjVNKKaWSoj0d2dWSJbB69S1PFy0KvXrBrFlw+rRzl1q6VBJQlVJKqexAg47UijdzJaGXXpJZKZ9+mvJl6taFrl3ho4/g1CkXt1EppZTKgDToSI3wcDh8OMmgIyAAHn8cJk+GkJCUL/fWW3LJ0aNd3E6llFIqA9KgIzX++UdmriQRdIAUC7t4Ebp1g6++kumxSaXNVK4M/fpJDsjBg25qs1JKKZVBeLrqReZy6RJUqQLVqyd5yJ13wsCBMHOmzGYBKFIE7r47bmvUCHx9Zd/rr0OFClC6dFJXVEoppbIGnb3iJtHRsGePrLfy55/w11+SDgJSUKxBA7jrrrhApEwZz7ZXKaVUxpVVZq9o0JGOgoOlcqkjENmwAa5fl31FikD+mFGu+gAAIABJREFU/LIS7d13S6Kpj49n26uUUipj0KDDQzwadHTuLMU4xo1zyeUiIqRex59/wvTp8r2Dry80bhzXE3LXXRKYKKWUyn406PAQjwYdRYvK9JSpU11+6evXJV2kZEl45RUZjvnzT1mV1rHIXePGknRat67LX14ppVQGllWCDp294qwLF2R8pGpVt1ze1xdGjYLNm+X7Dz+E9evhyhVYswbefReOH4cmTaSgWFSy6/IqpZRSGY/2dDjrr79knOPHH+Hhh93yEpGRULMm5MoFW7fKqrTxBQfDv/8NCxdCs2ZS/bR8ebc0RSmlVAaiPR3ZjWPqSTI1Om6Xt7cs6TJypCwMl1CRIrBggUzH3bIF6tSB2bOTrgOilFJKZSQadDirQAFo1QoqVnTry9x/P3TsKAvZJsYY6NlTkk7r1IGnnoJOneD8ebc2SymllLptOrySAUVFwdixUKIEPPNM8se9/770jBQpIj0gbdqkWzOVUkqlEx1eyW6io9PtpXLkgF9/heHDk1/DxcsLhg2ThNOCBaFtW6nz4aj9oZRSSmUkGnQ4IyoKChVKt3XojYExY+DsWVmFNiX168OmTVJ+/dNPpdrp33+7v50qfWWyTkmllLqFBh3OOHYMLl+W7oR0cued8NhjEucEB6d8vK+vBCi//CLTbO+4QwIXnVqbNUycKKXyN23ydEuUUirtNOhwRjrMXEnM22/L8MrYsc6fc999sGMHtG8PI0ZA8+Zw6JD72qjc77vvZNjs9Glo1w6OHPF0i5RSKm006HDG/v3yNZ2Djlq1pKejY8fUnVeoEMybB3PmwM6dUsF0+nTtns+M1q6Fbt2kDP7GjXDjBjzwAFy86OmWKaVU6mnQ4Yx9+2Q1tqJF0/2lX3pJhkpSyxj5sNq+HRo1klkw7dvDuXOub6Nyj3374JFHZLmfH36QXJ3vv5eeq8cekwBEKaUyEw06nHHPPZKlmVjFrnRw9iz07Qt79qT+3HLlZCbM++/D0qUQGChfVcZ25oz0aHh5wU8/xS3217y5TI1eswZ69UrXSVVKKXXbtE5HJnDuHFSqBC1ayJ1uwvLoztq+Hbp3l5yP/v1h/Hjwy/SzvrOea9fkZ71rF6xaJevtJPTeezJdetgwWZdHKZW1aZ2O7CIiQm47PRicFS0Kr78OixfDgw86N5slMXXqwIYN8PLL8PnnMtV2wwbXtlXdnshIqTD7998wf37iAQfISsT9+0uS8ZQp6dtGpZRKKw06UrJrl5QGXbjQo80YMkQChVWrZGx/27a0XSd3bunh+PVXCAuTNewee0zenuYIeJa18MILsGSJTJFNbl1BY6Qmy0MPwfPPS0CqlFIZnQYdKXFMlw0I8GgzjIF+/eDPP6F0aShW7Pau17KlDLe89JJUNH3iCShZEp57Dtat05kunjB2rASWQ4fCs8+mfLy3t8xSql9feke0hofKCC5ckL8pSiVGg46U7Nsnn/geDjocGjaUwKNkSSn8NW6c5ACkRYECcv7x47BsmSQuzpwp0zOrVYPRo7UmRHqZO1fK3nftKkXdnOXvL70cRYtqDQ/leefPQ9OmUtxw/nxPt0ZlRBp0pGTfPpkC4uvr6ZbEckyi+eMPSSRs0gT27k379by9Zd2WuXOlANX06dKbMnKkLKrbvDl8+aUUZVWu99tv0Lu3JI9On570CsNJKVFCZrhoDQ/lSVevyu/fP/9AvXqyAvbq1Z5uVTZizP0Ysw9jDmLMsET2D8GYrTHbToyJwphCMfuOYMyOmH1u7TPV2SspadxYqm39/HP6vWYqrFgBXbpIfsb06akvJJaco0clEJk1S2Kv3Lkl/6NHD1nN1tvbda+VXe3cKTOyy5aVILJAgbRfa80aqUh7551SDj9XLte1U6nkXL8uSe6//w6LFsG//iW/16dOye91rVqebmHml+zsFWO8gP3AfUAQsBHogrW7kzj+YWAw1raKeXwEaIS1aZym4Dzt6UjJyy9Ldl8Gde+9MtOhdm148snUdc2npHx56fLfs0fGaJ95Rj7MHnpI1gF56SXYulXzP9LqxAm5M/T3l9optxNwADRrpjU8VPqLiJCcotWr4auvJAG6YEHpffP1ld/xEyc83cosrwlwEGsPYW04MA94NJnjuwD/TZeWJWStzVRbnjx5rLrVjRvWDhpk7bp17n+d77+3tn17a318rAVrAwOtff99a0+ccO9rZyWXL1tbp461/v7Wbtni2muPHSs/l2HDXHvdrCY01NqRI6395RdPtyTzioqytmtX+X2bNOnW/Vu2WJs3r/yuX7qU/u3LSoBrNqnPRuhgYVq8xz0sTEzi2DwWLlgoFO+5w/b/7Z15fBRVtsd/lyyAQUjCIvuOMKLs8gTRgcHHrjCO7C6jPhFH88ZlEBgcnqMyLuDMiIoI6ozCCE9BFBEBdUQZJA6g7EvY1xAgYUkikKT7vD9+3a+b0J2kSXdVd+V8P5/6dHet99atrvrVOeeeC/wgwHoBxgQ9ThimmHOvNGrUSObMmWPJsRJyclDlxAnkNW8OSUiw5JjhIjOTb9BXXhm5Y7hcjFTPzvYFs1avDtSsybf2UGMTKgoiwO7d9IG3bMlzFm4OHmRSucaNbcneH/UUFDD24Kef+LtJE1/WV6XseK+zBg0YWxSI3Fxg1y7ej1q1si2xc8wztFevghPAZr9ZsyAyCwBgzFAAfSHyX57fdwHoCpG0S3ZkzHAAd0LkVr959SFyFMbUAfAFgDSIfBuRikRS0URistTSMXMmJfyBA9YdMwzk5Ylcc41IpUoif/oT30Yizc6dIn/4g0jTpjxltWqJPPusSE5O5I8dS7jdInffzXP0t79F7jiFhSIDB/Ia+PTTyB0nFvnqK16f1auLzJ8v0rcv2+OZZ9g+Stn4/e953saNK/28vfsu173zTj3HlwtKtnR0E2C53++JAkwMsu4iAUaVsK+nBfhd0OXlnGwXEaFOloqOxx8XqVrVmqd2mMnNFRkxgi18663WPfxdLpGvvxYZNIjHrlaNN6WjR605frTzhz/wvDz9dOSPlZsr0rmzyBVXiKxdG/njRTtuN92AlSpRlO/cyfkFBT4h+OCDFGxKybz0Es/XAw+UXURMmcJtJk6MbNmcSimiI16AvQI0EyBRgI0CtA2wXg2PayXJb16SAFf6ff9OgH5Bj6WiI4IMHEhnZIzidotMn87Yi7Ztrb+ZbtxIf2+lSiKJiSJjxojs3m1tGaKJ2bP5j7vvPuve9jIzRZo0EalTR2TvXmuOGY3k5YkMH87zf8cdImfPXrzc7ebDEBC57TaR/Hx7yhkLzJrF8zRsmEhRUdm3c7sp6gCRGTMiVz6nUqLooGAYIECGAHsEmOSZN1aAsX7r/FqA+cW2a+4RKRsF2Pr/26rosEF0tGwpMnSodceLEGvWiHzwgX3H37NHZOxYkcqVKUBGjBDZsMG+8tjB0qUicXE05RcUWHvsbdtEkpNF2rQRyc629tjRwK5dItdey2vvhRdKFnyvvipijEi3biInT1pXxlhh/nyen/79GVQeKoWFtLxWqsSAdKXslCo6YmSyvQChTpaJjgsX+JR46ilrjmcRf/ubyL33MnLfao4eFXnySUazAyIDBoisWmV9Oaxm/XqRpCSRjh0vfcO2im++obXp5ptFzp+3pwx28NlnFFypqWXvpbJgAQVy69Yi+/ZFtHgxxdKlIvHxIjfdVD5LUF6eSNeu9FyvWRO+8oWKyyXy/vvsdZOREf2xJio6nC46CgpEvvxSZMcOa45nEc89x1Zv355vgHZw6hTLUasWy3LjjSJLlkT/n/5y2LdPpG5dkcaN7Y9ref99nu8RI2IyTCkkXC4Ghhoj0qFD6K6lb7+lWKlXL/xdmmORb7+lSOjYMTxdX7OyRFq04D0gI6P8+wuVzZt532FfMk7NmtH9s3Ah71HRhooOp4sOB/PZZyIpKSI1athr4szPZ8xJ48a8Etu144PRKYF82dl0aSQni2zdandpiDeHx/jxdpckcpw+zbgMb2+Jy30r37JFpGFDWua++iq8ZYwl1q9nT5/WrUWOHw/ffnftouho3pwixAry8xm7Ex8vUrMmLb+7djHGZPBgnxU2Lk6ke3cGfH/3XXTck1R0OF10pKeLLFrkzNdv4Rt45868Auw25hQUsEvdz37G8jRvzt7K587ZW67ycO4czdCJiSIrV9pdGh9ut8hDD4ljg/m2bhW5+mo+VKZPL//f99AhxoMkJFAQVzS2b6cwaNxY5ODB8O8/PZ0WlOuvp9slkixbxnsLIPLrX4ucOHHpOgUFdPk+9RRdQMZw/eRkkV/9SuTNN+1zuanocLrouO8+hvw7mHPnLr6RrloVWjR6uHG5qPO6duWVWbcuu+bZFQdxubhcjOwHRObNs7s0l1JYyC7N4czh4Xbzhp2Xx+7ZlxNkWF4WLGAX7Tp1GMMSLk6dYiwMIDJtWvj2G+3s309LT506kXWBLF7Ma3HgwMhYFDIzfekDWrdml/6ykp3NIPz77+e58LpiWrUSeeQRlt2q+5NTREfMZSS1bMC3Hj2YUvPbyCRlizZ27wbatAHatQNef53D29uFCPD118Dzz3NAu+RkDn+TlgbUqWNfuUqioADYuBFITweWLeNYKi++CDz5pN0lC0x+PkcP3r4d+NWvOH5GYSHr4f30/17assLCi/eflMTB5wYN4kBg9epFri4uF/DUU8ALLwD/8R/AwoXMkBlOzp/nQIcLFgCPPQZMm+bsjLtZWRyi/vhxjqnSvn1kj/fmm8DYscADD/B7OLKWut3ArFkcifvcOWDSJGD8+MsfCFGEA18uX84xqFauZEbb+Hige3eO1N2nD9CpU2SujRIHfIshVHQEo3ZtDqk6e3bkjxUFiPCG+vjjwOHDHDDsxRftf8ivXcuHyaJF/N2yJW+AHTr4Phs0sDa1sghH4E1P50B46enAjz9yaHmAD9gxY4D/+Z/oTvl87BhHJT58GEhIABITfZ/+30Odl5DAtNdLljBNNgB06UIBMmgQb8rhOi/Z2cCoUXwIjBkDTJ8eudF1XS4KjldfBUaM4OB6ThzJ9/RpoGdPtuEXX/CBagWTJnHAymefpYgsD5s3Aw8+CKxZA/ziF8AbbwBXXx2ecnq5cAFYvZrX3ooVvAcAHAbillt4LYbz/ukU0RFZ3w2kHyA7AdkNyIQAy0cDsskzfQdI+9L2aYl7JTubNrSpUyN/rCgjN5dBhgkJNKtGS5KkbdtE/vhHDjTXooXPzAmwO2SvXiKPPSby978zB0g4zftnzrAj05QpzDFQp47v2FWrivToIfLEEyIffki/t0PDgELG7RbZtImp+Lt18/nH69dnJstPPimfH//HH5l2PzGRideswO0WefFF1qNXL+cNYpaXxwDKhASR5cutPbbbLXLXXVKuIQLy8tgtPz6esSjvvWfd/zErS2TuXGa3bdUq/C5GOMS9EknBEQfIHkCaA5IIyEZArim2TndAUjzf+wPyfWn7tUR0rFnDU7N4ceSPFaVs387gTi/bttlXlkCcOSPyr3+JvPYaH2DXXy9SpYpPDCQksDfM3XeLvPwyex+UJdlTUREzqc6aRT9u27a+h6XXJ3z33QzCXL/e+kRfsczx47ymhg719RKoXJmJpmbMCG2Io7lzKfgaNIj8yMqBeO89PtjatXPO6Mrnz4v06cP4igUL7CnDhQsit9zCc7tsWWjbLl3qG/vp/vudl9zNKaIjYu4VY9ANwNMi6Ov5PZGWFTwfZP0UAFtEUKI31hL3SlERh6CsXz+yw7TGCMuXA/36AffcQ5fLVVfZXaLAuFw0CW/YwPgK72dmpm+dBg0uds20acOm9rpJ1q0D8vK4bmoqYwRuuIGfXbsCKSn21M1pFBQAq1bRBfPpp2wDgDFFXjdM165AXNzF2xUWAuPGAa+8Atx8M/DBB/ZdjytWMB4mNZVxPD/7mT3lCAdFRXQZLVwIvP02cN999pXl7Fm27Z49jCfp1Knk9Y8eBR59FPjwQ/6f33yT2zsNda+Ubum4A5C3/H7fBchrJaz/O//1g02ap8N6cnNFJkyg9aBGDXZFjIZ+62UlK4vZKKdOFRk9ml0g4+LkIhdNfLxIly4iDz8sMmdObGQodApuN7ttT5sm8vOf+9qmdm2Re+6h2+rMGZFjx3y9SB59NDqsTOvX092WkiKyerXdpbk83G521gNE/vxnu0tDjhwRadSIPdiCdVEtKmI20erVaTF79llnZ9uFWjpKxhgMBdBXBP/l+X0XgK4iSAuwbi8AMwD0EEF2gOVjAIwBgMTEpM4XLkTY0vH220DVqoxQU/6fnTvZg+SLL4DevfkZzYGSJXH+PLBtG3tvNGsGdOzIJlfs59QpWteWLGEvoFOnGJyalMTgvdmzgdGj7S6lj717aQk8dAiYN4/x5+UhP59BvpmZvs/MTODkSaBKFRpfyzJVq8aeFSUhAjzxBPCXvwCTJwN//GP5yh5Otm5lJ8K6dRmwmZrqW7ZxIwNFv/+eQZtvvMEgcyfjFEuH7e4VY9AOwCIA/UWQUdp+LXGvXHcdn0SLF0f2ODGICE2wbjcwbBhdGtnZ9vdyUZxJURHdXp9+CmRksEdQhw52l+pSTpygS2jdOnY5Hzv24uVuN/8n/kIikLA4dgzIzb10//Hx7BVx/jyXu91lK1fVqpcKEf/fZ8/SLZGWRpdVtL1EfPMNu6Fefz27z7tcwNNPUySlpvJz1KjoK3ckUNFR2o4N4gFkAOgN4AiAtQBGiWCr3zqNAfwTwN0i+K4s+4246HC5+EqVlgZMnRq54ziEGTOAiROB554DHnqo9DcrRXEq+fnA8OHAZ5/R2lFU5BMUWVn8XZxq1djFul49vtEH+16zpi/3g4hPfJR3ys+n1ei116I378gHH/C89u7NmK2DB5nP44UXLrZ+OB2niI6IPSJEUGQMHgGwHEAcgHdEsNUYjPUsnwlgMoCaAGZ4lGqRCLpEqkxl4uBB2nBbt7a1GLFC794MtPzv/wbeeotveT162F0qRbGepCTg448Z1PjRR7T+1a0LXHttYEFRty5FR6gYQwtG1aoVw8I4bBhzyTzxBHDNNQxA1ntM7KLJwYqzbBnQvz/tek4MgY4AIkze9eij9GtHm29YUZTYZ8MGio7ERLtLYg9OsXREqUHNRg4d4qdaOsqMMcDttzMo8/e/92m1TZs4f9o0Zgb0ZuxUFEUJlQ4dKq7gcBJq6QhEXh5tpRUhOimCrFgB/OY3vhwMlSszHfa77wItWjAYLlr9yIqiKNGEWjqcTLVqKjjCQJ8+HEguM5M+7kceoSvG64d+5hkalO69l/Eg27aVPSpfURRFiT3U0lGc++/n03L48MgdQwHArnpz5wLffcccBADQuDGwfz813549DLi74gpbi6koimI7TrF0aAdHf/LzgXfeYY4OJeIMHcpJhF3hVq8GcnJ8RqahQzlaZMeOwI03Mh1ymzbssw8wot2bd6B4umxFURQl+lDR4U+GJzeZBpFaijEcdrr40NNTprB73OrVwMyZzE0wahTwj39weZs21IkAhUf16hwz4plnKGRGj+b8GjU4Va/uG0PF5WJWw5QUoGlT9aYpiqJYgYoOf1R0RBX9+3MCOEDY3r1MA+3llVeAM2d809mzQPPmXHb+PLB+vW/Z+fOcP2kSRUdODtC5M+c1a8bBrkaOZDJaRVEUJTJoTIc/zzzDHLv5+ToQh8MoKKAoiY8HkpOBc+fYuyYzE/jkE44j43IB8+cznEdErR+KokQPGtPhRIqKOOa5Cg7HkZgI1Krl+121KjB4ML+PHcuxMz78kDHEADOrzp1L68ewYQxoVRRFUcqHWjoUJQDz5wMvvQT8+CNzifTsyRiRe+9VC4iiKNbjFEuHig5FKYEdOzhc+bx5wFVXMbAVYJb8Ll2YQ05RFCXSqOiwiYiJjmPHODb1n/7ks7ErigcR4NQpjmqZnc3BuhIT6aIZORLo21dTNCuKEjmcIjo0I6mXHTvY3UFt50oAjPENo52SAnz5JXDXXcDy5cBtt1GEfPaZvWVUFEWJdlR0eNm5k5/aXVYphUqVgJ//nLlDjh2j2Bg4kHlDAA5U/NhjwL//TQuJoiiKQlR0eMnIYJeGhg3tLokSQyQkAAMGAHPmcBA7gKPrzpjBRGQtWzI3yJYt9pZTURQlGtCYDi+DBnFY+40bw79vpcJx+jSwaBEDUL/6iknLMjLopsnJ8blqFEVRyoLGdDiNli0ZDagoYSA5md1rV6wAjh5l6nZjmKSsZUtaQf76Vy5TFEUpN8b0gzE7YcxuGDMhwPJxMGaDZ9oCY1wwJrVM24azmGrpUBTryM+n62XePOYAMYbxIc89x0HtFEVRAlGipcOYOAAZAP4TwGEAawGMhMi2IOvfCuAxiPwi5G3LiVo6AI32UywjKQkYNw744Qdg+3Zg8mRaO7ydpjZvZibU3FxryqOXfnjJzwe2bQP27bO7JEoFoyuA3RDZC5ECAPMBDC5h/ZEA5l3mtuVCRQfAwTfq1uVTQFEsok0bDvWzYwfQrRvnvf8+u+LWqQMMHQp89JFvsLqyUFAAHDnC0KQvv6RF5fvvuezsWe6zZ0+gbVseIyGBQw4BFDqPPw5Mn86/xIYNjE2JFg4cAPbvB/Ly7BNLP/3E28TnnwNvvAH885+cf+IEz2e1ajy3zZsDQ4ZQRCqKBTQAcMjv92HPvEsx5goA/QAsDHnbMBBzY6+kpqZi5cqVYd1no88/R4usLKzasweurKyw7ltRQqFvX6BHDwab5uTwjXn2bN/otzk5QGEhhwnyflarRs0MMNVMcYqKOMCdCAVHfDynhAQgLg6oUQNYuZLiplEj7nf3bk4A0KQJx60pKACyspgELTERqFyZn/Eh3kVEfGUvKgKqV+f8M2eYgM0737tOx45cfuAAcPIkvxvD4yYm+roq5+SwDt76eesYylBKIsCFC6zrhQvcPjmZyzZtYpn8OXSI5w4Apk3znZvz54HjxymSsrN1AEGl/NQC4mHMOr9ZsyAyy/M90NUVTJrfCmA1RHIuY9tyE3OiIycnBz179gzvTufMAa66CjcNGhTe/SpKOSgqAr7+mu4X7yXfsCEtGZUrA7Vrcxo8GBgxgst/+IEunNq1KRRq1wbq16ewAIBevUo+Zt++fGs/cMA3tWkDXHstU7+npVEc+LN4MXDrrcC6dRRITZrwQX/iBB+8U6YwhfyMGcCECZe6jo4cYRlfeIHr1K5Nq4H386GHgCpVaDVYt47C4+RJPsyLijhgH8CxcebNu9gK0rSpz9Vx220UZTVr8tzUqsV6TZ7M5ddfz/37M2CAL+nbsmUUSE2b+qa6dZm3JRD5+cAVV1Bs/Pa3wOrVrP8vf0mxpyihcBIogkiXIIsPA2jk97shgGBh6iPgc62Eum250UBSgK+WcXG8qypKFHPkCAVEUpJ9b85nzvhcHQcOALffDjRoACxYAPzmNxQbAC0NtWoBX3zBh/vKlcDHH1NI+IuKTp0oosKBy0WXUHY2hUlhIQN1AeDVV+l28hctLVoAS5Zw+UsvcX2voGjWrGRREQpz5tCNtXs3cPXVwPjxwJ13aup8peyUEkgaDwaD9gZwBAwGHQWRrcXWqwFgH4BGEMkPadtw1UNFB3jnGzIEmDWr9HUVRSmR/Hy6J5KT1aXgj8sFLFwIPP8842XS0hg/oyhlodQ8HcYMAPBXAHEA3oHIFBhDO6DITM86vwbQDyIjSt02QqjoKCpid4KbbuIrm6IoSgQRYf6W5s2BVq0oQD75hCJEk8YpwXBKcjAVHYqiKDYydSrw5JN0mT34IHsQNYhY34Hwc+oUhdOPP3IaMYJjEe3bx/e4lBRavbzTyJGMn8nJYZyL/7LkZAZGx7KF7NgxugtTUsK7X6eIjpgLJA07Z8/yCgmXU1lRFCUExo0D+vVjTMkrrzD2JC0NePllu0t2MSLA4cN0nbVowdie9u0Z1+Olfn1fDI0Ie0OdPs1YltOnOXXpQtGxZQuDe4uzcCHFyqpVHDjRK0ZSU4HOnbmsdm1r6lwWMjMZZFy/PgOxjQGWLmVgs3IpaumYNIn/7ry80Pv+KYqihJF9+9j1tnZt5nARAbZuZSCuHXzwAUdL3rCBU3Y2LRXvv8+yPfAAXUQdOwIdOjA8rqzk5XFwb68Y8U5DhlDUpKczU++pU5yflcXjr11L4ZKeTstKz57sYWWldWTNGvZqWrqUZQAoMubO5ff8fFquwolTLB0qOu64g33xvEPbK4qiRAlLl9JV0bcv8MQTQOPG7GjXrBk/c3OZsCw+nr+9U9WqZX8InzvHW6DXPRIXB7z+Ope1b8/kddddR2HRsSPQvTsFhtWIALt2MRYmPh6YOJHdrAGKnZtvpgAZM4b5VcLJ8eMUXX368PcNN7B7dffu7Fbdvz/Qrl1khY+KDpsIu+i47jr+gxcvDt8+FUVRwsCZM8x8+pe/8MHnJTub7obx4+mWKU5BAR+8Dz8MvPnmxYIkKYlxBwDzh7z2GuB283dyMnO5fPQRfx854stcG22IAHv3siv2N9/w0+WiC8gY1subEK9t29C6PrtctKgsXcrss+vW0QOfnc3zt307UK+eL3GcFajosImwig6Xi1dQWhqjuRRFUaKQc+fY4yU/n7et4cOZ4yM9nQnhioo43zuNG8eH7KefMg2+//JKlejCAYC33gIOHvRZMZo0id0gThEGp9asyd833QT861/8nppKS8gddwSPtTh5kkGsVapQyI0fz3N1ww0+a0aHDuHJ23I5qOiwibCKjn37aKubNYvOSUVRFMUx7N9PK4jXEtKnDzBzJi07o0czoDU3l9aMf/+bFp4hQ4A9e2jp6NMneroxq+iwibCKjhMnmCpw4ECgdevw7FNRFEWJSgoKaCE6coS9bPbsoWWna1daM0aPZhBrNKKiwyY0T4eiKIoSDo4epQipVcvukpSOU0SH9hFVFEVRKiSYUNibAAAFkklEQVT169tdgoqHTSExiqIoiqJUNFR0KIqiKIpiCSo6FEVRFEWxBBUdiqIoiqJYgooORVEURVEsQUWHoiiKoiiWoKJDURRFURRLUNGhKIqiKIolqOhQFEVRFMUSVHQoiqIoimIJMTf2ijHGDeBcGHcZD6AojPuLFpxYLyfWCXBmvbROsYMT6+XEOlUVkZg3FMSc6Ag3xph1ItLF7nKEGyfWy4l1ApxZL61T7ODEejmxTk4h5lWToiiKoiixgYoORVEURVEsQUUHMMvuAkQIJ9bLiXUCnFkvrVPs4MR6ObFOjqDCx3QoiqIoimINaulQFEVRFMUSKozoMMb0M8bsNMbsNsZMCLDcGGOme5ZvMsZ0sqOcoWCMaWSM+doYs90Ys9UY89sA6/Q0xpwxxmzwTJPtKGsoGGP2G2M2e8q7LsDymGorY0xrv/O/wRhz1hjzaLF1YqKdjDHvGGOOG2O2+M1LNcZ8YYzZ5flMCbJtif9BuwhSp6nGmB2e62uRMSY5yLYlXqt2EqReTxtjjvhdZwOCbBtLbfW/fvXZb4zZEGTbqG2rCoWIOH4CEAdgD4DmABIBbARwTbF1BgD4HIABcAOA7+0udxnqVQ9AJ8/3KwFkBKhXTwBL7C5riPXaD6BWCctjrq38yh4H4BiAJrHYTgBuBtAJwBa/eS8BmOD5PgHAi0HqXeJ/MMrq1AdAvOf7i4Hq5FlW4rUahfV6GsDvStkuptqq2PKXAUyOtbaqSFNFsXR0BbBbRPaKSAGA+QAGF1tnMID3hKQDSDbG1LO6oKEgIpki8oPney6A7QAa2FsqS4i5tvKjN4A9InLA7oJcDiLyLYCcYrMHA3jX8/1dAEMCbFqW/6AtBKqTiKwQEW9yqXQADS0vWDkJ0lZlIabayosxxgAYBmCepYVSQqKiiI4GAA75/T6MSx/OZVknajHGNAXQEcD3ARZ3M8ZsNMZ8boxpa2nBLg8BsMIYs94YMybA8lhuqxEIflOMtXbycpWIZAIUwgDqBFgnltvsPtCyFojSrtVo5BGP2+idIK6wWG2rmwBkiciuIMtjsa0cR0URHSbAvOLddsqyTlRijKkGYCGAR0XkbLHFP4Cm/PYAXgXwsdXluwxuFJFOAPoDeNgYc3Ox5THZVsaYRAC3AfgwwOJYbKdQiNU2mwSm0/5HkFVKu1ajjTcAtADQAUAm6I4oTky2FYCRKNnKEWtt5Ugqiug4DKCR3++GAI5exjpRhzEmARQc/xCRj4ovF5GzIpLn+b4UQIIxppbFxQwJETnq+TwOYBFo7vUnJtsKvNn9ICJZxRfEYjv5keV1b3k+jwdYJ+bazBhzD4BBAEaLSMCHbhmu1ahCRLJExCUibgCzEbi8sdhW8QBuB/C/wdaJtbZyKhVFdKwF0MoY08zztjkCwOJi6ywGcLenZ8QNAM54TcbRiseH+TaA7SLy5yDr1PWsB2NMV7DNs60rZWgYY5KMMVd6v4MBfVuKrRZzbeUh6JtYrLVTMRYDuMfz/R4AnwRYpyz/wajBGNMPwHgAt4nIT0HWKcu1GlUUi336JQKXN6baysMtAHaIyOFAC2OxrRyL3ZGsVk1gj4cMMCp7kmfeWABjPd8NgNc9yzcD6GJ3mctQpx6g2XMTgA2eaUCxej0CYCsYgZ4OoLvd5S6lTs09Zd3oKbdT2uoKUETU8JsXc+0EiqZMAIXgG/H9AGoC+ArALs9nqmfd+gCW+m17yX8wGqYgddoNxjV4/1czi9cp2LUaLVOQes3x/Gc2gUKiXqy3lWf+373/Jb91Y6atKtKkGUkVRVEURbGEiuJeURRFURTFZlR0KIqiKIpiCSo6FEVRFEWxBBUdiqIoiqJYgooORVEURVEsQUWHoiiKoiiWoKJDURRFURRLUNGhKIqiKIol/B8ya5VfLvb1rgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "his = history.history \n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ln1 = ax.plot(his['loss'], 'b--',label='loss')\n",
    "ln2 = ax.plot(his['val_loss'], 'b-',label='val_loss')\n",
    "ax.set_ylabel('loss', color='blue')\n",
    "ax.tick_params(axis='y', colors=\"blue\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ln3 = ax2.plot(his['accuracy'], 'r--',label='accuracy')\n",
    "ln4 = ax2.plot(his['val_accuracy'], 'r-',label='val_accuracy')\n",
    "ax2.set_ylabel('accuracy', color='red')\n",
    "ax2.tick_params(axis='y', colors=\"red\")\n",
    "\n",
    "\n",
    "lns = ln1 + ln2 + ln3 + ln4 \n",
    "labels = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labels)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations: \n",
    "\n",
    "(1) The training loss has decreased over time while the validation loss seems saturated after epoch 7th. In fact, the validation loss even increases a bit in epoch 8th. \n",
    "\n",
    "(2) Analogously, while the training accuracy is increased over time, the validation accuracy is saturated after epoch 7 and a drop in epochs 8th and 16th. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/feed-forward-2branches.PNG\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall the model architecture as figure above \n",
    "# Implement using Functional API \n",
    "X = tf.keras.layers.Input(shape=(16,)) #declare input layer\n",
    "h = Dense(units=10, activation= 'relu')(X)\n",
    "\n",
    "# First branch \n",
    "h1 = Dense(units=20, activation= 'relu')(h)\n",
    "h1 = Dense(units=15, activation= 'relu')(h1)\n",
    "\n",
    "# Second branch \n",
    "h2 = Dense(units=20, activation= 'relu')(h)\n",
    "h2 = Dense(units=15, activation= 'relu')(h2)\n",
    "\n",
    "# Concatenate in the last dimention \n",
    "h = tf.concat([h1,h2], axis=-1)\n",
    "\n",
    "# Last layer \n",
    "h = Dense(units=26, activation= 'softmax')(h)\n",
    "dnn_model = tf.keras.Model(inputs= X, outputs=h)\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           170         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 20)           220         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 20)           220         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 15)           315         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 15)           315         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 30)]         0           dense_11[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 26)           806         tf_op_layer_concat[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 2,046\n",
      "Trainable params: 2,046\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf2_cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "92c79073133677da89801d1b4bc42714b1a3d83cbc90a7f9c522b094b613b522"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
