{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT3181: Deep Learning (2021)</span>\n",
    "***\n",
    "*CE/Lecturer:*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
    "*Head TA:*  **Mr Thanh Nguyen** | thanh.nguyen4@monash.edu <br/>\n",
    "*Tutor:* **Dr Van Nguyen**  \\[van.nguyen1@monash.edu \\] | **Mr James Tong** \\[james.tong1@monash.edu\\] | **Dr Mahmoud Mohammad** \\[mahmoud.hossam@monash.edu\\]\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Tutorial 7a: Advanced Convolutional Neural Networks</span> ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this tutorial is to show you how to implement ResNet, the most popular CNN model. This ResNet implementation follows the original paper of ResNet.**\n",
    "\n",
    "\n",
    "**Acknowledgement:** *This tutorial is developed based on the material in chapter 7 of the book Dive Into Deep Learning*.\n",
    "\n",
    "**References and additional reading and resources**\n",
    "- Chapter 7 of Dive Into Deep Learning ([link](https://d2l.ai/chapter_convolutional-modern/index.html)).\n",
    "\n",
    "**Hint**: The implementations of ResNet in this tutorial would facilitate you in doing Part 3 of assignment 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">I. Implementation of Residual Network (ResNet)</span> <span style=\"color:red\">****</span> ##\n",
    "This is a **highly recommend-to-learn** knowledge because ResNet is the most widely popular architecture used in computer vision tasks. Moreover, we can apply what is learned here to assignment 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.1. Residual Block</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The building block of ResNet is the **residual block** which has the following architecture: *[CONV2D, BatchNorm, RELU, CONV2D, BatchNorm]* together with the skip connection. For the skip connection, we have two options: `use 1x1 CONV1D` or `not use 1x1 CONV1D`. The following figure shows the architecture of the residual block for two options.\n",
    "\n",
    "#### Skip connection aims to solve gradient vanishing and gradient exploding: \n",
    "https://stats.stackexchange.com/questions/339894/how-does-resnet-or-cnn-with-skip-connections-solve-the-gradient-exploding-proble\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/ResidualBlock.png\" align=\"center\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we are going to implement the class `Residual`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to use 1x1 conv sometimes because sizees of X != Y \n",
    "\n",
    "<img src=\"./md_images/md1.png\" align=\"center\" width=600/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "class Residual(tf.keras.Model):\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # conv layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(num_channels, padding='same', kernel_size=3, strides=strides)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=3, padding='same')    \n",
    "        # add 1x1 conv layer or not    \n",
    "        if use_1x1conv:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=1, strides=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        # batch normalization layers\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, X):\n",
    "        # 1: X -> conv -> BN -> activation -> Y\n",
    "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
    "        \n",
    "        # 2: Y -> conv -> BN -> Y\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        \n",
    "        # 3: see if X needs to do 1x1 conv ; 1x1 conv skip connection\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "            \n",
    "        # 3: skip connection , doing addition of matrices ; Y = Y + X\n",
    "        Y += X\n",
    "        \n",
    "        # 4: Y -> act -> Y\n",
    "        return tf.keras.activations.relu(Y)\n",
    "\n",
    "blk = Residual(num_channels=3, use_1x1conv=True, strides=1)\n",
    "X = tf.random.uniform((10, 32, 32, 3))\n",
    "Y = blk(X)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case when we do not apply 1x1 Conv1D, hence it requires the `num_channels` is equal to the `input_depth` (equal to 3 in the following example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 6, 6, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3)\n",
    "X = tf.random.uniform((4, 6, 6, 3))\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply 1x1 Conv1D, the output shape of the residual block can be different from the input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 3, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.2. ResNet Block</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement **ResNet block**. A ResNet block consists of several residual blocks and we need to declare the number of residual blocks as `num_residuals` and the common number of channels of residual blocks in a ResNet block as `num_channels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, num_residuals, first_block=False, **kwargs):\n",
    "        super(ResnetBlock, self).__init__(**kwargs)\n",
    "        self.residual_layers = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                self.residual_layers.append(\n",
    "                    Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                self.residual_layers.append(Residual(num_channels))\n",
    "\n",
    "    def call(self, X):\n",
    "        for layer in self.residual_layers.layers:  # tf.keras.Model.layers\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that from the second ResNet block, we apply `1x1 Conv1D` over the skip connection of every first residual block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.3. Residual Network</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now declare our ResNet. Note that we set `input_shape = [28,28,1]` because we will train our ResNet on Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ResNet():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', input_shape = [28,28,1]),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same'),\n",
    "        ResnetBlock(64, 2, first_block=True),\n",
    "        ResnetBlock(128, 2),\n",
    "        ResnetBlock(256, 2),\n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "        tf.keras.layers.Dense(units=10, activation= 'softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We feed a batch $X$ with batch size $1$ to our ResNet and print out the output shapes. Your task is to explain the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D output shape:\t (1, 14, 14, 64)\n",
      "BatchNormalization output shape:\t (1, 14, 14, 64)\n",
      "Activation output shape:\t (1, 14, 14, 64)\n",
      "MaxPooling2D output shape:\t (1, 7, 7, 64)\n",
      "ResnetBlock output shape:\t (1, 7, 7, 64)\n",
      "ResnetBlock output shape:\t (1, 4, 4, 128)\n",
      "ResnetBlock output shape:\t (1, 2, 2, 256)\n",
      "GlobalAveragePooling2D output shape:\t (1, 256)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 28, 28, 1))\n",
    "for layer in create_ResNet().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.4. Test our ResNet</span> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,)\n",
      "(50000, 28, 28, 1) (50000,)\n",
      "(10000, 28, 28, 1) (10000,)\n",
      "(10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full) , (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full, X_test = X_train_full/255.0, X_test/255.0\n",
    "X_train_full = np.expand_dims(X_train_full, axis=-1)   #expand one more dimension at the end and obtain [60000, 28, 28,1]\n",
    "X_test = np.expand_dims(X_test, axis=-1)   #expand one more dimension at the end and obtain [10000, 28, 28,1]\n",
    "X_train, X_valid = X_train_full[:50000,:], X_train_full[50000:,:]\n",
    "y_train, y_valid = y_train_full[:50000], y_train_full[50000:]\n",
    "print(X_train_full.shape, y_train_full.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 70s 88ms/step - loss: 0.4228 - accuracy: 0.8457 - val_loss: 0.3862 - val_accuracy: 0.8656\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 64s 81ms/step - loss: 0.2979 - accuracy: 0.8894 - val_loss: 0.3727 - val_accuracy: 0.8683\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 0.2599 - accuracy: 0.9052 - val_loss: 0.2775 - val_accuracy: 0.8972\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 60s 77ms/step - loss: 0.2308 - accuracy: 0.9143 - val_loss: 0.3016 - val_accuracy: 0.8902\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 57s 73ms/step - loss: 0.2110 - accuracy: 0.9213 - val_loss: 0.2874 - val_accuracy: 0.8972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22798fce4c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_resnet = create_ResNet()\n",
    "my_resnet.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "my_resnet.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Exercise 1</span>**: Implement VGG network and test on Fashion MNIST dataset. Note that you can refer to the code [here](https://d2l.ai/chapter_convolutional-modern/vgg.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, num_channels):\n",
    "    blk = tf.keras.models.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(tf.keras.layers.Conv2D(num_channels,kernel_size=3, padding='same',activation='relu'))\n",
    "    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    net = tf.keras.models.Sequential()\n",
    "    # The convolutional part\n",
    "    for (num_convs, num_channels) in conv_arch:\n",
    "        net.add(vgg_block(num_convs, num_channels))\n",
    "    # The fully-connected part\n",
    "    net.add(tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation= 'softmax')]))\n",
    "    return net\n",
    "\n",
    "conv_arch = ((1, 16), (2, 32))\n",
    "vgg_net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t (1, 14, 14, 16)\n",
      "Sequential output shape:\t (1, 7, 7, 32)\n",
      "Sequential output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1, 28, 28, 1))\n",
    "for blk in vgg_net.layers:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_net.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.6051 - accuracy: 0.7784 - val_loss: 0.3973 - val_accuracy: 0.8539\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 0.3784 - accuracy: 0.8632 - val_loss: 0.3498 - val_accuracy: 0.8710\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 0.3216 - accuracy: 0.8838 - val_loss: 0.3049 - val_accuracy: 0.8885\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.2896 - accuracy: 0.8940 - val_loss: 0.2860 - val_accuracy: 0.8927\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.2629 - accuracy: 0.9042 - val_loss: 0.2822 - val_accuracy: 0.8959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2279927e6d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_net.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">II. Additional Reading: New Version of ResNet</span> <span style=\"color:red\">**</span> ## \n",
    "This is a **good-to-learn part** and helps you to speculate more recently updated architecture of ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As additional reading, we are going to implement ResNet which is the state-of-the-art convolutional network for image classification and other tasks which took first place in all three ILSVRC 2015 challenges (classification, detection, and localization). \n",
    "\n",
    "ResNet uses **residual blocks** to train Convolutional Neural Networks to depths previously thought impossible. For example, in 2014, the VGG16 and VGG19 architectures were considered very deep. However, with ResNet, we have successfully trained networks with over 100 layers on the challenging ImageNet dataset and over 1,000 layers on CIFAR-10.\n",
    "\n",
    "What we are going to implement is  the **bottleneck residual block** (proposed by He et al. in their 2016 publication, *Identity Mappings in Deep Residual Networks*) used to train deeper networks which is an extension of the **original residual block** proposed in his publication in 2015.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.1. The differences between original and bottleneck residual blocks</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows differences between the original residual block and the bottleneck residual block.\n",
    "\n",
    "<img src='imgs/BottleneckResidualBlock.png' align='center' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bottleneck one, each block includes:\n",
    "- ReLU, BATCH-NORM, CONV [filters = K/4, kernel_size = 1x1]\n",
    "- ReLU, BATCH-NORM, CONV [filters = K/4, kernel_size = 3x3]\n",
    "- ReLU, BATCH-NORM, CONV [filters = K, kernel_size = 1x1]\n",
    "- Add inputs and ouputs (residual operation to add shortcut (skip connection) to outputs). This addition is optional for each residual block. In our implementation, when declaring the code for the residual block, we use the parameter `skip_connection` to govern this boolean quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.2. Architecture of ResNet </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet consists of many consecutive ResNet blocks in which each block has several residual blocks. There are many variants of ResNet architecture, which depends on computer vision tasks. The architecture below is an example that solves image classification on Fashion MNIST dataset. The input data are passed through the following layers:\n",
    "- Inputs => BATCH-NORM => CONV.\n",
    "- **ResNet block 1**\n",
    "  - ***Residual block 1***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - Skip connection \n",
    "  - ***Residual block 2***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "  - .........\n",
    "  - ***Residual block $N_1$***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "- **ResNet block 2**\n",
    "  - ***Residual block 1***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (3,3), strides = (2,2)]  (**downsampling image size by $2$**).\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - Skip connection \n",
    "  - ***Residual block 2***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "  - .........\n",
    "  - ***Residual block $N_2$***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "-  ......................\n",
    "- **ResNet block M**\n",
    "  - ***Residual block 1***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (3,3), strides = (2,2)]  (**downsampling image size by $2$**).\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - Skip connection \n",
    "  - ***Residual block 2***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "  - .........\n",
    "  - ***Residual block $N_M$***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.3. Implementation of ResNet </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, models, layers, regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "bn_momentum= 0.9\n",
    "bn_eps= 2E-5\n",
    "reg= 0.001\n",
    "DefaultBatchNorm = partial(keras.layers.BatchNormalization, momentum=bn_momentum, epsilon=bn_eps)\n",
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_regularizer=regularizers.l2(reg), use_bias=False, padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def __init__(self, num_classes=10, batch_size=32, num_epochs=20, optimizer='adam', learning_rate=0.001,\n",
    "                 verbose=True, random_state=42):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.optimizer = keras.optimizers.get(optimizer)\n",
    "        self.optimizer.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        keras.backend.clear_session()\n",
    "        np.random.seed(self.random_state)\n",
    "        tf.random.set_seed(self.random_state)\n",
    "        self.model = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def ResidualBlock(inputs, K=64, strides= (1,1), skip_connection= False):\n",
    "        main_layers = [DefaultBatchNorm(), layers.Activation(activation='relu'), DefaultConv2D(filters=int(K/4), kernel_size=1, strides=(1,1)),\n",
    "                       DefaultBatchNorm(), layers.Activation(activation='relu'), DefaultConv2D(filters=int(K/4), kernel_size=3, strides=strides),\n",
    "                       DefaultBatchNorm(), layers.Activation(activation='relu'), DefaultConv2D(filters=K, kernel_size=1, strides=(1,1))]\n",
    "        skip_layers = []\n",
    "        if skip_connection:\n",
    "            skip_layers = [DefaultBatchNorm(), layers.Activation(activation='relu'), DefaultConv2D(filters=K, kernel_size=1, strides=strides)]\n",
    "        \n",
    "        h = inputs\n",
    "        for layer in main_layers:\n",
    "            h = layer(h)\n",
    "        \n",
    "        if skip_connection:\n",
    "            short_cut = inputs\n",
    "            for layer in skip_layers:\n",
    "                short_cut = layer(short_cut)\n",
    "            return (h + short_cut)\n",
    "        else:\n",
    "            return h\n",
    "    \n",
    "    def build(self, blocks=[3,4], filters=[16,16,16]):\n",
    "        self.model = models.Model()\n",
    "        inputs = layers.Input(shape=(28, 28, 1))\n",
    "        h = inputs\n",
    "        h = DefaultBatchNorm()(h)\n",
    "        h = DefaultConv2D(filters=filters[0], kernel_size=3)(h)\n",
    "        \n",
    "        for i in range(len(blocks)):\n",
    "            strides = (1,1) if i==0 else (2,2) # We downsample at every beginning residual block except the first ResNet block\n",
    "            h = ResNet.ResidualBlock(h, filters[i], strides, True)  # apply the skip connection on the first residual block\n",
    "            \n",
    "            for j in range(1, blocks[i]-1, 1): # Add more blocks[i]-1 residual models\n",
    "                h  =  ResNet.ResidualBlock(h, filters[i], (1,1), False)  # no skip connection for these residual blocks\n",
    "        \n",
    "        h = DefaultBatchNorm()(h)\n",
    "        h = layers.Activation(activation='relu')(h)\n",
    "        h = layers.AveragePooling2D(pool_size=(8,8))(h)\n",
    "        h = layers.Flatten()(h)\n",
    "        h = layers.Dense(units=self.num_classes, activation=\"softmax\")(h)\n",
    "        self.model = models.Model(inputs=inputs, outputs= h, name=\"ResNet\") # We now have a ResNet model\n",
    "        self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, batch_size=None, num_epochs=None, verbose=None):\n",
    "        batch_size = batch_size if batch_size is not None else self.batch_size\n",
    "        num_epochs = num_epochs if num_epochs is not None else self.num_epochs\n",
    "        verbose = verbose if verbose is not None else self.num_epochs\n",
    "        self.history = self.model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs, verbose=1 if verbose else 0)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, acc = self.model.evaluate(X_test, y_test)\n",
    "        return acc\n",
    "    \n",
    "    def plot_progress(self):\n",
    "        pd.DataFrame(self.history.history).plot(figsize=(8, 5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0, np.max(self.history.history['loss']))  # Set the vertical range to [0-max(train loss)]\n",
    "        plt.show()\n",
    "    \n",
    "    def summary(self):\n",
    "        print(self.model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 28, 28, 1)    4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 16)   144         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28, 28, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 4)    64          activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28, 28, 4)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 4)    144         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 4)    16          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 4)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 28, 28, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 16)   64          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 16)   256         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 28, 28, 16)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 16)   64          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 4)    64          activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 4)    16          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 4)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 4)    144         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 4)    16          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 28, 28, 4)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 16)   64          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 28, 28, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 28, 28, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 4)    64          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 4)    16          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 28, 28, 4)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 4)    144         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 14, 14, 4)    16          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 4)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 16)   64          activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 14, 14, 16)   256         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 14, 14, 16)   0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 14, 14, 16)   64          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 14, 14, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 14, 14, 4)    64          activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 14, 14, 4)    16          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 14, 14, 4)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 14, 14, 4)    144         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 14, 14, 4)    16          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 14, 14, 4)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 14, 14, 16)   64          activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 14, 14, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 14, 14, 4)    64          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 14, 14, 4)    16          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 14, 14, 4)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 14, 14, 4)    144         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 14, 14, 4)    16          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 14, 14, 4)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 14, 14, 16)   64          activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 14, 14, 16)   64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 14, 14, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 16)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16)           0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           170         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,862\n",
      "Trainable params: 2,524\n",
      "Non-trainable params: 338\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "res_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 198s 503ms/step - loss: 1.7148 - accuracy: 0.4080 - val_loss: 1.1903 - val_accuracy: 0.6648\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 211s 538ms/step - loss: 1.0181 - accuracy: 0.6989 - val_loss: 0.9228 - val_accuracy: 0.7202\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 203s 520ms/step - loss: 0.8487 - accuracy: 0.7397 - val_loss: 0.7995 - val_accuracy: 0.7495\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 201s 515ms/step - loss: 0.7666 - accuracy: 0.7639 - val_loss: 0.7572 - val_accuracy: 0.7605\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 191s 490ms/step - loss: 0.7113 - accuracy: 0.7830 - val_loss: 0.8195 - val_accuracy: 0.7491\n"
     ]
    }
   ],
   "source": [
    "res_net.fit(X_train, y_train, X_valid, y_valid, batch_size=128, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8237 - accuracy: 0.7525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7524999976158142"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_net.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_net.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf2_cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "92c79073133677da89801d1b4bc42714b1a3d83cbc90a7f9c522b094b613b522"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
